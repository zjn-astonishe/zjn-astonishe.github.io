<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>17_Reasoning_Techniques | ZJN_BLOG</title><meta name="keywords" content="Agent"><meta name="author" content="ZJN"><meta name="copyright" content="ZJN"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Reasoning TechniquesMotivationComplex problem-solving often requires more than a single, direct answer, posing a significant challenge for AI.  The core problem is enabling AI agents to tackle multi-s">
<meta property="og:type" content="article">
<meta property="og:title" content="17_Reasoning_Techniques">
<meta property="og:url" content="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/index.html">
<meta property="og:site_name" content="ZJN_BLOG">
<meta property="og:description" content="Reasoning TechniquesMotivationComplex problem-solving often requires more than a single, direct answer, posing a significant challenge for AI.  The core problem is enabling AI agents to tackle multi-s">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png">
<meta property="article:published_time" content="2025-09-14T05:22:31.000Z">
<meta property="article:modified_time" content="2025-09-22T08:39:22.908Z">
<meta property="article:author" content="ZJN">
<meta property="article:tag" content="Agent">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":800},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: ZJN","link":"链接: ","source":"来源: ZJN_BLOG","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#000000","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '17_Reasoning_Techniques',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-09-22 16:39:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_3207144_mqiyof22xva.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ZJN_BLOG" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">78</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">ZJN_BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">17_Reasoning_Techniques</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-14T05:22:31.000Z" title="发表于 2025-09-14 13:22:31">2025-09-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-22T08:39:22.908Z" title="更新于 2025-09-22 16:39:22">2025-09-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Agent/">Agent</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Reasoning-Techniques"><a href="#Reasoning-Techniques" class="headerlink" title="Reasoning Techniques"></a>Reasoning Techniques</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problem-solving often requires more than a single, direct answer, posing a significant challenge for AI. </p>
<p>The core problem is enabling AI agents to tackle multi-step tasks that demand logical inference, decomposition, and strategic planning. </p>
<p>Without a structured approach, agents may fail to handle intricacies, leading to inaccurate or incomplete conclusions. These advanced reasoning methodologies aim to make an agent’s internal “thought” process explicit, allowing it to systematically work through challenges.</p>
<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Reasoning techniques allow agents to break down problems, consider intermediate steps, and reach more robust and accurate conclusions.  </p>
<p>A core principle among these advanced methods is the allocation of increased computational resources during inference. This means granting the agent, or the underlying LLM, more processing time or steps to process a query and generate a response. </p>
<p>Rather than a quick, single pass, the agent can engage in iterative refinement, explore multiple solution paths, or utilize external tools. </p>
<p>This extended processing time during inference often significantly enhances accuracy, coherence, and robustness, especially for complex problems requiring deeper analysis and deliberation.</p>
<p>An agent’s thinking process is a structured approach that combines reasoning and acting to solve problems. This method allows an agent to explicitly plan its steps, monitor its progress, and interact with external tools to gather information.</p>
<p>At its core, the agent’s “thinking” is facilitated by a powerful LLM. This LLM generates a series of thoughts that guide the agent’s subsequent actions. The process typically follows a thought-action-observation loop:</p>
<ul>
<li>Thought: <ul>
<li>The agent first generates a textual thought that breaks down the problem, formulates a plan, or analyzes the current situation. This internal monologue makes the agent’s reasoning process transparent and steerable.</li>
</ul>
</li>
<li>Action: <ul>
<li>Based on the thought, the agent selects an action from a predefined, discrete set of options. For example, in a question-answering scenario, the action space might include searching online, retrieving information from a specific webpage, or providing a final answer.</li>
</ul>
</li>
<li>Observation: <ul>
<li>The agent then receives feedback from its environment based on the action taken. This could be the results of a web search or the content of a webpage.</li>
</ul>
</li>
</ul>
<h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Chain-of-Thoughts-CoT"><a href="#Chain-of-Thoughts-CoT" class="headerlink" title="Chain-of-Thoughts (CoT)"></a>Chain-of-Thoughts (CoT)</h3><p>Its prompting significantly enhances LLMs complex reasoning abilities by mimicking a step-by-step thought process.</p>
<p>Instead of providing a direct answer, CoT prompts guide the model to generate a sequence of intermediate reasoning steps, which allows LLMs to tackle complex problems by decomposing them into smaller, more manageable sub-problems.</p>
<p>CoT can be implemented using various strategies, including offering few-shot examples that demonstrate step-by-step reasoning or simply instructing the model to “think step-by-step”. These approaches not only boosts accuracy but also offers valuable insights into the model’s decision-making, aiding in debugging and comprehension. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CoT_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">You are an Information Retrieval Agent. Your goal is to answer the user&#x27;s question comprehensively and accurately by thinking step-by-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here&#x27;s the process you must follow:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.  **Analyze the Query:** Understand the core subject and specific requirements of the user&#x27;s question. Identify key entities, keywords, and the type of information being sought.</span></span><br><span class="line"><span class="string">2.  **Formulate Search Queries (for Knowledge Base):** Based on your analysis, generate a list of precise search queries that you would use to retrieve relevant information from a knowledge base or external tools.</span></span><br><span class="line"><span class="string">3.  **Simulate Information Retrieval (Self-Correction/Reasoning):** For each search query, mentally consider what kind of information you expect to find. If you were to retrieve the content, what would be the most relevant snippets? Think about potential ambiguities or missing pieces.</span></span><br><span class="line"><span class="string">4.  **Synthesize Information:** Based on the simulated retrieval and your understanding of the user&#x27;s original query, synthesize the gathered information into a coherent and complete answer. Ensure all aspects of the query are addressed.</span></span><br><span class="line"><span class="string">5.  **Review and Refine:** Before finalizing, critically evaluate your answer. Is it accurate? Is it comprehensive? Is it easy to understand? Is it concise? If not, identify what needs to be improved and how.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="Tree-of-Thoughts-ToT"><a href="#Tree-of-Thoughts-ToT" class="headerlink" title="Tree-of-Thoughts (ToT)"></a>Tree-of-Thoughts (ToT)</h3><p>It is a reasoning technique that builds upon Chain-of-Thought. It allows LLMs to explore multiple reasoning paths by branching into different intermediate steps, forming a tree structure. </p>
<p>This approach supports complex problem-solving by enabling backtracking, self-correction, and exploration of alternative solutions. </p>
<p>Maintaining a tree of possibilities allows the model to evaluate various reasoning trajectories before finalizing an answer. </p>
<h3 id="Self-correction"><a href="#Self-correction" class="headerlink" title="Self-correction"></a>Self-correction</h3><p>It, also known as self-refinement, is a crucial aspect of an agent’s reasoning process, particularly within Chain-of-Thought prompting. </p>
<p>It involves the agent’s internal evaluation of its generated content and intermediate thought processes. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">self_correction_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">You are a highly critical and detail-oriented Self-Correction Agent. Your task is to review a previously generated piece of content against its original requirements and identify areas for improvement. Your goal is to refine the content to be more accurate, comprehensive, engaging, and aligned with the prompt.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here&#x27;s the process you must follow for self-correction:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.  **Understand Original Requirements:** Review the initial prompt/requirements that led to the content&#x27;s creation. What was the *original intent*? What were the key constraints or goals?</span></span><br><span class="line"><span class="string">2.  **Analyze Current Content:** Read the provided content carefully.</span></span><br><span class="line"><span class="string">3.  **Identify Discrepancies/Weaknesses:** Compare the current content against the original requirements. Look for:</span></span><br><span class="line"><span class="string">   * **Accuracy Issues:** Are there any factual errors or misleading statements?</span></span><br><span class="line"><span class="string">   * **Completeness Gaps:** Does it fully address all aspects of the original prompt? Is anything missing?</span></span><br><span class="line"><span class="string">   * **Clarity &amp; Coherence:** Is the language clear, concise, and easy to understand? Does it flow logically?</span></span><br><span class="line"><span class="string">   * **Tone &amp; Style:** Does it match the desired tone and style (e.g., professional, engaging, concise)?</span></span><br><span class="line"><span class="string">   * **Engagement:** Is it captivating? Does it hold the reader&#x27;s attention?</span></span><br><span class="line"><span class="string">   * **Redundancy/Verbosity:** Can any parts be condensed or removed without losing meaning?</span></span><br><span class="line"><span class="string">4.  **Propose Specific Improvements:** For each identified weakness, suggest concrete and actionable changes. Do not just state the problem; propose a solution.</span></span><br><span class="line"><span class="string">5.  **Generate Revised Content:** Based on your proposed improvements, rewrite the original content to incorporate all the necessary changes. Ensure the revised content is polished and ready for final use.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="Program-Aided-Language-Models-PALMs"><a href="#Program-Aided-Language-Models-PALMs" class="headerlink" title="Program-Aided Language Models (PALMs)"></a>Program-Aided Language Models (PALMs)</h3><p>It integrates LLMs with symbolic reasoning capabilities, which allows the LLM to generate and execute code, such as Python, as part of its problem-solving process.</p>
<p>PALMs offload complex calculations, logical operations, and data manipulation to a deterministic programming environment. This approach utilizes the strengths of traditional programming for tasks where LLMs might exhibit limitations in accuracy or consistency. </p>
<h3 id="Reinforcement-Learning-with-Verifiable-Rewards-RLVR"><a href="#Reinforcement-Learning-with-Verifiable-Rewards-RLVR" class="headerlink" title="Reinforcement Learning with Verifiable Rewards (RLVR)"></a>Reinforcement Learning with Verifiable Rewards (RLVR)</h3><p>While effective, the standard Chain-of-Thought (CoT) prompting used by many LLMs is a somewhat basic approach to reasoning. It generates a single, predetermined line of thought without adapting to the complexity of the problem. </p>
<p>To overcome these limitations, a new class of specialized “reasoning models” has been developed. These models operate differently by dedicating a variable amount of “thinking” time before providing an answer. This “thinking” process produces a more extensive and dynamic Chain-of-Thought that can be thousands of tokens long. This extended reasoning allows for more complex behaviors like self-correction and backtracking, with the model dedicating more effort to harder problems. </p>
<p>The key innovation enabling these models is a training strategy called Reinforcement Learning from Verifiable Rewards (RLVR). By training the model on problems with known correct answers (like math or code), it learns through trial and error to generate effective, long-form reasoning. </p>
<p>This allows the model to evolve its problem-solving abilities without direct human supervision. Ultimately, these reasoning models don’t just produce an answer; they generate a “reasoning trajectory” that demonstrates advanced skills like planning, monitoring, and evaluation. This enhanced ability to reason and strategize is fundamental to the development of autonomous AI agents, which can break down and solve complex tasks with minimal human intervention.</p>
<h3 id="Reasoning-and-Acting-ReAct"><a href="#Reasoning-and-Acting-ReAct" class="headerlink" title="Reasoning and Acting (ReAct)"></a>Reasoning and Acting (ReAct)</h3><p>It is a paradigm that integrates Chain-of-Thought (CoT) prompting with an agent’s ability to interact with external environments through tools. Unlike generative models that produce a final answer, a ReAct agent reasons about which actions to take. </p>
<p>This reasoning phase involves an internal planning process, similar to CoT, where the agent determines its next steps, considers available tools, and anticipates outcomes. </p>
<p>Following this, the agent acts by executing a tool or function call, such as querying a database, performing a calculation, or interacting with an API. </p>
<h3 id="Chain-of-Debates-CoD"><a href="#Chain-of-Debates-CoD" class="headerlink" title="Chain of Debates (CoD)"></a>Chain of Debates (CoD)</h3><p>It is a formal AI framework proposed by Microsoft where multiple, diverse models collaborate and argue to solve a problem, moving beyond a single AI’s “chain of thought.” </p>
<p>This system operates like an AI council meeting, where different models present initial ideas, critique each other’s reasoning, and exchange counterarguments. </p>
<p>The primary goal is to enhance accuracy, reduce bias, and improve the overall quality of the final answer by leveraging collective intelligence. </p>
<p>Functioning as an AI version of peer review, this method creates a transparent and trustworthy record of the reasoning process. </p>
<p>Ultimately, it represents a shift from a solitary Agent providing an answer to a collaborative team of Agents working together to find a more robust and validated solution.</p>
<h3 id="Graph-of-Debates-GoD"><a href="#Graph-of-Debates-GoD" class="headerlink" title="Graph of Debates (GoD)"></a>Graph of Debates (GoD)</h3><p>It is an advanced Agentic framework that reimagines discussion as a dynamic, non-linear network rather than a simple chain. </p>
<p>In this model, arguments are individual nodes connected by edges that signify relationships like ‘supports’ or ‘refutes,’ reflecting the multi-threaded nature of real debate. This structure allows new lines of inquiry to dynamically branch off, evolve independently, and even merge over time. </p>
<p>A conclusion is reached not at the end of a sequence, but by identifying the most robust and well-supported cluster of arguments within the entire graph. </p>
<p>“Well-supported” refers to knowledge that is firmly established and verifiable. This can include information considered to be ground truth, which means it is inherently correct and widely accepted as fact. Additionally, it encompasses factual evidence obtained through search grounding, where information is validated against external sources and real-world data. Finally, it also pertains to a consensus reached by multiple models during a debate, indicating a high degree of agreement and confidence in the information presented.</p>
<h3 id="Deep-Research"><a href="#Deep-Research" class="headerlink" title="Deep Research"></a>Deep Research</h3><p>It describes a category of AI Agentic tools designed to act as tireless, methodical research assistants. Major platforms in this space include Perplexity AI, Google’s Gemini research capabilities, and OpenAI’s advanced functions within ChatGPT.</p>
<p>A fundamental shift introduced by these tools is the change in the search process itself. A standard search provides immediate links, leaving the work of synthesis to you. Deep Research operates on a different model. Here, you task an AI with a complex query and grant it a “time budget”—usually a few minutes. In return for this patience, you receive a detailed report.</p>
<p>During this time, the AI works on your behalf in an agentic way. It autonomously performs a series of sophisticated steps that would be incredibly time-consuming for a person:</p>
<ul>
<li>Initial Exploration: <ul>
<li>It runs multiple, targeted searches based on your initial prompt.</li>
</ul>
</li>
<li>Reasoning and Refinement: <ul>
<li>It reads and analyzes the first wave of results, synthesizes the findings, and critically identifies gaps, contradictions, or areas that require more detail.</li>
</ul>
</li>
<li>Follow-up Inquiry: <ul>
<li>Based on its internal reasoning, it conducts new, more nuanced searches to fill those gaps and deepen its understanding.</li>
</ul>
</li>
<li>Final Synthesis: <ul>
<li>After several rounds of this iterative searching and reasoning, it compiles all the validated information into a single, cohesive, and structured summary.</li>
</ul>
</li>
</ul>
<h3 id="Multi-Agent-System-Search-MASS"><a href="#Multi-Agent-System-Search-MASS" class="headerlink" title="Multi-Agent System Search (MASS)"></a>Multi-Agent System Search (MASS)</h3><p>An in-depth analysis of the design of multi-agent systems reveals that their effectiveness is critically dependent on both the quality of the prompts used to program individual agents and the topology that dictates their interactions. The complexity of designing these systems is significant, as it involves a vast and intricate search space.</p>
<p>The Multi-Agent System Search (MASS) Framework is a three-stage optimization process that navigates a search space encompassing optimizable prompts (instructions and demonstrations) and configurable agent building blocks (Aggregate, Reflect, Debate, Summarize, and Tool-use). </p>
<ul>
<li>The first stage, Block-level Prompt Optimization, independently optimizes prompts for each agent module. </li>
<li>Stage two, Workflow Topology Optimization, samples valid system configurations from an influence-weighted design space, integrating the optimized prompts. </li>
<li>The final stage, Workflow-level Prompt Optimization, involves a second round of prompt optimization for the entire multi-agent system after the optimal workflow from Stage two has been identified.</li>
</ul>
<h4 id="Block-Level-Prompt-Optimization"><a href="#Block-Level-Prompt-Optimization" class="headerlink" title="Block-Level Prompt Optimization"></a>Block-Level Prompt Optimization</h4><p>The process begins with a local optimization of prompts for individual agent types, or “blocks,” to ensure each component performs its role effectively before being integrated into a larger system. </p>
<p>This initial step is crucial as it ensures that the subsequent topology optimization builds upon well-performing agents, rather than suffering from the compounding impact of poorly configured ones.</p>
<p>The specialized role-playing prompt, discovered during block-level optimization, aims to make the debator agent highly effective at synthesizing information before it’s even placed into a larger workflow.</p>
<h4 id="Workflow-Topology-Optimization"><a href="#Workflow-Topology-Optimization" class="headerlink" title="Workflow Topology Optimization"></a>Workflow Topology Optimization</h4><p>Following local optimization, MASS optimizes the workflow topology by selecting and arranging different agent interactions from a customizable design space. </p>
<p>To make this search efficient, MASS employs an influence-weighted method. This method calculates the “incremental influence” of each topology by measuring its performance gain relative to a baseline agent and uses these scores to guide the search toward more promising combinations.</p>
<h4 id="Workflow-Level-Prompt-Optimization"><a href="#Workflow-Level-Prompt-Optimization" class="headerlink" title="Workflow-Level Prompt Optimization"></a>Workflow-Level Prompt Optimization</h4><p>It involves a global optimization of the entire system’s prompts. After identifying the best-performing topology, the prompts are fine-tuned as a single, integrated entity to ensure they are tailored for orchestration and that agent interdependencies are optimized.</p>
<h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Complex-Question-Answering"><a href="#Complex-Question-Answering" class="headerlink" title="Complex Question Answering"></a>Complex Question Answering</h3><p>Facilitating the resolution of multi-hop queries, which necessitate the integration of data from diverse sources and the execution of logical deductions, potentially involving the examination of multiple reasoning paths, and benefiting from extended inference time to synthesize information.</p>
<h3 id="Mathematical-Problem-Solving"><a href="#Mathematical-Problem-Solving" class="headerlink" title="Mathematical Problem Solving"></a>Mathematical Problem Solving</h3><p>Enabling the division of mathematical problems into smaller, solvable components, illustrating the step-by-step process, and employing code execution for precise computations, where prolonged inference enables more intricate code generation and validation.</p>
<h3 id="Code-Debugging-and-Generation"><a href="#Code-Debugging-and-Generation" class="headerlink" title="Code Debugging and Generation"></a>Code Debugging and Generation</h3><p>Supporting an agent’s explanation of its rationale for generating or correcting code, pinpointing potential issues sequentially, and iteratively refining the code based on test results (Self-Correction), leveraging extended inference time for thorough debugging cycles.</p>
<h3 id="Strategic-Planning"><a href="#Strategic-Planning" class="headerlink" title="Strategic Planning"></a>Strategic Planning</h3><p>Assisting in the development of comprehensive plans through reasoning across various options, consequences, and preconditions, and adjusting plans based on real-time feedback (ReAct), where extended deliberation can lead to more effective and reliable plans.</p>
<h3 id="Medical-Diagnosis"><a href="#Medical-Diagnosis" class="headerlink" title="Medical Diagnosis"></a>Medical Diagnosis</h3><p>Aiding an agent in systematically assessing symptoms, test outcomes, and patient histories to reach a diagnosis, articulating its reasoning at each phase, and potentially utilizing external instruments for data retrieval (ReAct). Increased inference time allows for a more comprehensive differential diagnosis.</p>
<h3 id="Legal-Analysis"><a href="#Legal-Analysis" class="headerlink" title="Legal Analysis"></a>Legal Analysis</h3><p>Supporting the analysis of legal documents and precedents to formulate arguments or provide guidance, detailing the logical steps taken, and ensuring logical consistency through self-correction. Increased inference time allows for more in-depth legal research and argument construction.</p>
<h2 id="Scaling-Inference-Law"><a href="#Scaling-Inference-Law" class="headerlink" title="Scaling Inference Law"></a>Scaling Inference Law</h2><p>Scaling Inference (not Training) Law dictates the relationship between an LLM’s performance and the computational resources allocated during its operational phase, known as inference.</p>
<p>A cornerstone of this law is the revelation that superior results can frequently be achieved from a comparatively smaller LLM by augmenting the computational investment at inference time. This doesn’t necessarily mean using a more powerful GPU, but rather employing more sophisticated or resource-intensive inference strategies. A prime example of such a strategy is instructing the model to generate multiple potential answers—perhaps through techniques like diverse beam search or self-consistency methods—and then employing a selection mechanism to identify the most optimal output. This iterative refinement or multiple-candidate generation process demands more computational cycles but can significantly elevate the quality of the final response.</p>
<p>This principle offers a crucial framework for informed and economically sound decision-making in the deployment of Agents systems. It challenges the intuitive notion that a larger model will always yield better performance. The law posits that a smaller model, when granted a more substantial “thinking budget” during inference, can occasionally surpass the performance of a much larger model that relies on a simpler, less computationally intensive generation process. The “thinking budget” here refers to the additional computational steps or complex algorithms applied during inference, allowing the smaller model to explore a wider range of possibilities or apply more rigorous internal checks before settling on an answer.</p>
<p>Consequently, the Scaling Inference Law becomes fundamental to constructing efficient and cost-effective Agentic systems. It provides a methodology for meticulously balancing several interconnected factors:</p>
<ul>
<li>Model Size: <ul>
<li>Smaller models are inherently less demanding in terms of memory and storage.</li>
</ul>
</li>
<li>Response Latency: <ul>
<li>While increased inference-time computation can add to latency, the law helps identify the point at which the performance gains outweigh this increase, or how to strategically apply computation to avoid excessive delays.</li>
</ul>
</li>
<li>Operational Cost: <ul>
<li>Deploying and running larger models typically incurs higher ongoing operational costs due to increased power consumption and infrastructure requirements. The law demonstrates how to optimize performance without unnecessarily escalating costs.</li>
</ul>
</li>
</ul>
<h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p><a target="_blank" rel="noopener" href="https://github.com/jina-ai/node-DeepResearch">node-DeepResearch</a></p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Agent/">Agent</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/09/14/Agent/2025-09-14-16_Resource_Aware_Optimization/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">16_Resource_Aware_Optimization</div></div></a></div><div class="next-post pull-right"><a href="/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">18_Guardrails_Safety_Patterns</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2025/09/07/Agent/2025-09-07-2_Routing/" title="2. Routing"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-07</div><div class="title">2. Routing</div></div></a></div><div><a href="/2025/09/07/Agent/2025-09-07-1_Prompt_Chaining/" title="1. Prompt Chaining"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-07</div><div class="title">1. Prompt Chaining</div></div></a></div><div><a href="/2025/09/08/Agent/2025-09-08-3_Parallelization/" title="3. Parallelization"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-08</div><div class="title">3. Parallelization</div></div></a></div><div><a href="/2025/09/08/Agent/2025-09-08-4_Reflection/" title="4. Reflection"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-08</div><div class="title">4. Reflection</div></div></a></div><div><a href="/2025/09/08/Agent/2025-09-08-5_Tool_Use/" title="5. Tool_Use"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-08</div><div class="title">5. Tool_Use</div></div></a></div><div><a href="/2025/09/08/Agent/2025-09-08-6_Planning/" title="6. Planning"><img class="cover" src="https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-08</div><div class="title">6. Planning</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ZJN</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">78</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zjn-astonishe"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="/atom.xml" target="_blank" title="RSS链接"><i class="iconfont icon-rss card_icon"></i></a><a class="social-icon" href="https://github.com/zjn-astonishe" target="_blank" title="Github"><i class="iconfont icon-github crad_icon"></i></a><a class="social-icon" href="https://gitee.com/zhang-jianning/" target="_blank" title="Gitee"><i class="iconfont icon-gitee2 card_icon"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=627561610&amp;website=www.oicqzone.com" target="_blank" title=""><i class="iconfont icon-QQ-circle-fill card_icon"></i></a><a class="social-icon" href="mailto:627561610@qq.com" target="_blank" title="Email"><i class="iconfont icon-email-fill card_icon"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Reasoning-Techniques"><span class="toc-text">Reasoning Techniques</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation"><span class="toc-text">Motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Definition"><span class="toc-text">Definition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Template"><span class="toc-text">Template</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Chain-of-Thoughts-CoT"><span class="toc-text">Chain-of-Thoughts (CoT)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tree-of-Thoughts-ToT"><span class="toc-text">Tree-of-Thoughts (ToT)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Self-correction"><span class="toc-text">Self-correction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Program-Aided-Language-Models-PALMs"><span class="toc-text">Program-Aided Language Models (PALMs)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reinforcement-Learning-with-Verifiable-Rewards-RLVR"><span class="toc-text">Reinforcement Learning with Verifiable Rewards (RLVR)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reasoning-and-Acting-ReAct"><span class="toc-text">Reasoning and Acting (ReAct)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Chain-of-Debates-CoD"><span class="toc-text">Chain of Debates (CoD)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graph-of-Debates-GoD"><span class="toc-text">Graph of Debates (GoD)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Research"><span class="toc-text">Deep Research</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-Agent-System-Search-MASS"><span class="toc-text">Multi-Agent System Search (MASS)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Block-Level-Prompt-Optimization"><span class="toc-text">Block-Level Prompt Optimization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Workflow-Topology-Optimization"><span class="toc-text">Workflow Topology Optimization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Workflow-Level-Prompt-Optimization"><span class="toc-text">Workflow-Level Prompt Optimization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Applicable-Scenarios"><span class="toc-text">Applicable Scenarios</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Complex-Question-Answering"><span class="toc-text">Complex Question Answering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mathematical-Problem-Solving"><span class="toc-text">Mathematical Problem Solving</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Debugging-and-Generation"><span class="toc-text">Code Debugging and Generation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Strategic-Planning"><span class="toc-text">Strategic Planning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Medical-Diagnosis"><span class="toc-text">Medical Diagnosis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Legal-Analysis"><span class="toc-text">Legal Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scaling-Inference-Law"><span class="toc-text">Scaling Inference Law</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Coding"><span class="toc-text">Coding</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/14/Agent/2025-09-14-21_Exploration_and_Discovery/" title="21_Exploration_and_Discovery">21_Exploration_and_Discovery</a><time datetime="2025-09-14T05:24:13.000Z" title="发表于 2025-09-14 13:24:13">2025-09-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/14/Agent/2025-09-14-20_Prioritization/" title="20_Prioritization">20_Prioritization</a><time datetime="2025-09-14T05:23:46.000Z" title="发表于 2025-09-14 13:23:46">2025-09-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/14/Agent/2025-09-14-19_Evaluation_and_Monitoring/" title="19_Evaluation_and_Monitoring">19_Evaluation_and_Monitoring</a><time datetime="2025-09-14T05:23:25.000Z" title="发表于 2025-09-14 13:23:25">2025-09-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/" title="18_Guardrails_Safety_Patterns">18_Guardrails_Safety_Patterns</a><time datetime="2025-09-14T05:23:02.000Z" title="发表于 2025-09-14 13:23:02">2025-09-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/" title="17_Reasoning_Techniques">17_Reasoning_Techniques</a><time datetime="2025-09-14T05:22:31.000Z" title="发表于 2025-09-14 13:22:31">2025-09-14</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.3.0/picture/7.png')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By ZJN</div><div class="footer_custom_text">Hi, welcome to my <a href="https://zjn-astonishe.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><div class="aplayer no-destroy" data-id="7307479551" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="list" data-preload="auto" data-autoplay="true" data-volume=0.2></div><div class="Canvas" style="position:fixed; right:0px; bottom:0px;" id="L2dCanvas"></div><script src="https://cdn.jsdelivr.net/npm/promise-polyfill@8/dist/polyfill.min.js"> </script><script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pixi.js@4.6.1/dist/pixi.min.js"></script><script src="https://cdn.jsdelivr.net/gh/zjn-astonishe/CDN@1.2.9/live2dv3.min.js"></script><script>window.onload=()=>{new l2dViewer({width:window.screen.width / 18,height:window.screen.height / 7.5,el:document.getElementById('L2dCanvas'),basePath:'https://cdn.jsdelivr.net/gh/zjn-astonishe/cdn@1.2',modelName:'lafei_4',mobileLimit:true,sizeLimit:true })}</script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script></div></body></html>