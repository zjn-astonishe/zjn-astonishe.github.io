<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZJN_BLOG</title>
  
  
  <link href="http://zjn-astonishe.github.io/atom.xml" rel="self"/>
  
  <link href="http://zjn-astonishe.github.io/"/>
  <updated>2025-09-14T05:24:14.583Z</updated>
  <id>http://zjn-astonishe.github.io/</id>
  
  <author>
    <name>ZJN</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>21_Exploration_and_Discovery</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-21_Exploration_and_Discovery/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-21_Exploration_and_Discovery/</id>
    <published>2025-09-14T05:24:13.000Z</published>
    <updated>2025-09-14T05:24:14.583Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>20_Prioritization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-20_Prioritization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-20_Prioritization/</id>
    <published>2025-09-14T05:23:46.000Z</published>
    <updated>2025-09-14T05:23:48.812Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>19_Evaluation_and_Monitoring</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-19_Evaluation_and_Monitoring/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-19_Evaluation_and_Monitoring/</id>
    <published>2025-09-14T05:23:25.000Z</published>
    <updated>2025-09-14T05:23:26.515Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>18_Guardrails_Safety_Patterns</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/</id>
    <published>2025-09-14T05:23:02.000Z</published>
    <updated>2025-09-14T05:23:03.362Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>17_Reasoning_Techniques</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/</id>
    <published>2025-09-14T05:22:31.000Z</published>
    <updated>2025-09-14T05:22:32.912Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>16_Resource_Aware_Optimization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-16_Resource_Aware_Optimization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-16_Resource_Aware_Optimization/</id>
    <published>2025-09-14T05:22:07.000Z</published>
    <updated>2025-09-14T05:22:07.949Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>15_Inter_Agent_Communication</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-15_Inter_Agent_Communication/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-15_Inter_Agent_Communication/</id>
    <published>2025-09-14T05:21:18.000Z</published>
    <updated>2025-09-14T05:21:19.007Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>14_Knowledge_Retrieval</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-14_Knowledge_Retrieval/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-14_Knowledge_Retrieval/</id>
    <published>2025-09-14T05:20:47.000Z</published>
    <updated>2025-09-14T05:20:48.052Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>13_Human_in_the_Loop</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-13_Human_in_the_Loop/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-13_Human_in_the_Loop/</id>
    <published>2025-09-14T05:20:17.000Z</published>
    <updated>2025-09-14T05:20:18.256Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>12_Exception_Handling_and_Recovery</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-12_Exception_Handling_and_Recovery/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-12_Exception_Handling_and_Recovery/</id>
    <published>2025-09-14T05:19:57.000Z</published>
    <updated>2025-09-14T05:19:57.771Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>11_Goal_Setting_and_Monitoring</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-11_Goal_Setting_and_Monitoring/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-11_Goal_Setting_and_Monitoring/</id>
    <published>2025-09-14T05:19:30.000Z</published>
    <updated>2025-09-14T05:19:30.642Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>10_Model_Context_Protocol</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-10_Model_Context_Protocol/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-10_Model_Context_Protocol/</id>
    <published>2025-09-14T05:19:08.000Z</published>
    <updated>2025-09-14T05:19:08.820Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>9_Learning_and_Adaptation</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-9_Learning_and_Adaptation/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-9_Learning_and_Adaptation/</id>
    <published>2025-09-14T05:18:40.000Z</published>
    <updated>2025-09-14T05:18:41.124Z</updated>
    
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>8. Memory Management</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-8_Memory_Management/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-8_Memory_Management/</id>
    <published>2025-09-14T05:17:58.000Z</published>
    <updated>2025-09-14T08:32:04.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Agentic systems need to remember information from past interactions to perform complex tasks and provide coherent experiences. </p><p>Without a memory mechanism, agents are stateless, unable to maintain conversational context, learn from experience, or personalize responses for users. </p><p>This fundamentally limits them to simple, one-shot interactions, failing to handle multi-step processes or evolving user needs. </p><p>The core problem is how to effectively manage both the immediate, temporary information of a single conversation and the vast, persistent knowledge gathered over time.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>In agent systems, memory refers to an agent’s ability to retain and utilize information from past interactions, observations, and learning experiences. This capability allows agents to make informed decisions, maintain conversational context, and improve over time.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>Agent memory is generally categorized into two main types:</p><ul><li>Short-Term Memory (Contextual Memory):<ul><li>This memory holds information currently being processed or recently accessed.</li><li>This memory primarily exists within the context window which contains recent messages, agent replies, tool usage results, and agent reflections from the current interaction. All inform the LLM’s subsequent responses and actions. </li><li>The context window has a limited capacity, restricting the amount of recent information an agent can directly access. <ul><li>Efficient short-term memory management involves keeping the most relevant information within this limited space, summarizing older conversation segments or emphasizing key details.</li><li>Long Context windows simply expands the size of this short-term memory, allowing more information to be held within a single interaction.</li></ul></li><li>However, it is still ephemeral and is lost once the session concludes, and it can be costly and inefficient to process every time. </li></ul></li><li>Long-Term Memory (Persistent Memory):<ul><li>This memory acts as a repository for information agents need to retain across various interactions, tasks or extended periods, akin to long-term knowledge bases.<ul><li>Data is typically stored outside the agent’s immediate processing environment, often in databases, knowledge graphs, or vector databases.</li><li>In vector databases, information is converted into numerical vectors and stored, enabling agents to retrieve data based on semantic similarity rather than exact keyword matches, a process known as semantic search.</li></ul></li><li>When an agent needs information from long-term memory, it queries the external storage, retrieves relevant data, and integrates it into the short-term context for immediate use, thus combining prior knowledge with the current interaction.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when an agent needs to do more than answer a single question. It is essential for agents that must maintain context throughout a conversation, track progress in multi-step tasks, or personalize interactions by recalling user preferences and history. Implement memory management whenever the agent is expected to learn or adapt based on past successes, failures, or newly acquired information.</p><ul><li>Chatbots and Conversational AI</li><li>Task-Oriented Agents</li><li>Personalized Experiences</li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Agentic frameworks like the Google ADK provide specific components to manage this, such as Session for the conversation thread and State for its temporary data. A dedicated MemoryService is used to interface with the long-term knowledge base, allowing the agent to retrieve and incorporate relevant past information into its current context.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Memory-Management&quot;&gt;&lt;a href=&quot;#Memory-Management&quot; class=&quot;headerlink&quot; title=&quot;Memory Management&quot;&gt;&lt;/a&gt;Memory Management&lt;/h1&gt;&lt;h2 id=&quot;Motiv</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>7. Multi-Agent Collaboration</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-7_Multi_Agent_Collaboration/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-7_Multi_Agent_Collaboration/</id>
    <published>2025-09-08T09:26:13.000Z</published>
    <updated>2025-09-13T05:23:13.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Multi-Agent-Collaboration"><a href="#Multi-Agent-Collaboration" class="headerlink" title="Multi-Agent Collaboration"></a>Multi-Agent Collaboration</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problems often exceed the capabilities of a single, monolithic LLM-based agent. A solitary agent may lack the diverse, specialized skills or access to the specific tools needed to address all parts of a multifaceted task. This limitation creates a bottleneck, reducing the system’s overall effectiveness and scalability. As a result, tackling sophisticated, multi-domain objectives becomes inefficient and can lead to incomplete or suboptimal outcomes.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Multi-Agent Collaboration pattern offers a standardized solution by creating a system of multiple, cooperating agents. </p><p>A complex problem is broken down into smaller, more manageable sub-problems. Each sub-problem is then assigned to a specialized agent with the precise tools and capabilities required to solve it. </p><p>The efficacy of such a system is not merely due to the division of labor but is critically dependent on the mechanisms for inter-agent communication. These agents work together through defined communication protocols and shared ontology, allowing agents to exchange data, delegate sub-tasks, and coordinate their actions to ensure the final output is coherent.</p><p>This agentic, distributed approach creates a synergistic effect, allowing the group to achieve outcomes that would be impossible for any single agent.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p><img src="" alt="img"></p><p>A multi-agent system fundamentally comprises the delineation of agent roles and responsibilities, the establishment of communication channels through which agents exchange information, and the formulation of a task flow or interaction protocol that directs their collaborative endeavors.</p><ul><li>A complex research query might be decomposed and assigned to a Research Agent for information retrieval, </li><li>A Data Analysis Agent for statistical processing, </li><li>A Synthesis Agent for generating the final report.</li></ul><h3 id="Collaboration-Pattern"><a href="#Collaboration-Pattern" class="headerlink" title="Collaboration Pattern"></a>Collaboration Pattern</h3><p>Collaboration can take various forms: </p><ul><li>Sequential Handoffs: One agent completes a task and passes its output to another agent for the next step in a pipeline (similar to the <a href="">Planning</a>, but explicitly involving different agents).</li><li>Parallel Processing: Multiple agents work on different parts of a problem simultaneously, and their results are later combined.</li><li>Debate and Consensus: Multi-Agent Collaboration where Agents with varied perspectives and information sources engage in discussions to evaluate options, ultimately reaching a consensus or a more informed decision.</li><li>Hierarchical Structures: A manager agent might delegate tasks to worker agents dynamically based on their tool access or plugin capabilities and synthesize their results. Each agent can also handle relevant groups of tools, rather than a single agent handling all the tools.</li><li>Expert Teams: Agents with specialized knowledge in different domains (e.g., a researcher, a writer, an editor) collaborate to produce a complex output.</li><li>Critic-Reviewer: Agents create initial outputs such as plans, drafts, or answers. A second group of agents then critically assesses this output for adherence to policies, security, compliance, correctness, quality, and alignment with organizational objectives. The original creator or a final agent revises the output based on the feedback. <ul><li>This pattern is particularly effective for code generation, research writing, logic checking, and ensuring ethical alignment. </li><li>The advantages of this approach include increased robustness, improved quality, and a reduced likelihood of hallucinations or errors.</li></ul></li></ul><h3 id="Collaboration-Architecture"><a href="#Collaboration-Architecture" class="headerlink" title="Collaboration Architecture"></a>Collaboration Architecture</h3><ul><li>Single Agent: <ul><li>At the most basic level, a “Single Agent” operates autonomously without direct interaction or communication with other entities.</li><li>It is suitable for tasks that are decomposable into independent sub-problems, each solvable by a single, self-sufficient agent.</li><li>While this method is straightforward to implement and manage, its capabilities are inherently limited by the individual agent’s scope and resources.</li></ul></li><li>Network:<ul><li>The “Network” represents a significant step towards collaboration, where multiple agents interact directly with each other in a decentralized fashion.</li><li>Communication typically occurs peer-to-peer, allowing for the sharing of information, resources, and even tasks.</li><li>This method fosters resilience, as the failure of one agent does not necessarily cripple the entire system.</li><li>However, managing communication overhead and ensuring coherent decision-making in a large, unstructured network can be challenging.</li></ul></li><li>Supervisor (Agent version):<ul><li>A dedicated agent as “supervisor”, oversees and coordinates the activities of a group of subordinate agents.</li><li>The supervisor acts as a central hub for communication, task allocation, and conflict resolution.</li><li>This hierarchical structure offers clear lines of authority and can simplify management and control.</li><li>However, it introduces a single point of failure (the supervisor) and can become a bottleneck if the supervisor is overwhelmed by a large number of subordinates or complex tasks.</li></ul></li><li>Supervisor (Tool version): <ul><li>The supervisor’s role is less about direct command and control and more about providing resources, guidance, or analytical support to other agents, aiming to leverage the supervisor’s capabilities without imposing rigid top-down control.</li></ul></li><li>Hierarchical:<ul><li>This method expands upon the supervisor concept to create a multi-layered organizational structure. </li><li>This involves multiple levels of supervisors, with higher-level supervisors overseeing lower-level ones, and ultimately, a collection of operational agents at the lowest tier.</li><li>This structure is well-suited for complex problems that can be decomposed into sub-problems, each managed by a specific layer of the hierarchy. </li></ul></li><li>Custom:<ul><li>This method represents the ultimate flexibility in multi-agent system design. </li><li>It allows for the creation of unique interrelationship and communication structures tailored precisely to the specific requirements of a given problem or application. It requires careful consideration of communication protocols, coordination mechanisms, and emergent behaviors.</li><li>This can involve hybrid approaches that combine elements from the previously mentioned models, or entirely novel designs that emerge from the unique constraints and opportunities of the environment.</li><li>Custom models often arise from the need to optimize for specific performance metrics, handle highly dynamic environments, or incorporate domain-specific knowledge into the system’s architecture.</li></ul></li></ul><p><img src="" alt="img"></p><p>Each method offers distinct advantages and disadvantages, and the optimal choice depends on factors such as the complexity of the task, the number of agents, the desired level of autonomy, the need for robustness, and the acceptable communication overhead. </p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when a task is too complex for a single agent and can be decomposed into distinct sub-tasks requiring specialized skills or tools. </p><p>It is ideal for problems that benefit from diverse expertise, parallel processing, or a structured workflow with multiple stages, such as complex research and analysis, software development, or creative content generation.</p><h3 id="Complex-Research-and-Analysis"><a href="#Complex-Research-and-Analysis" class="headerlink" title="Complex Research and Analysis"></a>Complex Research and Analysis</h3><p>This mirrors how a human research team might operate:</p><ul><li>One agent might specialize in searching academic databases, </li><li>Another in summarizing findings, </li><li>A third in identifying trends, </li><li>A fourth in synthesizing the information into a report. </li></ul><h3 id="Software-Development"><a href="#Software-Development" class="headerlink" title="Software Development"></a>Software Development</h3><p>This mirrors how a human software team might operate:</p><ul><li>One agent could be a requirement analyst, </li><li>Another a code generator,</li><li>A third a tester,</li><li>A fourth a documentation writer</li></ul><h3 id="Creative-Content-Generation"><a href="#Creative-Content-Generation" class="headerlink" title="Creative Content Generation"></a>Creative Content Generation</h3><p>Creating a marketing campaign could involve:</p><ul><li>A market research agent, </li><li>A copywriter agent, </li><li>A graphic design agent which use image generation tools,</li><li>A social media scheduling agent </li></ul><h3 id="Financial-Analysis"><a href="#Financial-Analysis" class="headerlink" title="Financial Analysis"></a>Financial Analysis</h3><p>This might specialize in:</p><ul><li>Fetching stock data,</li><li>Analyzing news sentiment, </li><li>Performing technical analysis, </li><li>Generating investment recommendations</li></ul><h3 id="Customer-Support-Escalation"><a href="#Customer-Support-Escalation" class="headerlink" title="Customer Support Escalation"></a>Customer Support Escalation</h3><p>A front-line support agent can handle:</p><ul><li>Initial queries,</li><li>Escalating complex issues to a specialist agent (e.g., a technical expert or a billing specialist) when needed, demonstrating a sequential handoff based on problem complexity.</li></ul><h3 id="Supply-Chain-Optimization"><a href="#Supply-Chain-Optimization" class="headerlink" title="Supply Chain Optimization"></a>Supply Chain Optimization</h3><p>Agents could represent different nodes in a supply chain:</p><ul><li>Suppliers,</li><li>Manufacturers,</li><li>Distributors</li></ul><p>They Collaborate to optimize:</p><ul><li>Inventory levels,</li><li>Logistics,</li><li>Scheduling</li></ul><h3 id="Network-Analysis-amp-Remediation"><a href="#Network-Analysis-amp-Remediation" class="headerlink" title="Network Analysis &amp; Remediation"></a>Network Analysis &amp; Remediation</h3><p>Multiple agents can collaborate to triage and remediate issues, suggesting optimal actions.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Frameworks such as Crew AI and Google ADK are engineered to facilitate this paradigm by providing structures for the specification of agents, tasks, and their interactive procedures. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Multi-Agent-Collaboration&quot;&gt;&lt;a href=&quot;#Multi-Agent-Collaboration&quot; class=&quot;headerlink&quot; title=&quot;Multi-Agent Collaboration&quot;&gt;&lt;/a&gt;Multi-Agent</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>6. Planning</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-6_Planning/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-6_Planning/</id>
    <published>2025-09-08T09:25:51.000Z</published>
    <updated>2025-09-12T03:10:18.390Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Planning"><a href="#Planning" class="headerlink" title="Planning"></a>Planning</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problems often cannot be solved with a single action and require foresight to achieve a desired outcome. Without a structured approach, an agentic system struggles to handle multifaceted requests that involve multiple steps and dependencies. This makes it difficult to break down high-level objectives into a manageable series of smaller, executable tasks. Consequently, the system fails to strategize effectively, leading to incomplete or incorrect results when faced with intricate goals.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Planning pattern offers a standardized solution by having an agentic system first create a coherent plan to address a goal. It involves decomposing a high-level objective into a sequence of smaller, actionable steps or sub-goals. This allows the system to manage complex workflows, orchestrate various tools, and handle dependencies in a logical order. LLMs are particularly well-suited for this, as they can generate plausible and effective plans based on their vast training data. This structured approach transforms a simple reactive agent into a strategic executor that can proactively work towards a complex objective and even adapt its plan if necessary.</p><p>The efficiency of this approach stems from the automation of the iterative search-and-filter cycle, which is a core bottleneck in manual research. </p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when a user’s request is too complex to be handled by a single action or tool. It is ideal for automating multi-step processes, such as generating a detailed research report, onboarding a new employee, or executing a competitive analysis. Apply the Planning pattern whenever a task requires a sequence of interdependent operations to reach a final, synthesized outcome.</p><ul><li>In domains such as procedural task automation, planning is used to orchestrate complex workflows.</li><li>Within robotics and autonomous navigation, planning is fundamental for state-space traversal. </li><li>Planning is also critical for structured information synthesis.</li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Google Deep Research is an agent analyzing on our behalf sources obtained using Google Search as a tool. It reflects, plans, and executes</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Planning&quot;&gt;&lt;a href=&quot;#Planning&quot; class=&quot;headerlink&quot; title=&quot;Planning&quot;&gt;&lt;/a&gt;Planning&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>5. Tool_Use</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-5_Tool_Use/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-5_Tool_Use/</id>
    <published>2025-09-08T09:25:34.000Z</published>
    <updated>2025-09-11T03:28:24.336Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tool-Use-Function-Calling"><a href="#Tool-Use-Function-Calling" class="headerlink" title="Tool Use (Function Calling)"></a>Tool Use (Function Calling)</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>LLMs are powerful text generators, but they are fundamentally disconnected from the outside world. Their knowledge is static, limited to the data they were trained on, and they lack the ability to perform actions or retrieve real-time information. This inherent limitation prevents them from completing tasks that require interaction with external APIs, databases, or services. Without a bridge to these external systems, their utility for solving real-world problems is severely constrained.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>The Tool Use pattern, often implemented through a mechanism called Function Calling, enables an agent to interact with external APIs, databases, services, or even execute code. It allows the LLM at the core of the agent to decide when and how to use a specific external function based on the user’s request or the current state of the task.</p><p>A “tool” can be a traditional function, but it can also be a complex API endpoint, a request to a database, or even an instruction directed at another specialized agent. </p><p>Tool Use is a cornerstone pattern for building powerful, interactive, and externally aware agents.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The process typically involves the following steps:</p><ul><li>Tool Definition: <ul><li>External functions or capabilities are defined and described to the LLM. This description includes the function’s purpose, its name, and the parameters it accepts, along with their types and descriptions.</li></ul></li><li>LLM Decision:<ul><li>The LLM receives the user’s request and the available tool definitions. Based on its understanding of the request and the tools, the LLM decides if calling one or more tools is necessary to fulfill the request.</li></ul></li><li>Function Call Generation:<ul><li>If the LLM decides to use a tool, it generates a structured output (often a JSON object) that specifies the name of the tool to call and the arguments (parameters) to pass to it, extracted from the user’s request.</li></ul></li><li>Tool Execution:<ul><li>The agentic framework or orchestration layer intercepts this structured output. It identifies the requested tool and executes the actual external function with the provided arguments.</li></ul></li><li>Observation/Result:<ul><li>The output or result from the tool execution is returned to the agent.</li></ul></li><li>LLM Processing:<ul><li>The LLM receives the tool’s output as context and uses it to formulate a final response to the user or decide on the next step in the workflow (which might involve calling another tool, reflecting, or providing a final answer).</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>The Tool Use pattern is applicable in virtually any scenario where an agent needs to go beyond generating text to perform an action or retrieve specific, dynamic information. This is essential for tasks requiring real-time data (e.g., checking weather, stock prices), accessing private or proprietary information (e.g., querying a company’s database), performing precise calculations, executing code, or triggering actions in other systems (e.g., sending an email, controlling smart devices).</p><h3 id="Information-Retrieval-from-External-Sources"><a href="#Information-Retrieval-from-External-Sources" class="headerlink" title="Information Retrieval from External Sources"></a>Information Retrieval from External Sources</h3><p>Accessing real-time data or information that is not present in the LLM’s training data. </p><ul><li>Weather Agent:<ul><li>Tool: A weather API that takes a location and returns the current weather conditions.</li><li>Workflow: User asks, “What’s the weather in London?”, LLM identifies the need for the weather tool, calls the tool with “London”, tool returns data, LLM formats the data into a user-friendly response.</li></ul></li></ul><h3 id="Interacting-with-Databases-and-APIs"><a href="#Interacting-with-Databases-and-APIs" class="headerlink" title="Interacting with Databases and APIs"></a>Interacting with Databases and APIs</h3><p>Performing queries, updates, or other operations on structured data.</p><ul><li>E-commerce Agent:<ul><li>Tool: API calls to check product inventory, get order status, or process payments.</li><li>Workflow: User asks “Is product X in stock?”, LLM calls the inventory API, tool returns stock count, LLM tells the user the stock status.</li></ul></li></ul><h3 id="Performing-Calculations-and-Data-Analysis"><a href="#Performing-Calculations-and-Data-Analysis" class="headerlink" title="Performing Calculations and Data Analysis"></a>Performing Calculations and Data Analysis</h3><p>Using external calculators, data analysis libraries, or statistical tools.</p><ul><li>Financial Agent:<ul><li>Tools: A calculator function, a stock market data API, a spreadsheet tool.</li><li>Workflow: User asks “What’s the current price of AAPL and calculate the potential profit if I bought 100 shares at $150?”, LLM calls stock API, gets current price, then calls calculator tool, gets result, formats response.</li></ul></li></ul><h3 id="Sending-Communications"><a href="#Sending-Communications" class="headerlink" title="Sending Communications"></a>Sending Communications</h3><p>Sending emails, messages, or making API calls to external communication services.</p><ul><li>Personal Assistant Agent: <ul><li>Tools: An email sending API.</li><li>Workflow: User says, “Send an e-mail to John about the meeting tomorrow.”, LLM calls an email tool with the recipient, subject, and body extracted from the request.</li></ul></li></ul><h3 id="Executing-Code"><a href="#Executing-Code" class="headerlink" title="Executing Code"></a>Executing Code</h3><p>Running code snippets in a safe environment to perform specific tasks.</p><ul><li>Coding Assistant Agent: <ul><li>Tools: A coding interpreter.</li><li>Workflow: User provides a Python snippet and asks, “What does this code do?”, LLM uses the interpreter tool to run the code and analyze its output.</li></ul></li></ul><h3 id="Controlling-Other-Systems-or-Devices"><a href="#Controlling-Other-Systems-or-Devices" class="headerlink" title="Controlling Other Systems or Devices"></a>Controlling Other Systems or Devices</h3><p>Interacting with smart home devices, IoT platforms, or other connected systems.</p><ul><li>Smart Home Assistant Agent:<ul><li>Tools: An API to control smart lights.</li><li>Workflow: User says, “Turn off the living room lights”, LLM calls the smart home tool with the command and target device.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The implementation of tool use within the LangChain framework is a two-stage process.</p><ul><li>Initially, one or more tools are defined, typically by encapsulating existing Python functions or other runnable components. </li><li>Subsequently, these tools are bound to a language model, thereby granting the model the capability to generate a structured tool-use request when it determines that an external function call is required to fulfill a user’s query.</li></ul><p>LangChain simplifies tool definition using the @tool decorator and provides create_tool_calling_agent and AgentExecutor for building tool-using agents.</p><p>Google ADK has a number of very useful pre-built tools such as Google Search, Code Execution and Vertex AI Search Tool.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Tool-Use-Function-Calling&quot;&gt;&lt;a href=&quot;#Tool-Use-Function-Calling&quot; class=&quot;headerlink&quot; title=&quot;Tool Use (Function Calling)&quot;&gt;&lt;/a&gt;Tool Use </summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>4. Reflection</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-4_Reflection/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-4_Reflection/</id>
    <published>2025-09-08T09:25:16.000Z</published>
    <updated>2025-09-10T03:30:28.817Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Reflection"><a href="#Reflection" class="headerlink" title="Reflection"></a>Reflection</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>An agent’s initial output is often suboptimal, suffering from inaccuracies, incompleteness, or a failure to meet complex requirements. Basic agentic workflows lack a built-in process for the agent to recognize and fix its own errors. This is solved by having the agent evaluate its own work or, more robustly, by introducing a separate logical agent to act as a critic, preventing the initial response from being the final one regardless of quality.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Reflection pattern involves an agent evaluating its own work, output, or internal state and using that evaluation to improve its performance or refine its response. It’s a form of self-correction or self-improvement, allowing the agent to iteratively refine its output or adjust its approach based on feedback, internal critique, or comparison against desired criteria. Reflection can occasionally be facilitated by a separate agent whose specific role is to analyze the output of an initial agent.</p><p><img src="" alt="img"></p><p>The intersection of reflection with goal setting and monitoring (See <a href="#">Chapter 11</a>) is worth noticing. A goal provides the ultimate benchmark for the agent’s self-evaluation, while monitoring tracks its progress. This synergy transforms the agent from a passive executor into a purposeful system that adaptively works to achieve its objectives.</p><p>Furthermore, the effectiveness of the Reflection pattern is significantly enhanced when the LLM keeps a memory of the conversation (see <a href="#">Chapter 8</a>). This conversational history provides crucial context for the evaluation phase, allowing the agent to assess its output not just in isolation, but against the backdrop of previous interactions, user feedback, and evolving goals. It enables the agent to learn from past critiques and avoid repeating errors. Without memory, each reflection is a self-contained event; with memory, reflection becomes a cumulative process where each cycle builds upon the last, leading to more intelligent and context-aware refinement.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The Reflection pattern introduces a feedback loop. The agent doesn’t just produce an output; it then examines that output (or the process that generated it), identifies potential issues or areas for improvement, and uses those insights to generate a better version or modify its future actions.</p><p>The workflow is as follows:</p><ul><li>Execution: <ul><li>The agent performs a task or generates an initial output.</li></ul></li><li>Evaluation/Critique: <ul><li>The agent (often using another LLM call or a set or rules) analyzes the result from the previous step. This evaluation might check for factual accuracy, coherence, style, completeness, adherence to instructions, or other relevant criteria.</li></ul></li><li>Reflection/Refinement: <ul><li>Based on the critique, the agent determines how to improve. This might involve generating a refined output, adjusting parameters for a subsequent step, or even modifying the overall plan.</li></ul></li><li>Iteration (Optional but common): <ul><li>The refined output or adjusted approach can then be executed, and the reflection process can repeat until a satisfactory result is achieved, or a stopping condition is met.</li></ul></li></ul><p>A key and highly effective implementation of the Reflection pattern separates the process into two distinct logical roles: a Producer and a Critic. This is often called the “Generator-Critic” or “Producer-Reviewer” model. While a single agent can perform self-reflection, using two specialized agents (or two separate LLM calls with distinct system prompts) often yields more robust and unbiased results.</p><ul><li>The Producer Agent:<ul><li>This agent’s primary responsibility is to perform the initial execution of the task. It focuses entirely on generating the content, whether it’s writing code, drafting a blog post, or creating a plan. It takes the initial prompt and produces the first version of the output.</li></ul></li><li>The Critic Agent:<ul><li>This agent’s sole purpose is to evaluate the output generated by the Producer. It is given a different set of instructions, often a distinct persona (e.g., “You are a senior software engineer,” “You are a meticulous fact-checker”). The Critic’s instructions guide it to analyze the Producer’s work against specific criteria, such as factual accuracy, code quality, stylistic requirements, or completeness. It is designed to find flaws, suggest improvements, and provide structured feedback.</li></ul></li></ul><p>This separation of concerns is powerful because it prevents the “cognitive bias” of an agent reviewing its own work. The Critic agent approaches the output with a fresh perspective, dedicated entirely to finding errors and areas for improvement. The feedback from the Critic is then passed back to the Producer agent, which uses it as a guide to generate a new, refined version of the output. </p><p>Reflection adds a layer of meta-cognition to agentic systems, enabling them to learn from their own outputs and processes, leading to more intelligent, reliable, and high-quality results.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>The Reflection pattern is valuable in scenarios where output quality, accuracy, or adherence to complex constraints is critical. </p><h3 id="Creative-Writing-and-Content-Creation"><a href="#Creative-Writing-and-Content-Creation" class="headerlink" title="Creative Writing and Content Creation"></a>Creative Writing and Content Creation</h3><p>Refining generated text, stories, poems, or marketing copy.</p><ul><li>Reflection Tasks: Generate a draft, critique it for flow, tone, and clarity, then rewrite based on the critique. Repeat until the post meets quality standards.</li></ul><h3 id="Code-Generation-and-Debugging"><a href="#Code-Generation-and-Debugging" class="headerlink" title="Code Generation and Debugging"></a>Code Generation and Debugging</h3><p>Writing code, identifying errors, and fixing them.</p><ul><li>Reflection Tasks: Write initial code, run tests or static analysis, identify errors or inefficiencies, then modify the code based on the findings.</li></ul><h3 id="Complex-Problem-Solving"><a href="#Complex-Problem-Solving" class="headerlink" title="Complex Problem Solving"></a>Complex Problem Solving</h3><p>Evaluating intermediate steps or proposed solutions in multi-step reasoning tasks.</p><ul><li>Reflection Tasks: Propose a step, evaluate if it leads closer to the solution or introduces contradictions, backtrack or choose a different step if needed.</li></ul><h3 id="Summarization-and-Information-Synthesis"><a href="#Summarization-and-Information-Synthesis" class="headerlink" title="Summarization and Information Synthesis"></a>Summarization and Information Synthesis</h3><p>Refining summaries for accuracy, completeness, and conciseness. </p><ul><li>Reflection Tasks: Generate an initial summary, compare it against key points in the original document, refine the summary to include missing information or improve accuracy. </li></ul><h3 id="Planning-and-Strategy"><a href="#Planning-and-Strategy" class="headerlink" title="Planning and Strategy"></a>Planning and Strategy</h3><p>Evaluating a proposed plan and identifying potential flaws or improvements.</p><ul><li>Reflection Tasks: Generate a plan, simulate its execution or evaluate its feasibility against constraints, revise the plan based on the evaluation.</li></ul><h3 id="Conversational-Agents"><a href="#Conversational-Agents" class="headerlink" title="Conversational Agents"></a>Conversational Agents</h3><p>Reviewing previous turns in a conversation to maintain context, correct misunderstandings, or improve response quality.</p><ul><li>Reflection Tasks: After a user response, review the conversation history and the last generated message to ensure coherence and address the user’s latest input accurately.</li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The provided LangChain and ADK code examples both implement this two-agent model: the LangChain example uses a specific “reflector_prompt” to create a critic persona, while the ADK example explicitly defines a producer and a reviewer agent. While a single step of evaluation and refinement can be implemented within either a LangChain/LangGraph, or ADK, or Crew.AI chain, true iterative reflection typically involves more complex orchestration.</p><h2 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages"></a>Disadvantages</h2><p>The iterative process, though powerful, can lead to higher costs and latency, since every refinement loop may require a new LLM call, making it suboptimal for time-sensitive applications. Furthermore, the pattern is memory-intensive; with each iteration, the conversational history expands, including the initial output, critique, and subsequent refinements.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Reflection&quot;&gt;&lt;a href=&quot;#Reflection&quot; class=&quot;headerlink&quot; title=&quot;Reflection&quot;&gt;&lt;/a&gt;Reflection&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>3. Parallelization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-3_Parallelization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-3_Parallelization/</id>
    <published>2025-09-08T08:04:45.000Z</published>
    <updated>2025-09-10T03:22:26.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parallelization"><a href="#Parallelization" class="headerlink" title="Parallelization"></a>Parallelization</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Many complex agentic tasks involve multiple sub-tasks that can be executed simultaneously rather than one after another. A purely sequential execution, where each task waits for the previous one to finish, is often inefficient and slow. This latency becomes a significant bottleneck when tasks depend on external I/O operations, such as calling different APIs or querying multiple databases. Without a mechanism for concurrent execution, the total processing time is the sum of all individual task durations, hindering the system’s overall performance and responsiveness.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>Parallelization involves executing multiple components, such as LLM calls, tool usages, or even entire sub-agents, concurrently. Instead of waiting for one step to complete before starting the next, parallel execution allows independent tasks to run at the same time, significantly reducing the overall execution time for tasks that can be broken down into independent parts.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The core idea is to identify parts of the workflow that do not depend on the output of other parts and execute them in parallel. </p><p>Implementing parallelization often requires frameworks that support asynchronous execution or multi-threading/multi-processing. Modern agentic frameworks are designed with asynchronous operations in mind, allowing you to easily define steps that can run in parallel.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>This is particularly effective when dealing with external services (like APIs or databases) that have latency, as you can issue multiple requests concurrently.</p><h3 id="Information-Gathering-and-Research"><a href="#Information-Gathering-and-Research" class="headerlink" title="Information Gathering and Research"></a>Information Gathering and Research</h3><p>Collecting information from multiple sources simultaneously is a classic use case. </p><ul><li>Parallel Tasks: execute below all at the same time.<ul><li>Search news articles</li><li>Pull stock data</li><li>Check social media mentions</li><li>Query a company database</li></ul></li></ul><h3 id="Data-Processing-and-Analysis"><a href="#Data-Processing-and-Analysis" class="headerlink" title="Data Processing and Analysis"></a>Data Processing and Analysis</h3><p>Applying different analysis techniques or processing different data segments concurrently. </p><ul><li>Parallel Tasks: execute across a batch of feedback entries simultaneously.<ul><li>Run sentiment analysis</li><li>Extract keywords</li><li>Categorize feedback</li><li>Identify urgent issues</li></ul></li></ul><h3 id="Multi-API-or-Tool-Interaction"><a href="#Multi-API-or-Tool-Interaction" class="headerlink" title="Multi-API or Tool Interaction"></a>Multi-API or Tool Interaction</h3><p>Calling multiple independent APIs or tools to gather different types of information or perform different actions, such as travel planning agent.</p><ul><li>Parallel Tasks: execute below concurrently.<ul><li>Check flight prices</li><li>Search for hotel availability</li><li>Look up local events</li><li>Find restaurant recommendations</li></ul></li></ul><h3 id="Content-Generation-with-Multiple-Components"><a href="#Content-Generation-with-Multiple-Components" class="headerlink" title="Content Generation with Multiple Components"></a>Content Generation with Multiple Components</h3><p>Generating different parts of a complex piece of content in parallel.</p><ul><li>Parallel Tasks:<ul><li>Generate a subject line</li><li>Draft the email body</li><li>Find a relevant image</li><li>Create a call-to-action button text</li></ul></li></ul><h3 id="Validation-and-Verification"><a href="#Validation-and-Verification" class="headerlink" title="Validation and Verification"></a>Validation and Verification</h3><p>Performing multiple independent checks or validations concurrently.</p><ul><li>Parallel Tasks:<ul><li>Check email format</li><li>Validate phone number</li><li>Verify address against a database</li><li>Check for profanity</li></ul></li></ul><h3 id="Multi-Modal-Processing"><a href="#Multi-Modal-Processing" class="headerlink" title="Multi-Modal Processing"></a>Multi-Modal Processing</h3><p>Processing different modalities (text, image, audio) of the same input concurrently.</p><ul><li>Parallel Tasks:<ul><li>Analyze the text for sentiment and keywords</li><li>Analyze the image for objects and scene description</li></ul></li></ul><h3 id="A-B-Testing-or-Multiple-Options-Generation"><a href="#A-B-Testing-or-Multiple-Options-Generation" class="headerlink" title="A/B Testing or Multiple Options Generation"></a>A/B Testing or Multiple Options Generation</h3><p>Generating multiple variations of a response or output in parallel to select the best one.</p><ul><li>Parallel tasks:<ul><li>Generate three different headlines for an article simultaneously using slightly different prompts or models.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Frameworks provide distinct mechanisms for implementing this pattern. In LangChain, constructs like RunnableParallel are used to explicitly define and execute multiple processing chains simultaneously. In contrast, frameworks like the Google Agent Developer Kit (ADK) can achieve parallelization through multi-agent delegation, where a primary coordinator model assigns different sub-tasks to specialized agents that can operate concurrently.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Parallelization&quot;&gt;&lt;a href=&quot;#Parallelization&quot; class=&quot;headerlink&quot; title=&quot;Parallelization&quot;&gt;&lt;/a&gt;Parallelization&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>2. Routing</title>
    <link href="http://zjn-astonishe.github.io/2025/09/07/Agent/2025-09-07-2_Routing/"/>
    <id>http://zjn-astonishe.github.io/2025/09/07/Agent/2025-09-07-2_Routing/</id>
    <published>2025-09-07T09:17:43.000Z</published>
    <updated>2025-09-10T03:22:03.418Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>Real-world agentic systems must often arbitrate between multiple potential actions based on contingent factors, such as the state of the environment, user input, or the outcome of a preceding operation. </p><p>This capacity for dynamic decision-making, which governs the flow of control to different specialized functions, tools, or sub-processes, is achieved through a mechanism known as routing.</p><p>Routing introduces conditional logic into an agent’s operational framework, enabling a shift from a fixed execution path to a model where the agent dynamically evaluates specific criteria to select from a set of possible subsequent actions. This allows for more flexible and context-aware system behavior.</p><p>The implementation of routing enables a system to move beyond deterministic sequential processing. It facilitates the development of more adaptive execution flows that can respond dynamically and appropriately to a wider range of inputs and state changes.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The core component of the Routing pattern is a mechanism that performs the evaluation and directs the flow. This mechanism can be implemented in several ways: </p><ul><li>LLM-based Routing: <ul><li>The language model itself can be prompted to analyze the input and output a specific identifier or instruction that indicates the next step or destination. </li></ul></li><li>Embedding-based Routing: <ul><li>The input query can be converted into a vector embedding. This embedding is then compared to embeddings representing different routes or capabilities. The query is routed to the route whose embedding is most similar. </li><li>This is useful for semantic routing, where the decision is based on the meaning of the input rather than just keywords. </li></ul></li><li>Rule-based Routing: <ul><li>This involves using predefined rules or logic (e.g., if-else statements, switch cases) based on keywords, patterns, or structured data extracted from the input. This can be faster and more deterministic than LLM-based routing, but is less flexible for handling nuanced or novel inputs. </li></ul></li><li>Machine Learning Model-Based Routing: <ul><li>It employs a discriminative model, such as a classifier, that has been specifically trained on a small corpus of labeled data to perform a routing task. </li><li>While it shares conceptual similarities with embedding-based methods, its key characteristic is the supervised fine-tuning process, which adjusts the model’s parameters to create a specialized routing function.</li><li>This technique is also distinct from LLM-based routing because the decision-making component is not a generative model executing a prompt at inference time. Instead, the routing logic is encoded within the fine-tuned model’s learned weights. </li><li>While LLMs may be used in a pre-processing step to generate synthetic data for augmenting the training set, they are not involved in the real-time routing decision itself.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>An agent designed for customer inquiries, when equipped with a routing function, can first classify an incoming query to determine the user’s intent. Based on this classification, it can then direct the query to a specialized agent for direct question-answering:</p><ul><li>Analyze the user’s query.</li><li>Route the query based on its intent:<ul><li>If the intent is “Check order status”, route to a sub-agent or tool chain that interacts with the order database. </li><li>If the intent is “product information”, route to a sub-agent or chain that searches the product catalog.</li><li>If the intent is “technical support”, route to a different chain that accesses troubleshooting guides or escalates to a human.</li><li>If the intent is unclear, route to a clarification sub-agent or prompt chain.</li></ul></li></ul><p>Routing mechanisms can be implemented at multiple junctures within an agent’s operational cycle. </p><ul><li>They can be applied at the outset to classify a primary task, </li><li>at intermediate points within a processing chain to determine a subsequent action, </li><li>or during a subroutine to select the most appropriate tool from a given set.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Routing&quot;&gt;&lt;a href=&quot;#Routing&quot; class=&quot;headerlink&quot; title=&quot;Routing&quot;&gt;&lt;/a&gt;Routing&lt;/h1&gt;&lt;h2 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
</feed>
