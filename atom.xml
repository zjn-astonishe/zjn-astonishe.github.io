<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZJN_BLOG</title>
  
  
  <link href="http://zjn-astonishe.github.io/atom.xml" rel="self"/>
  
  <link href="http://zjn-astonishe.github.io/"/>
  <updated>2025-09-23T09:12:23.212Z</updated>
  <id>http://zjn-astonishe.github.io/</id>
  
  <author>
    <name>ZJN</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>21_Exploration_and_Discovery</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-21_Exploration_and_Discovery/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-21_Exploration_and_Discovery/</id>
    <published>2025-09-14T05:24:13.000Z</published>
    <updated>2025-09-23T09:12:23.212Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Exploration-and-Discovery"><a href="#Exploration-and-Discovery" class="headerlink" title="Exploration and Discovery"></a>Exploration and Discovery</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI agents often operate within predefined knowledge, limiting their ability to tackle novel situations or open-ended problems. In complex and dynamic environments, this static, pre-programmed information is insufficient for true innovation or discovery. </p><p>The fundamental challenge is to enable agents to move beyond simple optimization to actively seek out new information and identify “unknown unknowns.” This necessitates a paradigm shift from purely reactive behaviors to proactive, Agentic exploration that expands the system’s own understanding and capabilities.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Exploration and discovery differ from reactive behaviors or optimization within a predefined solution space. Instead, they focus on agents proactively venturing into unfamiliar territories, experimenting with new approaches, and generating new knowledge or understanding. This pattern is crucial for agents operating in open-ended, complex, or rapidly evolving domains where static knowledge or pre-programmed solutions are insufficient. It emphasizes the agent’s capacity to expand its understanding and capabilities.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Exploration-and-Discovery&quot;&gt;&lt;a href=&quot;#Exploration-and-Discovery&quot; class=&quot;headerlink&quot; title=&quot;Exploration and Discovery&quot;&gt;&lt;/a&gt;Exploration</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>20_Prioritization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-20_Prioritization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-20_Prioritization/</id>
    <published>2025-09-14T05:23:46.000Z</published>
    <updated>2025-09-23T07:15:54.236Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Prioritization"><a href="#Prioritization" class="headerlink" title="Prioritization"></a>Prioritization</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI agents operating in complex environments face a multitude of potential actions, conflicting goals, and finite resources. </p><p>Without a clear method to determine their next move, these agents risk becoming inefficient and ineffective. This can lead to significant operational delays or a complete failure to accomplish primary objectives. </p><p>The core challenge is to manage this overwhelming number of choices to ensure the agent acts purposefully and logically.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Agents employ prioritization to effectively manage tasks, goals, and sub-goals, guiding subsequent actions. This process facilitates informed decision-making when addressing multiple demands, prioritizing vital or urgent activities over less critical ones. It is particularly relevant in real-world scenarios where resources are constrained, time is limited, and objectives may conflict.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The fundamental aspects of agent prioritization typically involve several elements. </p><ul><li>First, criteria definition establishes the rules or metrics for task evaluation. These may include <ul><li>urgency (time sensitivity of the task), </li><li>importance (impact on the primary objective), </li><li>dependencies (whether the task is a prerequisite for others), </li><li>resource availability (readiness of necessary tools or information), </li><li>cost/benefit analysis (effort versus expected outcome), </li><li>user preferences for personalized agents. </li></ul></li><li>Second, task evaluation involves assessing each potential task against these defined criteria, utilizing methods ranging from simple rules to complex scoring or reasoning by LLMs. </li><li>Third, scheduling or selection logic refers to the algorithm that, based on the evaluations, selects the optimal next action or task sequence, potentially utilizing a queue or an advanced planning component. </li><li>Finally, dynamic re-prioritization allows the agent to modify priorities as circumstances change, such as the emergence of a new critical event or an approaching deadline, ensuring agent adaptability and responsiveness.</li></ul><p>Prioritization can occur at various levels: </p><ul><li>Select an overarching objective (high-level goal prioritization), </li><li>Order steps within a plan (sub-task prioritization),</li><li>Choose the next immediate action from available options (action selection). </li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Automated-Customer-Support"><a href="#Automated-Customer-Support" class="headerlink" title="Automated Customer Support"></a>Automated Customer Support</h3><p>Agents prioritize urgent requests, like system outage reports, over routine matters, such as password resets. </p><p>They may also give preferential treatment to high-value customers.</p><h3 id="Cloud-Computing"><a href="#Cloud-Computing" class="headerlink" title="Cloud Computing"></a>Cloud Computing</h3><p>AI manages and schedules resources by prioritizing allocation to critical applications during peak demand, while relegating less urgent batch jobs to off-peak hours to optimize costs.</p><h3 id="Autonomous-Driving-Systems"><a href="#Autonomous-Driving-Systems" class="headerlink" title="Autonomous Driving Systems"></a>Autonomous Driving Systems</h3><p>Continuously prioritize actions to ensure safety and efficiency. For example, braking to avoid a collision takes precedence over maintaining lane discipline or optimizing fuel efficiency.</p><h3 id="Financial-Trading"><a href="#Financial-Trading" class="headerlink" title="Financial Trading"></a>Financial Trading</h3><p>Bots prioritize trades by analyzing factors like market conditions, risk tolerance, profit margins, and real-time news, enabling prompt execution of high-priority transactions.</p><h3 id="Project-Management"><a href="#Project-Management" class="headerlink" title="Project Management"></a>Project Management</h3><p>AI agents prioritize tasks on a project board based on deadlines, dependencies, team availability, and strategic importance.</p><h3 id="Cybersecurity"><a href="#Cybersecurity" class="headerlink" title="Cybersecurity"></a>Cybersecurity</h3><p>Agents monitoring network traffic prioritize alerts by assessing threat severity, potential impact, and asset criticality, ensuring immediate responses to the most dangerous threats.</p><h3 id="Personal-Assistant-AIs"><a href="#Personal-Assistant-AIs" class="headerlink" title="Personal Assistant AIs"></a>Personal Assistant AIs</h3><p>Utilize prioritization to manage daily lives, organizing calendar events, reminders, and notifications according to user-defined importance, upcoming deadlines, and current context.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Prioritization&quot;&gt;&lt;a href=&quot;#Prioritization&quot; class=&quot;headerlink&quot; title=&quot;Prioritization&quot;&gt;&lt;/a&gt;Prioritization&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>19_Evaluation_and_Monitoring</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-19_Evaluation_and_Monitoring/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-19_Evaluation_and_Monitoring/</id>
    <published>2025-09-14T05:23:25.000Z</published>
    <updated>2025-09-23T06:06:57.802Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Evaluation-and-Monitoring"><a href="#Evaluation-and-Monitoring" class="headerlink" title="Evaluation and Monitoring"></a>Evaluation and Monitoring</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Agentic systems and LLMs operate in complex, dynamic environments where their performance can degrade over time. Their probabilistic and non-deterministic nature means that traditional software testing is insufficient for ensuring reliability. </p><p>Evaluating dynamic multi-agent systems is a significant challenge because their constantly changing nature and that of their environments demand the development of adaptive testing methods and sophisticated metrics that can measure collaborative success beyond individual performance. Problems like data drift, unexpected interactions, tool calling, and deviations from intended goals can arise after deployment. </p><p>Continuous assessment is therefore necessary to measure an agent’s effectiveness, efficiency, and adherence to operational and safety requirements.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>A standardized evaluation and monitoring framework provides a systematic way to assess and ensure the ongoing performance of intelligent agents. </p><p>This involves defining clear metrics for accuracy, latency, and resource consumption, like token usage for LLMs. It also includes advanced techniques such as analyzing agentic trajectories to understand the reasoning process and employing an LLM-as-a-Judge for nuanced, qualitative assessments. By establishing feedback loops and reporting systems, this framework allows for continuous improvement, A/B testing, and the detection of anomalies or performance drift, ensuring the agent remains aligned with its objectives.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Agent-Response-Assessment"><a href="#Agent-Response-Assessment" class="headerlink" title="Agent Response Assessment"></a>Agent Response Assessment</h3><p>This core process is essential for evaluating the quality and accuracy of an agent’s outputs. It involves determining if the agent delivers pertinent, correct, logical, unbiased, and accurate information in response to given inputs. Assessment metrics may include factual correctness, fluency, grammatical precision, and adherence to the user’s intended purpose.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_response_accuracy</span>(<span class="params">agent_output: <span class="built_in">str</span>, expected_output: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">   <span class="string">&quot;&quot;&quot;Calculates a simple accuracy score for agent responses.&quot;&quot;&quot;</span></span><br><span class="line">   <span class="comment"># This is a very basic exact match; real-world would use more sophisticated metrics</span></span><br><span class="line">   <span class="keyword">return</span> <span class="number">1.0</span> <span class="keyword">if</span> agent_output.strip().lower() == expected_output.strip().lower() <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">agent_response = <span class="string">&quot;The capital of France is Paris.&quot;</span></span><br><span class="line">ground_truth = <span class="string">&quot;Paris is the capital of France.&quot;</span></span><br><span class="line">score = evaluate_response_accuracy(agent_response, ground_truth)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Response accuracy: <span class="subst">&#123;score&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Some metrics for evaluating agent responses include:</p><ul><li>String Similarity Measures <ul><li>Levenshtein distance </li><li>Jaccard similarity, </li></ul></li><li>Keyword Analysis for the presence or absence of specific keywords, </li><li>Semantic Similarity using cosine similarity with embedding models, </li><li>LLM-as-a-Judge Evaluations </li><li>RAG-specific Metrics<ul><li>faithfulness</li><li>relevance</li></ul></li></ul><h3 id="Latency-Monitoring"><a href="#Latency-Monitoring" class="headerlink" title="Latency Monitoring"></a>Latency Monitoring</h3><p>This process measures the duration required for an agent to process requests and generate outputs.</p><p>Latency Monitoring for Agent Actions is crucial in applications where the speed of an AI agent’s response or action is a critical factor. Elevated latency can adversely affect user experience and the agent’s overall effectiveness, particularly in real-time or interactive environments. </p><p>In practical applications, simply printing latency data to the console is insufficient. Logging this information to a persistent storage system is recommended. Options include </p><ul><li>structured log files (e.g., JSON), </li><li>time-series databases (e.g., InfluxDB, Prometheus), </li><li>data warehouses (e.g., Snowflake, BigQuery, PostgreSQL), </li><li>observability platforms (e.g., Datadog, Splunk, Grafana Cloud).</li></ul><h3 id="Tracking-Token-Usage-for-LLM-Interaction"><a href="#Tracking-Token-Usage-for-LLM-Interaction" class="headerlink" title="Tracking Token Usage for LLM Interaction"></a>Tracking Token Usage for LLM Interaction</h3><p>For LLM-powered agents, tracking token usage is crucial for managing costs and optimizing resource allocation. Billing for LLM interactions often depends on the number of tokens processed (input and output). </p><p>Therefore, efficient token usage directly reduces operational expenses. Additionally, monitoring token counts helps identify potential areas for improvement in prompt engineering or response generation processes.</p><h3 id="Custom-Metric-for-“Helpfulness”-using-LLM-as-a-Judge"><a href="#Custom-Metric-for-“Helpfulness”-using-LLM-as-a-Judge" class="headerlink" title="Custom Metric for “Helpfulness” using LLM-as-a-Judge:"></a>Custom Metric for “Helpfulness” using LLM-as-a-Judge:</h3><p>A potential framework involves using an LLM as an evaluator, which assesses another AI agent’s output based on predefined criteria for “helpfulness.” </p><p>Leveraging the advanced linguistic capabilities of LLMs, this method offers nuanced, human-like evaluations of subjective qualities, surpassing simple keyword matching or rule-based assessments. </p><p>Though in development, this technique shows promise for automating and scaling qualitative evaluations.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Performance-Tracking-in-Live-Systems"><a href="#Performance-Tracking-in-Live-Systems" class="headerlink" title="Performance Tracking in Live Systems"></a>Performance Tracking in Live Systems</h3><p>Continuously monitoring the accuracy, latency, and resource consumption of an agent deployed in a production environment (e.g., a customer service chatbot’s resolution rate, response time).</p><h3 id="A-B-Testing-for-Agent-Improvements"><a href="#A-B-Testing-for-Agent-Improvements" class="headerlink" title="A/B Testing for Agent Improvements"></a>A/B Testing for Agent Improvements</h3><p>Systematically comparing the performance of different agent versions or strategies in parallel to identify optimal approaches (e.g., trying two different planning algorithms for a logistics agent).</p><h3 id="Compliance-and-Safety-Audits"><a href="#Compliance-and-Safety-Audits" class="headerlink" title="Compliance and Safety Audits"></a>Compliance and Safety Audits</h3><p>Generate automated audit reports that track an agent’s compliance with ethical guidelines, regulatory requirements, and safety protocols over time. These reports can be verified by a human-in-the-loop or another agent, and can generate KPIs or trigger alerts upon identifying issues.</p><h3 id="Enterprise-systems"><a href="#Enterprise-systems" class="headerlink" title="Enterprise systems"></a>Enterprise systems</h3><p>To govern Agentic AI in corporate systems, a new control instrument, the AI “Contract,” is needed. This dynamic agreement codifies the objectives, rules, and controls for AI-delegated tasks.</p><h3 id="Drift-Detection"><a href="#Drift-Detection" class="headerlink" title="Drift Detection"></a>Drift Detection</h3><p>Monitoring the relevance or accuracy of an agent’s outputs over time, detecting when its performance degrades due to changes in input data distribution (concept drift) or environmental shifts.</p><h3 id="Anomaly-Detection-in-Agent-Behavior"><a href="#Anomaly-Detection-in-Agent-Behavior" class="headerlink" title="Anomaly Detection in Agent Behavior"></a>Anomaly Detection in Agent Behavior</h3><p>Identifying unusual or unexpected actions taken by an agent that might indicate an error, a malicious attack, or an emergent un-desired behavior.</p><h3 id="Learning-Progress-Assessment"><a href="#Learning-Progress-Assessment" class="headerlink" title="Learning Progress Assessment"></a>Learning Progress Assessment</h3><p>For agents designed to learn, tracking their learning curve, improvement in specific skills, or generalization capabilities over different tasks or data sets.</p><h2 id="Agents-trajectories"><a href="#Agents-trajectories" class="headerlink" title="Agents trajectories"></a>Agents trajectories</h2><p>Evaluating agents’ trajectories is essential, as traditional software tests are insufficient. </p><ul><li>Standard code yields predictable pass/fail results, </li><li>Agents operate probabilistically, necessitating qualitative assessment of both the final output and the agent’s trajectory—the sequence of steps taken to reach a solution.</li></ul><p>Evaluating multi-agent systems is challenging because they are constantly in flux. This requires developing sophisticated metrics that go beyond individual performance to measure the effectiveness of communication and teamwork. </p><p>Moreover, the environments themselves are not static, demanding that evaluation methods, including test cases, adapt over time.</p><p>This involves examining the quality of decisions, the reasoning process, and the overall outcome. </p><p>Implementing automated evaluations is valuable, particularly for development beyond the prototype stage. </p><ul><li>Analyzing trajectory and tool use includes <ul><li>Evaluating the steps an agent employs to achieve a goal, such as <ul><li>tool selection, </li><li>strategies, </li><li>task efficiency. </li></ul></li></ul></li><li>The agent’s actual actions are compared to this expected, or ground truth, trajectory to identify errors and inefficiencies. <ul><li>Comparison methods include <ul><li>exact match (requiring a perfect match to the ideal sequence)</li><li>in-order match (correct actions in order, allowing extra steps)</li><li>any-order match (correct actions in any order, allowing extra steps), </li><li>precision (measuring the relevance of predicted actions),</li><li>recall (measuring how many essential actions are captured), </li><li>single-tool use (checking for a specific action). </li></ul></li><li>Metric selection depends on specific agent requirements, with <ul><li>high-stakes scenarios potentially demanding an exact match, </li><li>while more flexible situations might use an in-order or any-order match.</li></ul></li></ul></li></ul><p>Evaluation of AI agents involves two primary approaches: </p><ul><li>using test files<ul><li>Test files, in JSON format, represent single, simple agent-model interactions or sessions and are ideal for unit testing during active development, focusing on rapid execution and simple session complexity.</li><li>Each test file contains a single session with multiple turns, where a turn is a user-agent interaction including the user’s query, expected tool use trajectory, intermediate agent responses, and final response. </li><li>Test files can be organized into folders and may include a test_config.json file to define evaluation criteria. </li></ul></li><li>using evalset files. <ul><li>Evalset files utilize a dataset called an “evalset” to evaluate interactions, containing multiple potentially lengthy sessions suited for simulating complex, multi-turn conversations and integration tests. </li><li>An evalset file comprises multiple “evals,” each representing a distinct session with one or more “turns” that include user queries, expected tool use, intermediate responses, and a reference final response. </li></ul></li></ul><h3 id="Multi-Agents"><a href="#Multi-Agents" class="headerlink" title="Multi-Agents"></a>Multi-Agents</h3><p>Evaluating a complex AI system with multiple agents is much like assessing a team project. Because there are many steps and handoffs, its complexity is an advantage, allowing you to check the quality of work at each stage. </p><ul><li>You can examine how well each individual “agent” performs its specific job, </li><li>but you must also evaluate how the entire system is performing as a whole.<ul><li>Did they create a good plan and stick to it?</li><li>Is the right agent being chosen for the right task? </li><li>Are the agents cooperating effectively?</li><li>Does adding more agents improve performance?</li></ul></li></ul><h2 id="From-Agents-to-Advanced-Contractors"><a href="#From-Agents-to-Advanced-Contractors" class="headerlink" title="From Agents to Advanced Contractors"></a>From Agents to Advanced Contractors</h2><p>This theory moves from probabilistic, often unreliable systems to more deterministic and accountable ones designed for complex, high-stakes environments.</p><p>Today’s common AI agents operate on brief, underspecified instructions, which makes them suitable for simple demonstrations but brittle in production, where ambiguity leads to failure. The “contractor” model addresses this by establishing a rigorous, formalized relationship between the user and the AI, built upon a foundation of clearly defined and mutually agreed-upon terms, much like a legal service agreement in the human world. </p><p>This transformation is supported by four key pillars that collectively ensure clarity, reliability, and robust execution of tasks that were previously beyond the scope of autonomous systems.</p><ul><li>First is the pillar of the Formalized Contract, a detailed specification that serves as the single source of truth for a task.</li><li>Second is the pillar of a Dynamic Lifecycle of Negotiation and Feedback. The contract is not a static command but the start of a dialogue. The contractor agent can analyze the initial terms and negotiate. This negotiation phase, which also allows the agent to flag ambiguities or potential risks, resolves misunderstandings before execution begins, preventing costly failures and ensuring the final output aligns perfectly with the user’s actual intent.</li><li>The third pillar is Quality-Focused Iterative Execution. Unlike agents designed for low-latency responses, a contractor prioritizes correctness and quality. It operates on a principle of self-validation and correction.</li><li>Finally, the fourth pillar is Hierarchical Decomposition via Subcontracts. For tasks of significant complexity, a primary contractor agent can act as a project manager, breaking the main goal into smaller, more manageable sub-tasks. It achieves this by generating new, formal “subcontracts.”</li></ul><p>Ultimately, this contractor framework reimagines AI interaction by embedding principles of formal specification, negotiation, and verifiable execution directly into the agent’s core logic.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Evaluation-and-Monitoring&quot;&gt;&lt;a href=&quot;#Evaluation-and-Monitoring&quot; class=&quot;headerlink&quot; title=&quot;Evaluation and Monitoring&quot;&gt;&lt;/a&gt;Evaluation </summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>18_Guardrails_Safety_Patterns</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-18_Guardrails_Safety_Patterns/</id>
    <published>2025-09-14T05:23:02.000Z</published>
    <updated>2025-09-22T08:42:08.525Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Guardrails-Safety-Patterns"><a href="#Guardrails-Safety-Patterns" class="headerlink" title="Guardrails: Safety Patterns"></a>Guardrails: Safety Patterns</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>As intelligent agents and LLMs become more autonomous, they might pose risks if left unconstrained, as their behavior can be unpredictable. They can generate harmful, biased, unethical, or factually incorrect outputs, potentially causing real-world damage. These systems are vulnerable to adversarial attacks, such as jailbreaking, which aim to bypass their safety protocols. Without proper controls, agentic systems can act in unintended ways, leading to a loss of user trust and exposing organizations to legal and reputational harm.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Guardrails, also referred to as safety patterns, are crucial mechanisms that ensure intelligent agents operate safely, ethically, and as intended, particularly as these agents become more autonomous and integrated into critical systems. They serve as a protective layer, guiding the agent’s behavior and output to prevent harmful, biased, irrelevant, or otherwise undesirable responses. </p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>These guardrails can be implemented at various stages, including:</p><ul><li>Input Validation/Sanitization to filter malicious content, </li><li>Output Filtering/Post-processing to analyze generated responses for toxicity or bias, </li><li>Behavioral Constraints (Prompt-level) through direct instructions, </li><li>Tool Use Restrictions to limit agent capabilities, </li><li>External Moderation APIs for content moderation, </li><li>Human Oversight/Intervention via “Human-in-the-Loop” mechanisms.</li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Customer-Service-Chatbots"><a href="#Customer-Service-Chatbots" class="headerlink" title="Customer Service Chatbots"></a>Customer Service Chatbots</h3><p>To prevent generation of offensive language, incorrect or harmful advice (e.g., medical, legal), or off-topic responses. Guardrails can detect toxic user input and instruct the bot to respond with a refusal or escalation to a human.</p><h3 id="Content-Generation-Systems"><a href="#Content-Generation-Systems" class="headerlink" title="Content Generation Systems"></a>Content Generation Systems</h3><p>To ensure generated articles, marketing copy, or creative content adheres to guidelines, legal requirements, and ethical standards, while avoiding hate speech, misinformation, or explicit content. Guardrails can involve post-processing filters that flag and redact problematic phrases.</p><h3 id="Educational-Tutors-Assistants"><a href="#Educational-Tutors-Assistants" class="headerlink" title="Educational Tutors/Assistants"></a>Educational Tutors/Assistants</h3><p>To prevent the agent from providing incorrect answers, promoting biased viewpoints, or engaging in inappropriate conversations. This may involve content filtering and adherence to a predefined curriculum.</p><h3 id="Legal-Research-Assistants"><a href="#Legal-Research-Assistants" class="headerlink" title="Legal Research Assistants"></a>Legal Research Assistants</h3><p>To prevent the agent from providing definitive legal advice or acting as a substitute for a licensed attorney, instead guiding users to consult with legal professionals.</p><h3 id="Recruitment-and-HR-Tools"><a href="#Recruitment-and-HR-Tools" class="headerlink" title="Recruitment and HR Tools"></a>Recruitment and HR Tools</h3><p>To ensure fairness and prevent bias in candidate screening or employee evaluations by filtering discriminatory language or criteria.</p><h3 id="Social-Media-Content-Moderation"><a href="#Social-Media-Content-Moderation" class="headerlink" title="Social Media Content Moderation"></a>Social Media Content Moderation</h3><p>To automatically identify and flag posts containing hate speech, misinformation, or graphic content.</p><h3 id="Scientific-Research-Assistants"><a href="#Scientific-Research-Assistants" class="headerlink" title="Scientific Research Assistants"></a>Scientific Research Assistants</h3><p>To prevent the agent from fabricating research data or drawing unsupported conclusions, emphasizing the need for empirical validation and peer review.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><ul><li>Modularity and Separation of Concerns: <ul><li>A monolithic, do-everything agent is brittle and difficult to debug. The best practice is to design a system of smaller, specialized agents or tools that collaborate.</li></ul></li><li>Observability through Structured Logging: <ul><li>A reliable system is one you can understand. For agents, this means implementing deep observability. Instead of just seeing the final output, engineers need structured logs that capture the agent’s entire “chain of thought”—which tools it called, the data it received, its reasoning for the next step, and the confidence scores for its decisions. This is essential for debugging and performance tuning.</li></ul></li><li>The Principle of Least Privilege: <ul><li>Security is paramount. An agent should be granted the absolute minimum set of permissions required to perform its task. An agent designed to summarize public news articles should only have access to a news API, not the ability to read private files or interact with other company systems. This drastically limits the “blast radius” of potential errors or malicious exploits.</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Guardrails-Safety-Patterns&quot;&gt;&lt;a href=&quot;#Guardrails-Safety-Patterns&quot; class=&quot;headerlink&quot; title=&quot;Guardrails: Safety Patterns&quot;&gt;&lt;/a&gt;Guardra</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>17_Reasoning_Techniques</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-17_Reasoning_Techniques/</id>
    <published>2025-09-14T05:22:31.000Z</published>
    <updated>2025-09-22T08:39:22.908Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Reasoning-Techniques"><a href="#Reasoning-Techniques" class="headerlink" title="Reasoning Techniques"></a>Reasoning Techniques</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problem-solving often requires more than a single, direct answer, posing a significant challenge for AI. </p><p>The core problem is enabling AI agents to tackle multi-step tasks that demand logical inference, decomposition, and strategic planning. </p><p>Without a structured approach, agents may fail to handle intricacies, leading to inaccurate or incomplete conclusions. These advanced reasoning methodologies aim to make an agent’s internal “thought” process explicit, allowing it to systematically work through challenges.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Reasoning techniques allow agents to break down problems, consider intermediate steps, and reach more robust and accurate conclusions.  </p><p>A core principle among these advanced methods is the allocation of increased computational resources during inference. This means granting the agent, or the underlying LLM, more processing time or steps to process a query and generate a response. </p><p>Rather than a quick, single pass, the agent can engage in iterative refinement, explore multiple solution paths, or utilize external tools. </p><p>This extended processing time during inference often significantly enhances accuracy, coherence, and robustness, especially for complex problems requiring deeper analysis and deliberation.</p><p>An agent’s thinking process is a structured approach that combines reasoning and acting to solve problems. This method allows an agent to explicitly plan its steps, monitor its progress, and interact with external tools to gather information.</p><p>At its core, the agent’s “thinking” is facilitated by a powerful LLM. This LLM generates a series of thoughts that guide the agent’s subsequent actions. The process typically follows a thought-action-observation loop:</p><ul><li>Thought: <ul><li>The agent first generates a textual thought that breaks down the problem, formulates a plan, or analyzes the current situation. This internal monologue makes the agent’s reasoning process transparent and steerable.</li></ul></li><li>Action: <ul><li>Based on the thought, the agent selects an action from a predefined, discrete set of options. For example, in a question-answering scenario, the action space might include searching online, retrieving information from a specific webpage, or providing a final answer.</li></ul></li><li>Observation: <ul><li>The agent then receives feedback from its environment based on the action taken. This could be the results of a web search or the content of a webpage.</li></ul></li></ul><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Chain-of-Thoughts-CoT"><a href="#Chain-of-Thoughts-CoT" class="headerlink" title="Chain-of-Thoughts (CoT)"></a>Chain-of-Thoughts (CoT)</h3><p>Its prompting significantly enhances LLMs complex reasoning abilities by mimicking a step-by-step thought process.</p><p>Instead of providing a direct answer, CoT prompts guide the model to generate a sequence of intermediate reasoning steps, which allows LLMs to tackle complex problems by decomposing them into smaller, more manageable sub-problems.</p><p>CoT can be implemented using various strategies, including offering few-shot examples that demonstrate step-by-step reasoning or simply instructing the model to “think step-by-step”. These approaches not only boosts accuracy but also offers valuable insights into the model’s decision-making, aiding in debugging and comprehension. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CoT_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">You are an Information Retrieval Agent. Your goal is to answer the user&#x27;s question comprehensively and accurately by thinking step-by-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here&#x27;s the process you must follow:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.  **Analyze the Query:** Understand the core subject and specific requirements of the user&#x27;s question. Identify key entities, keywords, and the type of information being sought.</span></span><br><span class="line"><span class="string">2.  **Formulate Search Queries (for Knowledge Base):** Based on your analysis, generate a list of precise search queries that you would use to retrieve relevant information from a knowledge base or external tools.</span></span><br><span class="line"><span class="string">3.  **Simulate Information Retrieval (Self-Correction/Reasoning):** For each search query, mentally consider what kind of information you expect to find. If you were to retrieve the content, what would be the most relevant snippets? Think about potential ambiguities or missing pieces.</span></span><br><span class="line"><span class="string">4.  **Synthesize Information:** Based on the simulated retrieval and your understanding of the user&#x27;s original query, synthesize the gathered information into a coherent and complete answer. Ensure all aspects of the query are addressed.</span></span><br><span class="line"><span class="string">5.  **Review and Refine:** Before finalizing, critically evaluate your answer. Is it accurate? Is it comprehensive? Is it easy to understand? Is it concise? If not, identify what needs to be improved and how.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Tree-of-Thoughts-ToT"><a href="#Tree-of-Thoughts-ToT" class="headerlink" title="Tree-of-Thoughts (ToT)"></a>Tree-of-Thoughts (ToT)</h3><p>It is a reasoning technique that builds upon Chain-of-Thought. It allows LLMs to explore multiple reasoning paths by branching into different intermediate steps, forming a tree structure. </p><p>This approach supports complex problem-solving by enabling backtracking, self-correction, and exploration of alternative solutions. </p><p>Maintaining a tree of possibilities allows the model to evaluate various reasoning trajectories before finalizing an answer. </p><h3 id="Self-correction"><a href="#Self-correction" class="headerlink" title="Self-correction"></a>Self-correction</h3><p>It, also known as self-refinement, is a crucial aspect of an agent’s reasoning process, particularly within Chain-of-Thought prompting. </p><p>It involves the agent’s internal evaluation of its generated content and intermediate thought processes. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">self_correction_prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">You are a highly critical and detail-oriented Self-Correction Agent. Your task is to review a previously generated piece of content against its original requirements and identify areas for improvement. Your goal is to refine the content to be more accurate, comprehensive, engaging, and aligned with the prompt.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here&#x27;s the process you must follow for self-correction:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.  **Understand Original Requirements:** Review the initial prompt/requirements that led to the content&#x27;s creation. What was the *original intent*? What were the key constraints or goals?</span></span><br><span class="line"><span class="string">2.  **Analyze Current Content:** Read the provided content carefully.</span></span><br><span class="line"><span class="string">3.  **Identify Discrepancies/Weaknesses:** Compare the current content against the original requirements. Look for:</span></span><br><span class="line"><span class="string">   * **Accuracy Issues:** Are there any factual errors or misleading statements?</span></span><br><span class="line"><span class="string">   * **Completeness Gaps:** Does it fully address all aspects of the original prompt? Is anything missing?</span></span><br><span class="line"><span class="string">   * **Clarity &amp; Coherence:** Is the language clear, concise, and easy to understand? Does it flow logically?</span></span><br><span class="line"><span class="string">   * **Tone &amp; Style:** Does it match the desired tone and style (e.g., professional, engaging, concise)?</span></span><br><span class="line"><span class="string">   * **Engagement:** Is it captivating? Does it hold the reader&#x27;s attention?</span></span><br><span class="line"><span class="string">   * **Redundancy/Verbosity:** Can any parts be condensed or removed without losing meaning?</span></span><br><span class="line"><span class="string">4.  **Propose Specific Improvements:** For each identified weakness, suggest concrete and actionable changes. Do not just state the problem; propose a solution.</span></span><br><span class="line"><span class="string">5.  **Generate Revised Content:** Based on your proposed improvements, rewrite the original content to incorporate all the necessary changes. Ensure the revised content is polished and ready for final use.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Program-Aided-Language-Models-PALMs"><a href="#Program-Aided-Language-Models-PALMs" class="headerlink" title="Program-Aided Language Models (PALMs)"></a>Program-Aided Language Models (PALMs)</h3><p>It integrates LLMs with symbolic reasoning capabilities, which allows the LLM to generate and execute code, such as Python, as part of its problem-solving process.</p><p>PALMs offload complex calculations, logical operations, and data manipulation to a deterministic programming environment. This approach utilizes the strengths of traditional programming for tasks where LLMs might exhibit limitations in accuracy or consistency. </p><h3 id="Reinforcement-Learning-with-Verifiable-Rewards-RLVR"><a href="#Reinforcement-Learning-with-Verifiable-Rewards-RLVR" class="headerlink" title="Reinforcement Learning with Verifiable Rewards (RLVR)"></a>Reinforcement Learning with Verifiable Rewards (RLVR)</h3><p>While effective, the standard Chain-of-Thought (CoT) prompting used by many LLMs is a somewhat basic approach to reasoning. It generates a single, predetermined line of thought without adapting to the complexity of the problem. </p><p>To overcome these limitations, a new class of specialized “reasoning models” has been developed. These models operate differently by dedicating a variable amount of “thinking” time before providing an answer. This “thinking” process produces a more extensive and dynamic Chain-of-Thought that can be thousands of tokens long. This extended reasoning allows for more complex behaviors like self-correction and backtracking, with the model dedicating more effort to harder problems. </p><p>The key innovation enabling these models is a training strategy called Reinforcement Learning from Verifiable Rewards (RLVR). By training the model on problems with known correct answers (like math or code), it learns through trial and error to generate effective, long-form reasoning. </p><p>This allows the model to evolve its problem-solving abilities without direct human supervision. Ultimately, these reasoning models don’t just produce an answer; they generate a “reasoning trajectory” that demonstrates advanced skills like planning, monitoring, and evaluation. This enhanced ability to reason and strategize is fundamental to the development of autonomous AI agents, which can break down and solve complex tasks with minimal human intervention.</p><h3 id="Reasoning-and-Acting-ReAct"><a href="#Reasoning-and-Acting-ReAct" class="headerlink" title="Reasoning and Acting (ReAct)"></a>Reasoning and Acting (ReAct)</h3><p>It is a paradigm that integrates Chain-of-Thought (CoT) prompting with an agent’s ability to interact with external environments through tools. Unlike generative models that produce a final answer, a ReAct agent reasons about which actions to take. </p><p>This reasoning phase involves an internal planning process, similar to CoT, where the agent determines its next steps, considers available tools, and anticipates outcomes. </p><p>Following this, the agent acts by executing a tool or function call, such as querying a database, performing a calculation, or interacting with an API. </p><h3 id="Chain-of-Debates-CoD"><a href="#Chain-of-Debates-CoD" class="headerlink" title="Chain of Debates (CoD)"></a>Chain of Debates (CoD)</h3><p>It is a formal AI framework proposed by Microsoft where multiple, diverse models collaborate and argue to solve a problem, moving beyond a single AI’s “chain of thought.” </p><p>This system operates like an AI council meeting, where different models present initial ideas, critique each other’s reasoning, and exchange counterarguments. </p><p>The primary goal is to enhance accuracy, reduce bias, and improve the overall quality of the final answer by leveraging collective intelligence. </p><p>Functioning as an AI version of peer review, this method creates a transparent and trustworthy record of the reasoning process. </p><p>Ultimately, it represents a shift from a solitary Agent providing an answer to a collaborative team of Agents working together to find a more robust and validated solution.</p><h3 id="Graph-of-Debates-GoD"><a href="#Graph-of-Debates-GoD" class="headerlink" title="Graph of Debates (GoD)"></a>Graph of Debates (GoD)</h3><p>It is an advanced Agentic framework that reimagines discussion as a dynamic, non-linear network rather than a simple chain. </p><p>In this model, arguments are individual nodes connected by edges that signify relationships like ‘supports’ or ‘refutes,’ reflecting the multi-threaded nature of real debate. This structure allows new lines of inquiry to dynamically branch off, evolve independently, and even merge over time. </p><p>A conclusion is reached not at the end of a sequence, but by identifying the most robust and well-supported cluster of arguments within the entire graph. </p><p>“Well-supported” refers to knowledge that is firmly established and verifiable. This can include information considered to be ground truth, which means it is inherently correct and widely accepted as fact. Additionally, it encompasses factual evidence obtained through search grounding, where information is validated against external sources and real-world data. Finally, it also pertains to a consensus reached by multiple models during a debate, indicating a high degree of agreement and confidence in the information presented.</p><h3 id="Deep-Research"><a href="#Deep-Research" class="headerlink" title="Deep Research"></a>Deep Research</h3><p>It describes a category of AI Agentic tools designed to act as tireless, methodical research assistants. Major platforms in this space include Perplexity AI, Google’s Gemini research capabilities, and OpenAI’s advanced functions within ChatGPT.</p><p>A fundamental shift introduced by these tools is the change in the search process itself. A standard search provides immediate links, leaving the work of synthesis to you. Deep Research operates on a different model. Here, you task an AI with a complex query and grant it a “time budget”—usually a few minutes. In return for this patience, you receive a detailed report.</p><p>During this time, the AI works on your behalf in an agentic way. It autonomously performs a series of sophisticated steps that would be incredibly time-consuming for a person:</p><ul><li>Initial Exploration: <ul><li>It runs multiple, targeted searches based on your initial prompt.</li></ul></li><li>Reasoning and Refinement: <ul><li>It reads and analyzes the first wave of results, synthesizes the findings, and critically identifies gaps, contradictions, or areas that require more detail.</li></ul></li><li>Follow-up Inquiry: <ul><li>Based on its internal reasoning, it conducts new, more nuanced searches to fill those gaps and deepen its understanding.</li></ul></li><li>Final Synthesis: <ul><li>After several rounds of this iterative searching and reasoning, it compiles all the validated information into a single, cohesive, and structured summary.</li></ul></li></ul><h3 id="Multi-Agent-System-Search-MASS"><a href="#Multi-Agent-System-Search-MASS" class="headerlink" title="Multi-Agent System Search (MASS)"></a>Multi-Agent System Search (MASS)</h3><p>An in-depth analysis of the design of multi-agent systems reveals that their effectiveness is critically dependent on both the quality of the prompts used to program individual agents and the topology that dictates their interactions. The complexity of designing these systems is significant, as it involves a vast and intricate search space.</p><p>The Multi-Agent System Search (MASS) Framework is a three-stage optimization process that navigates a search space encompassing optimizable prompts (instructions and demonstrations) and configurable agent building blocks (Aggregate, Reflect, Debate, Summarize, and Tool-use). </p><ul><li>The first stage, Block-level Prompt Optimization, independently optimizes prompts for each agent module. </li><li>Stage two, Workflow Topology Optimization, samples valid system configurations from an influence-weighted design space, integrating the optimized prompts. </li><li>The final stage, Workflow-level Prompt Optimization, involves a second round of prompt optimization for the entire multi-agent system after the optimal workflow from Stage two has been identified.</li></ul><h4 id="Block-Level-Prompt-Optimization"><a href="#Block-Level-Prompt-Optimization" class="headerlink" title="Block-Level Prompt Optimization"></a>Block-Level Prompt Optimization</h4><p>The process begins with a local optimization of prompts for individual agent types, or “blocks,” to ensure each component performs its role effectively before being integrated into a larger system. </p><p>This initial step is crucial as it ensures that the subsequent topology optimization builds upon well-performing agents, rather than suffering from the compounding impact of poorly configured ones.</p><p>The specialized role-playing prompt, discovered during block-level optimization, aims to make the debator agent highly effective at synthesizing information before it’s even placed into a larger workflow.</p><h4 id="Workflow-Topology-Optimization"><a href="#Workflow-Topology-Optimization" class="headerlink" title="Workflow Topology Optimization"></a>Workflow Topology Optimization</h4><p>Following local optimization, MASS optimizes the workflow topology by selecting and arranging different agent interactions from a customizable design space. </p><p>To make this search efficient, MASS employs an influence-weighted method. This method calculates the “incremental influence” of each topology by measuring its performance gain relative to a baseline agent and uses these scores to guide the search toward more promising combinations.</p><h4 id="Workflow-Level-Prompt-Optimization"><a href="#Workflow-Level-Prompt-Optimization" class="headerlink" title="Workflow-Level Prompt Optimization"></a>Workflow-Level Prompt Optimization</h4><p>It involves a global optimization of the entire system’s prompts. After identifying the best-performing topology, the prompts are fine-tuned as a single, integrated entity to ensure they are tailored for orchestration and that agent interdependencies are optimized.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Complex-Question-Answering"><a href="#Complex-Question-Answering" class="headerlink" title="Complex Question Answering"></a>Complex Question Answering</h3><p>Facilitating the resolution of multi-hop queries, which necessitate the integration of data from diverse sources and the execution of logical deductions, potentially involving the examination of multiple reasoning paths, and benefiting from extended inference time to synthesize information.</p><h3 id="Mathematical-Problem-Solving"><a href="#Mathematical-Problem-Solving" class="headerlink" title="Mathematical Problem Solving"></a>Mathematical Problem Solving</h3><p>Enabling the division of mathematical problems into smaller, solvable components, illustrating the step-by-step process, and employing code execution for precise computations, where prolonged inference enables more intricate code generation and validation.</p><h3 id="Code-Debugging-and-Generation"><a href="#Code-Debugging-and-Generation" class="headerlink" title="Code Debugging and Generation"></a>Code Debugging and Generation</h3><p>Supporting an agent’s explanation of its rationale for generating or correcting code, pinpointing potential issues sequentially, and iteratively refining the code based on test results (Self-Correction), leveraging extended inference time for thorough debugging cycles.</p><h3 id="Strategic-Planning"><a href="#Strategic-Planning" class="headerlink" title="Strategic Planning"></a>Strategic Planning</h3><p>Assisting in the development of comprehensive plans through reasoning across various options, consequences, and preconditions, and adjusting plans based on real-time feedback (ReAct), where extended deliberation can lead to more effective and reliable plans.</p><h3 id="Medical-Diagnosis"><a href="#Medical-Diagnosis" class="headerlink" title="Medical Diagnosis"></a>Medical Diagnosis</h3><p>Aiding an agent in systematically assessing symptoms, test outcomes, and patient histories to reach a diagnosis, articulating its reasoning at each phase, and potentially utilizing external instruments for data retrieval (ReAct). Increased inference time allows for a more comprehensive differential diagnosis.</p><h3 id="Legal-Analysis"><a href="#Legal-Analysis" class="headerlink" title="Legal Analysis"></a>Legal Analysis</h3><p>Supporting the analysis of legal documents and precedents to formulate arguments or provide guidance, detailing the logical steps taken, and ensuring logical consistency through self-correction. Increased inference time allows for more in-depth legal research and argument construction.</p><h2 id="Scaling-Inference-Law"><a href="#Scaling-Inference-Law" class="headerlink" title="Scaling Inference Law"></a>Scaling Inference Law</h2><p>Scaling Inference (not Training) Law dictates the relationship between an LLM’s performance and the computational resources allocated during its operational phase, known as inference.</p><p>A cornerstone of this law is the revelation that superior results can frequently be achieved from a comparatively smaller LLM by augmenting the computational investment at inference time. This doesn’t necessarily mean using a more powerful GPU, but rather employing more sophisticated or resource-intensive inference strategies. A prime example of such a strategy is instructing the model to generate multiple potential answers—perhaps through techniques like diverse beam search or self-consistency methods—and then employing a selection mechanism to identify the most optimal output. This iterative refinement or multiple-candidate generation process demands more computational cycles but can significantly elevate the quality of the final response.</p><p>This principle offers a crucial framework for informed and economically sound decision-making in the deployment of Agents systems. It challenges the intuitive notion that a larger model will always yield better performance. The law posits that a smaller model, when granted a more substantial “thinking budget” during inference, can occasionally surpass the performance of a much larger model that relies on a simpler, less computationally intensive generation process. The “thinking budget” here refers to the additional computational steps or complex algorithms applied during inference, allowing the smaller model to explore a wider range of possibilities or apply more rigorous internal checks before settling on an answer.</p><p>Consequently, the Scaling Inference Law becomes fundamental to constructing efficient and cost-effective Agentic systems. It provides a methodology for meticulously balancing several interconnected factors:</p><ul><li>Model Size: <ul><li>Smaller models are inherently less demanding in terms of memory and storage.</li></ul></li><li>Response Latency: <ul><li>While increased inference-time computation can add to latency, the law helps identify the point at which the performance gains outweigh this increase, or how to strategically apply computation to avoid excessive delays.</li></ul></li><li>Operational Cost: <ul><li>Deploying and running larger models typically incurs higher ongoing operational costs due to increased power consumption and infrastructure requirements. The law demonstrates how to optimize performance without unnecessarily escalating costs.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p><a href="https://github.com/jina-ai/node-DeepResearch">node-DeepResearch</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Reasoning-Techniques&quot;&gt;&lt;a href=&quot;#Reasoning-Techniques&quot; class=&quot;headerlink&quot; title=&quot;Reasoning Techniques&quot;&gt;&lt;/a&gt;Reasoning Techniques&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>16_Resource_Aware_Optimization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-16_Resource_Aware_Optimization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-16_Resource_Aware_Optimization/</id>
    <published>2025-09-14T05:22:07.000Z</published>
    <updated>2025-09-21T09:47:07.197Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Resource-Aware-Optimization"><a href="#Resource-Aware-Optimization" class="headerlink" title="Resource Aware Optimization"></a>Resource Aware Optimization</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>LLM-based applications can be expensive and slow, and selecting the best model or tool for every task is often inefficient. This creates a fundamental trade-off between the quality of a system’s output and the resources required to produce it. Without a dynamic management strategy, systems cannot adapt to varying task complexities or operate within budgetary and performance constraints.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Resource-Aware Optimization addresses the challenge of managing the consumption of computational, temporal, and financial resources in intelligent systems.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>Resource-Aware Optimization requires agents to make decisions regarding action execution to achieve goals within specified resource budgets or to optimize efficiency. This involves choosing between more accurate but expensive models and faster, lower-cost ones, or deciding whether to allocate additional compute for a more refined response versus returning a quicker, less detailed answer.</p><p>A key strategy in this category is the fallback mechanism, which acts as a safeguard when a preferred model is unavailable due to being overloaded or throttled. To ensure graceful degradation, the system automatically switches to a default or more affordable model, maintaining service continuity instead of failing completely.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Cost-Optimized-LLM-Usage"><a href="#Cost-Optimized-LLM-Usage" class="headerlink" title="Cost-Optimized LLM Usage"></a>Cost-Optimized LLM Usage</h3><p>An agent deciding whether to use a large, expensive LLM for complex tasks or a smaller, more affordable one for simpler queries, based on a budget constraint.</p><h3 id="Latency-Sensitive-Operations"><a href="#Latency-Sensitive-Operations" class="headerlink" title="Latency-Sensitive Operations"></a>Latency-Sensitive Operations</h3><p>In real-time systems, an agent chooses a faster but potentially less comprehensive reasoning path to ensure a timely response.</p><h3 id="Energy-Efficiency"><a href="#Energy-Efficiency" class="headerlink" title="Energy Efficiency"></a>Energy Efficiency</h3><p>For agents deployed on edge devices or with limited power, optimizing their processing to conserve battery life.</p><h3 id="Fallback-for-service-reliability"><a href="#Fallback-for-service-reliability" class="headerlink" title="Fallback for service reliability"></a>Fallback for service reliability</h3><p>An agent automatically switches to a backup model when the primary choice is unavailable, ensuring service continuity and graceful degradation.</p><h3 id="Data-Usage-Management"><a href="#Data-Usage-Management" class="headerlink" title="Data Usage Management"></a>Data Usage Management</h3><p>An agent opting for summarized data retrieval instead of full dataset downloads to save bandwidth or storage.</p><h3 id="Adaptive-Task-Allocation"><a href="#Adaptive-Task-Allocation" class="headerlink" title="Adaptive Task Allocation"></a>Adaptive Task Allocation</h3><p>In multi-agent systems, agents self-assign tasks based on their current computational load or available time.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><h3 id="Basic-Architecture"><a href="#Basic-Architecture" class="headerlink" title="Basic Architecture"></a>Basic Architecture</h3><p>A Router Agent can direct queries based on simple metrics like query length, where shorter queries go to less expensive models and longer queries to more capable models. However, a more sophisticated Router Agent can utilize either LLM or ML models to analyze query nuances and complexity. </p><p>This LLM router can determine which downstream language model is most suitable. For example, a query requesting a factual recall is routed to a flash model, while a complex query requiring deep analysis is routed to a pro model.</p><p>Optimization techniques can further enhance the LLM router’s effectiveness. Prompt tuning involves crafting prompts to guide the router LLM for better routing decisions. Fine-tuning the LLM router on a dataset of queries and their optimal model choices improves its accuracy and efficiency. This dynamic routing capability balances response quality with cost-effectiveness.</p><p>The Critique Agent evaluates responses from language models, providing feedback that serves several functions. Its feedback can signal reinforcement learning or fine-tuning</p><h3 id="Openrouter"><a href="#Openrouter" class="headerlink" title="Openrouter"></a>Openrouter</h3><p>OpenRouter offers a unified interface to hundreds of AI models via a single API endpoint. </p><p>It offers two distinct methodologies for routing and determining the computational model used to process a given request: </p><ul><li>Automated Model Selection:<ul><li>This function routes a request to an optimized model chosen from a curated set of available models. </li><li>The selection is predicated on the specific content of the user’s prompt. The identifier of the model that ultimately processes the request in the response’s metadata.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;model&quot;</span>: <span class="string">&quot;openrouter/auto&quot;</span>,</span><br><span class="line"> ... // Other params</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Sequential Model Fallback:<ul><li>This mechanism provides operational redundancy by allowing users to specify a hierarchical list of models. </li><li>The system will first attempt to process the request with the primary model designated in the sequence. Should this primary model fail to respond due to any number of error conditions—such as service unavailability, rate-limiting, or content filtering—the system will automatically re-route the request to the next specified model in the sequence. This process continues until a model in the list successfully executes the request or the list is exhausted. The final cost of the operation and the model identifier returned in the response will correspond to the model that successfully completed the computation.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;models&quot;</span>: [<span class="string">&quot;anthropic/claude-3.5-sonnet&quot;</span>, <span class="string">&quot;gryphe/mythomax-l2-13b&quot;</span>],</span><br><span class="line"> ... // Other params</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Beyond-Dynamic-Model-Switching-A-Spectrum-of-Agent-Resource-Optimizations"><a href="#Beyond-Dynamic-Model-Switching-A-Spectrum-of-Agent-Resource-Optimizations" class="headerlink" title="Beyond Dynamic Model Switching: A Spectrum of Agent Resource Optimizations"></a>Beyond Dynamic Model Switching: A Spectrum of Agent Resource Optimizations</h2><h3 id="Dynamic-Model-Switching"><a href="#Dynamic-Model-Switching" class="headerlink" title="Dynamic Model Switching"></a>Dynamic Model Switching</h3><p>It is a critical technique involving the strategic selection of large language models based on the intricacies of the task at hand and the available computational resources. </p><p>When faced with simple queries, a lightweight, cost-effective LLM can be deployed, whereas complex, multifaceted problems necessitate the utilization of more sophisticated and resource-intensive models. </p><h3 id="Adaptive-Tool-Use-amp-Selection"><a href="#Adaptive-Tool-Use-amp-Selection" class="headerlink" title="Adaptive Tool Use &amp; Selection"></a>Adaptive Tool Use &amp; Selection</h3><p>It ensures agents can intelligently choose from a suite of tools, selecting the most appropriate and efficient one for each specific sub-task, with careful consideration given to factors like API usage costs, latency, and execution time. </p><p>This dynamic tool selection enhances overall system efficiency by optimizing the use of external APIs and services. </p><h3 id="Contextual-Pruning-amp-Summarization"><a href="#Contextual-Pruning-amp-Summarization" class="headerlink" title="Contextual Pruning &amp; Summarization"></a>Contextual Pruning &amp; Summarization</h3><p>It plays a vital role in managing the amount of information processed by agents, strategically minimizing the prompt token count and reducing inference costs by intelligently summarizing and selectively retaining only the most relevant information from the interaction history, preventing unnecessary computational overhead. </p><h3 id="Proactive-Resource-Prediction"><a href="#Proactive-Resource-Prediction" class="headerlink" title="Proactive Resource Prediction"></a>Proactive Resource Prediction</h3><p>It involves anticipating resource demands by forecasting future workloads and system requirements, which allows for proactive allocation and management of resources, ensuring system responsiveness and preventing bottlenecks. </p><h3 id="Cost-Sensitive-Exploration"><a href="#Cost-Sensitive-Exploration" class="headerlink" title="Cost-Sensitive Exploration"></a>Cost-Sensitive Exploration</h3><p>In multi-agent systems, it extends optimization considerations to encompass communication costs alongside traditional computational costs, influencing the strategies employed by agents to collaborate and share information, aiming to minimize the overall resource expenditure. </p><h3 id="Energy-Efficient-Deployment"><a href="#Energy-Efficient-Deployment" class="headerlink" title="Energy-Efficient Deployment"></a>Energy-Efficient Deployment</h3><p>It is specifically tailored for environments with stringent resource constraints, aiming to minimize the energy footprint of intelligent agent systems, extending operational time and reducing overall running costs. </p><h3 id="Parallelization-amp-Distributed-Computing-Awareness"><a href="#Parallelization-amp-Distributed-Computing-Awareness" class="headerlink" title="Parallelization &amp; Distributed Computing Awareness"></a>Parallelization &amp; Distributed Computing Awareness</h3><p>It leverages distributed resources to enhance the processing power and throughput of agents, distributing computational workloads across multiple machines or processors to achieve greater efficiency and faster task completion. </p><h3 id="Learned-Resource-Allocation-Policies"><a href="#Learned-Resource-Allocation-Policies" class="headerlink" title="Learned Resource Allocation Policies"></a>Learned Resource Allocation Policies</h3><p>It introduces a learning mechanism, enabling agents to adapt and optimize their resource allocation strategies over time based on feedback and performance metrics, improving efficiency through continuous refinement. </p><h3 id="Graceful-Degradation-and-Fallback-Mechanisms"><a href="#Graceful-Degradation-and-Fallback-Mechanisms" class="headerlink" title="Graceful Degradation and Fallback Mechanisms"></a>Graceful Degradation and Fallback Mechanisms</h3><p>It ensures that intelligent agent systems can continue to function, albeit perhaps at a reduced capacity, even when resource constraints are severe, gracefully degrading performance and falling back to alternative strategies to maintain operation and provide essential functionality.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Resource-Aware-Optimization&quot;&gt;&lt;a href=&quot;#Resource-Aware-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Resource Aware Optimization&quot;&gt;&lt;/a&gt;Resou</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>15_Inter_Agent_Communication</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-15_Inter_Agent_Communication/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-15_Inter_Agent_Communication/</id>
    <published>2025-09-14T05:21:18.000Z</published>
    <updated>2025-09-21T07:56:17.495Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Inter-Agent-Communication-A2A"><a href="#Inter-Agent-Communication-A2A" class="headerlink" title="Inter-Agent Communication (A2A)"></a>Inter-Agent Communication (A2A)</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Individual AI agents, especially those built on different frameworks, often struggle with complex, multi-faceted problems on their own. The primary challenge is the lack of a common language or protocol that allows them to communicate and collaborate effectively. This isolation prevents the creation of sophisticated systems where multiple specialized agents can combine their unique skills to solve larger tasks. Without a standardized approach, integrating these disparate agents is costly, time-consuming, and hinders the development of more powerful, cohesive AI solutions.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Google’s Inter-Agent Communication (A2A) is an open standard which enables diverse AI agents, potentially built with different frameworks, to collaborate effectively. This collaboration involves seamless coordination, task delegation, and information exchange.</p><p>While MCP focuses on structuring context for agents and their interaction with external data and tools, A2A facilitates coordination and communication among agents, enabling task delegation and collaboration.</p><p><img src="" alt="img"></p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Core-Actors"><a href="#Core-Actors" class="headerlink" title="Core Actors"></a>Core Actors</h3><ul><li>User: <ul><li>Initiates requests for agent assistance.</li></ul></li><li>A2A Client (Client Agent): <ul><li>An application or AI agent that acts on the user’s behalf to request actions or information.</li></ul></li><li>A2A Server (Remote Agent): <ul><li>An AI agent or system that provides an HTTP endpoint to process client requests and return results. The remote agent operates as an “opaque” system, meaning the client does not need to understand its internal operational details.</li></ul></li></ul><h3 id="Agent-Card"><a href="#Agent-Card" class="headerlink" title="Agent Card"></a>Agent Card</h3><p>An agent’s digital identity is defined by its Agent Card, usually a JSON file. </p><p>This file contains key information for client interaction and automatic discovery, including the agent’s identity, endpoint URL, and version. </p><p>It also details supported capabilities like streaming or push notifications, specific skills, default input/output modes, and authentication requirements.</p><p>Below is an example of an Agent Card for a WeatherBot.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;name&quot;</span>: <span class="string">&quot;WeatherBot&quot;</span>,</span><br><span class="line"> <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Provides accurate weather forecasts and historical data.&quot;</span>,</span><br><span class="line"> <span class="string">&quot;url&quot;</span>: <span class="string">&quot;http://weather-service.example.com/a2a&quot;</span>,</span><br><span class="line"> <span class="string">&quot;version&quot;</span>: <span class="string">&quot;1.0.0&quot;</span>,</span><br><span class="line"> <span class="string">&quot;capabilities&quot;</span>: &#123;</span><br><span class="line">   <span class="string">&quot;streaming&quot;</span>: true,</span><br><span class="line">   <span class="string">&quot;pushNotifications&quot;</span>: false,</span><br><span class="line">   <span class="string">&quot;stateTransitionHistory&quot;</span>: true</span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="string">&quot;authentication&quot;</span>: &#123;</span><br><span class="line">   <span class="string">&quot;schemes&quot;</span>: [</span><br><span class="line">     <span class="string">&quot;apiKey&quot;</span></span><br><span class="line">   ]</span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="string">&quot;defaultInputModes&quot;</span>: [</span><br><span class="line">   <span class="string">&quot;text&quot;</span></span><br><span class="line"> ],</span><br><span class="line"> <span class="string">&quot;defaultOutputModes&quot;</span>: [</span><br><span class="line">   <span class="string">&quot;text&quot;</span></span><br><span class="line"> ],</span><br><span class="line"> <span class="string">&quot;skills&quot;</span>: [</span><br><span class="line">   &#123;</span><br><span class="line">     <span class="string">&quot;id&quot;</span>: <span class="string">&quot;get_current_weather&quot;</span>,</span><br><span class="line">     <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Get Current Weather&quot;</span>,</span><br><span class="line">     <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Retrieve real-time weather for any location.&quot;</span>,</span><br><span class="line">     <span class="string">&quot;inputModes&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;text&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;outputModes&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;text&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;examples&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;What&#x27;s the weather in Paris?&quot;</span>,</span><br><span class="line">       <span class="string">&quot;Current conditions in Tokyo&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;tags&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;weather&quot;</span>,</span><br><span class="line">       <span class="string">&quot;current&quot;</span>,</span><br><span class="line">       <span class="string">&quot;real-time&quot;</span></span><br><span class="line">     ]</span><br><span class="line">   &#125;,</span><br><span class="line">   &#123;</span><br><span class="line">     <span class="string">&quot;id&quot;</span>: <span class="string">&quot;get_forecast&quot;</span>,</span><br><span class="line">     <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Get Forecast&quot;</span>,</span><br><span class="line">     <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Get 5-day weather predictions.&quot;</span>,</span><br><span class="line">     <span class="string">&quot;inputModes&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;text&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;outputModes&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;text&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;examples&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;5-day forecast for New York&quot;</span>,</span><br><span class="line">       <span class="string">&quot;Will it rain in London this weekend?&quot;</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="string">&quot;tags&quot;</span>: [</span><br><span class="line">       <span class="string">&quot;weather&quot;</span>,</span><br><span class="line">       <span class="string">&quot;forecast&quot;</span>,</span><br><span class="line">       <span class="string">&quot;prediction&quot;</span></span><br><span class="line">     ]</span><br><span class="line">   &#125;</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Agent-Discovery"><a href="#Agent-Discovery" class="headerlink" title="Agent Discovery"></a>Agent Discovery</h3><p>It allows clients to find Agent Cards, which describe the capabilities of available A2A Servers. </p><p>Several strategies exist for this process:</p><ul><li>Well-Known URL: <ul><li>Agent host their Agent Card at a standardized path. </li><li>This approach offers broad, often automated, accessibility for public or domain-specific use.</li></ul></li><li>Curated Registries:<ul><li>These provide a centralized catalog where Agent Cards are published and can be queried based on specific criteria. </li><li>This is well-suited for enterprise environments needing centralized management and access control.</li></ul></li><li>Direct Configuration: <ul><li>Agent Card information is embedded or privately shared. </li><li>This method is appropriate for closely coupled or private systems where dynamic discovery isn’t crucial.</li></ul></li></ul><h3 id="Communication-and-Tasks"><a href="#Communication-and-Tasks" class="headerlink" title="Communication and Tasks"></a>Communication and Tasks</h3><p>Communication is structured around asynchronous tasks, which represent the fundamental units of work for long-running processes. </p><p>Each task is assigned a unique identifier and moves through a series of states (submitted, working, or completed). </p><p>Communication between agents occurs through a Message, which contains attributes, which are key-value metadata describing the message (priority or creation time), and one or more parts, which carry the actual content being delivered (plain text, files or structured JSON data).</p><p>The tangible outputs generated by an agent during a task are called artifacts, which are also composed of one or more parts and can be streamed incrementally as results become available. </p><p>All communication within the A2A framework is conducted over HTTP(S) using the JSON-RPC 2.0 protocol for payloads. </p><p>To maintain continuity across multiple interactions, a server-generated “contextId” is used to group related tasks and preserve context.</p><h3 id="Interaction-mechanisms"><a href="#Interaction-mechanisms" class="headerlink" title="Interaction mechanisms"></a>Interaction mechanisms</h3><ul><li>Synchronous Request/Response: <ul><li>For quick, immediate operations. </li><li>The client sends a request and actively waits for the server to process it and return a complete response in a single synchronous exchange.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;Synchronous Request Example&quot;&quot;&quot;</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;jsonrpc&quot;</span>: <span class="string">&quot;2.0&quot;</span>,</span><br><span class="line"> <span class="string">&quot;id&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line"> <span class="string">&quot;method&quot;</span>: <span class="string">&quot;sendTask&quot;</span>,</span><br><span class="line"> <span class="string">&quot;params&quot;</span>: &#123;</span><br><span class="line">   <span class="string">&quot;id&quot;</span>: <span class="string">&quot;task-001&quot;</span>,</span><br><span class="line">   <span class="string">&quot;sessionId&quot;</span>: <span class="string">&quot;session-001&quot;</span>,</span><br><span class="line">   <span class="string">&quot;message&quot;</span>: &#123;</span><br><span class="line">     <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">     <span class="string">&quot;parts&quot;</span>: [</span><br><span class="line">       &#123;</span><br><span class="line">         <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">         <span class="string">&quot;text&quot;</span>: <span class="string">&quot;What is the exchange rate from USD to EUR?&quot;</span></span><br><span class="line">       &#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="string">&quot;acceptedOutputModes&quot;</span>: [<span class="string">&quot;text/plain&quot;</span>],</span><br><span class="line">   <span class="string">&quot;historyLength&quot;</span>: <span class="number">5</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Asynchronous Polling: <ul><li>Suited for tasks that take longer to process. </li><li>The client sends a request, and the server immediately acknowledges it with a “working” status and task ID. </li><li>The client is then free to perform other actions and can periodically poll the server by sending new requests to check the status of the task until it is marked as “completed” or “failed” </li></ul></li><li>Streaming Updates (Server-Sent Events SSE): <ul><li>Ideal for receiving real-time, incremental results. </li><li>This method establishes a persistent, one-way connection from the server to the client. It allows the remote agent to continuously push updates, such as status changes or partial results, without the client needing to make multiple requests.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;Streaming Request Example&quot;&quot;&quot;</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;jsonrpc&quot;</span>: <span class="string">&quot;2.0&quot;</span>,</span><br><span class="line"> <span class="string">&quot;id&quot;</span>: <span class="string">&quot;2&quot;</span>,</span><br><span class="line"> <span class="string">&quot;method&quot;</span>: <span class="string">&quot;sendTaskSubscribe&quot;</span>,</span><br><span class="line"> <span class="string">&quot;params&quot;</span>: &#123;</span><br><span class="line">   <span class="string">&quot;id&quot;</span>: <span class="string">&quot;task-002&quot;</span>,</span><br><span class="line">   <span class="string">&quot;sessionId&quot;</span>: <span class="string">&quot;session-001&quot;</span>,</span><br><span class="line">   <span class="string">&quot;message&quot;</span>: &#123;</span><br><span class="line">     <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">     <span class="string">&quot;parts&quot;</span>: [</span><br><span class="line">       &#123;</span><br><span class="line">         <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">         <span class="string">&quot;text&quot;</span>: <span class="string">&quot;What&#x27;s the exchange rate for JPY to GBP today?&quot;</span></span><br><span class="line">       &#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="string">&quot;acceptedOutputModes&quot;</span>: [<span class="string">&quot;text/plain&quot;</span>],</span><br><span class="line">   <span class="string">&quot;historyLength&quot;</span>: <span class="number">5</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Push Notifications (Webhooks): <ul><li>Designed for very long-running or resource-intensive tasks where maintaining a constant connection or frequent polling is inefficient.</li><li>The client can register a webhook URL, and the server will send an asynchronous notification (a “push”) to that URL when the task’s status changes significantly (upon completion).</li></ul></li></ul><h3 id="Security-robustness-and-integrity"><a href="#Security-robustness-and-integrity" class="headerlink" title="Security: robustness and integrity"></a>Security: robustness and integrity</h3><ul><li>Mutual Transport Layer Security (TLS):<ul><li>Encrypted and authenticated connections are established to prevent unauthorized access and data interception, ensuring secure communication.</li></ul></li><li>Comprehensive Audit Logs:<ul><li>All inter-agent communications are meticulously recorded, detailing information flow, involved agents, and actions. This audit trail is crucial for accountability, troubleshooting, and security analysis.</li></ul></li><li>Agent Card Declaration:<ul><li>Authentication requirements are explicitly declared in the Agent Card, a configuration artifact outlining the agent’s identity, capabilities, and security policies. This centralizes and simplifies authentication management.</li></ul></li><li>Credential Handling: <ul><li>Agents typically authenticate using secure credentials like OAuth 2.0 tokens or API keys, passed via HTTP headers. This method prevents credential exposure in URLs or message bodies, enhancing overall security.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Multi-Framework-Collaboration"><a href="#Multi-Framework-Collaboration" class="headerlink" title="Multi-Framework Collaboration"></a>Multi-Framework Collaboration</h3><p>A2A’s primary use case is enabling independent AI agents, regardless of their underlying frameworks (e.g., ADK, LangChain, CrewAI), to communicate and collaborate. This is fundamental for building complex multi-agent systems where different agents specialize in different aspects of a problem.</p><h3 id="Automated-Workflow-Orchestration"><a href="#Automated-Workflow-Orchestration" class="headerlink" title="Automated Workflow Orchestration"></a>Automated Workflow Orchestration</h3><p>In enterprise settings, A2A can facilitate complex workflows by enabling agents to delegate and coordinate tasks. For instance, an agent might handle initial data collection, then delegate to another agent for analysis, and finally to a third for report generation, all communicating via the A2A protocol.</p><h3 id="Dynamic-Information-Retrieval"><a href="#Dynamic-Information-Retrieval" class="headerlink" title="Dynamic Information Retrieval"></a>Dynamic Information Retrieval</h3><p>Agents can communicate to retrieve and exchange real-time information. A primary agent might request live market data from a specialized “data fetching agent,” which then uses external APIs to gather the information and send it back.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p><a href="https://github.com/google-a2a/a2a-samples/tree/main/samples">A2A Github Repository</a></p><p><a href="https://www.trickle.so/blog/how-to-build-google-a2a-project">Further exploration of A2A</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Inter-Agent-Communication-A2A&quot;&gt;&lt;a href=&quot;#Inter-Agent-Communication-A2A&quot; class=&quot;headerlink&quot; title=&quot;Inter-Agent Communication (A2A)&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>14_Knowledge_Retrieval</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-14_Knowledge_Retrieval/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-14_Knowledge_Retrieval/</id>
    <published>2025-09-14T05:20:47.000Z</published>
    <updated>2025-09-21T05:55:40.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Knowledge-Retrieval"><a href="#Knowledge-Retrieval" class="headerlink" title="Knowledge Retrieval"></a>Knowledge Retrieval</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>LLMs possess impressive text generation abilities but are fundamentally limited by their training data. This knowledge is static, meaning it doesn’t include real-time information or private, domain-specific data. Consequently, their responses can be outdated, inaccurate, or lack the specific context required for specialized tasks. This gap restricts their reliability for applications demanding current and factual answers.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Knowledge Retrieval (RAG, or  Retrieval Augmented Generation), addresses this limitation. RAG enables LLMs to access and integrate external, current, and context-specific information, thereby enhancing the accuracy, relevance, and factual basis of their outputs.</p><p>By integrating external knowledge, RAG transforms agents from simple conversationalists into effective, data-driven tools capable of executing meaningful work.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>When a user poses a question or gives a prompt to an AI system using RAG, the query isn’t sent directly to the LLM. </p><p>Instead, the system first scours a vast external knowledge base—a highly organized library of documents, databases, or web pages—for relevant information. This search is not a simple keyword match; it’s a “semantic search” that understands the user’s intent and the meaning behind their words. </p><p>This initial search pulls out the most pertinent snippets or “chunks” of information. These extracted pieces are then “augmented,” or added, to the original prompt, creating a richer, more informed query. </p><p>Finally, this enhanced prompt is sent to the LLM. With this additional context, the LLM can generate a response that is not only fluent and natural but also factually grounded in the retrieved data.</p><h3 id="Technology"><a href="#Technology" class="headerlink" title="Technology"></a>Technology</h3><h4 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h4><p>In the context of LLMs, embeddings are numerical representations of text, such as words, phrases, or entire documents. </p><ul><li>These representations are in the form of a vector, which is a list of numbers. </li><li>The key idea is to capture the semantic meaning and the relationships between different pieces of text in a mathematical space. </li><li>These embeddings are in a much higher-dimensional space with hundreds or even thousands of dimensions, allowing for a very nuanced understanding of language.</li><li>Words or phrases with similar meanings will have embeddings that are closer to each other in this vector space.</li></ul><h4 id="Text-Similarity"><a href="#Text-Similarity" class="headerlink" title="Text Similarity"></a>Text Similarity</h4><p>Text similarity refers to the measure of how alike two pieces of text are. </p><ul><li>It is often calculated using the embeddings of the texts.</li><li>This can be at a surface level, looking at the overlap of words (lexical similarity)</li><li>This also can be at a deeper, meaning-based level.</li></ul><p>In the context of RAG, text similarity is crucial for finding the most relevant information in the knowledge base that corresponds to a user’s query. </p><h4 id="Semantic-Similarity-and-Distance"><a href="#Semantic-Similarity-and-Distance" class="headerlink" title="Semantic Similarity and Distance"></a>Semantic Similarity and Distance</h4><p>Semantic similarity is a more advanced form of text similarity that focuses purely on the meaning and context of the text, rather than just the words used. It aims to understand if two pieces of text convey the same concept or idea.</p><p>Semantic distance is the inverse of this; a high semantic similarity implies a low semantic distance, and vice versa. In RAG, semantic search relies on finding documents with the smallest semantic distance to the user’s query.</p><h4 id="Chunking-of-Documents"><a href="#Chunking-of-Documents" class="headerlink" title="Chunking of Documents"></a>Chunking of Documents</h4><p>Chunking is the process of breaking down large documents into smaller, more manageable pieces, or “chunks.”</p><p>Once documents are chunked, the RAG system must employ a retrieval technique to find the most relevant pieces for a given query.</p><ul><li>The primary method is vector search, which uses embeddings and semantic distance to find chunks that are conceptually similar to the user’s question. </li><li>An older, but still valuable, technique is BM25, a keyword-based algorithm that ranks chunks based on term frequency without understanding semantic meaning.</li><li>To get the best of both worlds, hybrid search approaches are often used, combining the keyword precision of BM25 with the contextual understanding of semantic search.</li></ul><h4 id="Vector-databases"><a href="#Vector-databases" class="headerlink" title="Vector databases"></a>Vector databases</h4><p>A vector database is a specialized type of database designed to store and query embeddings efficiently. By storing text as numerical vectors, they can find results based on conceptual meaning, not just keyword overlap. </p><p>After documents are chunked and converted into embeddings, these high-dimensional vectors are stored in a vector database. </p><ul><li>Traditional retrieval techniques, like keyword-based search, are excellent at finding documents containing exact words from a query but lack a deep understanding of language.</li><li>When a user’s query is also converted into a vector, the database uses highly optimized algorithms (like HNSW - Hierarchical Navigable Small World) to rapidly search through millions of vectors and find the ones that are “closest” in meaning. This approach is far superior for RAG because it uncovers relevant context even if the user’s phrasing is completely different from the source documents. In essence, while other techniques search for words, vector databases search for meaning. </li></ul><p>This technology is implemented in various forms:</p><ul><li>Managed databases like Pinecone and Weaviate </li><li>Open-source solutions such as Chroma DB, Milvus, and Qdrant</li><li>Even existing databases can be augmented with vector search capabilities, as seen with Redis, Elasticsearch, and Postgres (using the pgvector extension). </li><li>The core retrieval mechanisms are often powered by libraries like Meta AI’s FAISS or Google Research’s ScaNN, which are fundamental to the efficiency of these systems.</li></ul><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ul><li>A primary issue arises when the information needed to answer a query is not confined to a single chunk but is spread across multiple parts of a document or even several documents. In such cases, the retriever might fail to gather all the necessary context, leading to an incomplete or inaccurate answer. </li><li>The system’s effectiveness is also highly dependent on the quality of the chunking and retrieval process; if irrelevant chunks are retrieved, it can introduce noise and confuse the LLM. </li><li>Effectively synthesizing information from potentially contradictory sources remains a significant hurdle for these systems.  </li><li>RAG requires the entire knowledge base to be pre-processed and stored in specialized databases, such as vector or graph databases, which is a considerable undertaking. Consequently, this knowledge requires periodic reconciliation to remain up-to-date. This entire process can have a noticeable impact on performance, increasing latency, operational costs, and the number of tokens used in the final prompt.</li></ul><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><h4 id="Graph-RAG"><a href="#Graph-RAG" class="headerlink" title="Graph RAG"></a>Graph RAG</h4><p>GraphRAG is an advanced form of Retrieval-Augmented Generation that utilizes a knowledge graph instead of a simple vector database for information retrieval. </p><p>It answers complex queries by navigating the explicit relationships (edges) between data entities (nodes) within this structured knowledge base. </p><p>A key advantage is its ability to synthesize answers from information fragmented across multiple documents, a common failing of traditional RAG. </p><p>By understanding these connections, GraphRAG provides more contextually accurate and nuanced responses.</p><ul><li>Disadvantages:<ul><li>The primary drawback, however, is the significant complexity, cost, and expertise required to build and maintain a high-quality knowledge graph. </li><li>This setup is also less flexible and can introduce higher latency compared to simpler vector search systems. </li><li>The system’s effectiveness is entirely dependent on the quality and completeness of the underlying graph structure.</li></ul></li></ul><h4 id="Agentic-RAG"><a href="#Agentic-RAG" class="headerlink" title="Agentic RAG"></a>Agentic RAG</h4><p>It introduces a reasoning and decision-making layer to significantly enhance the reliability of information extraction. </p><p>Instead of just retrieving and augmenting, an “agent”—a specialized AI component—acts as a critical gatekeeper and refiner of knowledge. </p><ul><li><p>Rather than passively accepting the initially retrieved data, this agent actively interrogates its quality, relevance, and completeness.</p></li><li><p>Disadvantages:</p><ul><li>The primary drawback is a significant increase in complexity and cost. Designing, implementing, and maintaining the agent’s decision-making logic and tool integrations requires substantial engineering effort and adds to computational expenses. This complexity can also lead to increased latency, as the agent’s cycles of reflection, tool use, and multi-step reasoning take more time than a standard, direct retrieval process. </li><li>Furthermore, the agent itself can become a new source of error; a flawed reasoning process could cause it to get stuck in useless loops, misinterpret a task, or improperly discard relevant information, ultimately degrading the quality of the final response.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Enterprise-Search-and-Q-amp-A"><a href="#Enterprise-Search-and-Q-amp-A" class="headerlink" title="Enterprise Search and Q&amp;A"></a>Enterprise Search and Q&amp;A</h3><p>Organizations can develop internal chatbots that respond to employee inquiries using internal documentation such as HR policies, technical manuals, and product specifications. The RAG system extracts relevant sections from these documents to inform the LLM’s response.</p><h3 id="Customer-Support-and-Helpdesks"><a href="#Customer-Support-and-Helpdesks" class="headerlink" title="Customer Support and Helpdesks"></a>Customer Support and Helpdesks</h3><p>RAG-based systems can offer precise and consistent responses to customer queries by accessing information from product manuals, frequently asked questions (FAQs), and support tickets. This can reduce the need for direct human intervention for routine issues.</p><h3 id="Personalized-Content-Recommendation"><a href="#Personalized-Content-Recommendation" class="headerlink" title="Personalized Content Recommendation"></a>Personalized Content Recommendation</h3><p>Instead of basic keyword matching, RAG can identify and retrieve content (articles, products) that is semantically related to a user’s preferences or previous interactions, leading to more relevant recommendations.</p><h3 id="News-and-Current-Events-Summarization"><a href="#News-and-Current-Events-Summarization" class="headerlink" title="News and Current Events Summarization"></a>News and Current Events Summarization</h3><p>LLMs can be integrated with real-time news feeds. When prompted about a current event, the RAG system retrieves recent articles, allowing the LLM to produce an up-to-date summary.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Knowledge-Retrieval&quot;&gt;&lt;a href=&quot;#Knowledge-Retrieval&quot; class=&quot;headerlink&quot; title=&quot;Knowledge Retrieval&quot;&gt;&lt;/a&gt;Knowledge Retrieval&lt;/h1&gt;&lt;h2 i</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>13_Human_in_the_Loop</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-13_Human_in_the_Loop/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-13_Human_in_the_Loop/</id>
    <published>2025-09-14T05:20:17.000Z</published>
    <updated>2025-09-18T08:29:29.856Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Human-in-the-Loop"><a href="#Human-in-the-Loop" class="headerlink" title="Human in the Loop"></a>Human in the Loop</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI systems, including advanced LLMs, often struggle with tasks that require nuanced judgment, ethical reasoning, or a deep understanding of complex, ambiguous contexts. </p><p>Deploying fully autonomous AI in high-stakes environments carries significant risks, as errors can lead to severe safety, financial, or ethical consequences. </p><p>These systems lack the inherent creativity and common-sense reasoning that humans possess. </p><p>Consequently, relying solely on automation in critical decision-making processes is often imprudent and can undermine the system’s overall effectiveness and trustworthiness.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>The Human-in-the-Loop (HITL) pattern represents a pivotal strategy in the development and deployment of Agents. It deliberately interweaves the unique strengths of human cognition—such as judgment, creativity, and nuanced understanding—with the computational power and efficiency of AI. </p><p>The core principle of HITL is to ensure that AI operates within ethical boundaries, adheres to safety protocols, and achieves its objectives with optimal effectiveness.</p><p>In practice, HITL can be implemented in diverse ways:</p><ul><li>One common approach involves humans acting as validators or reviewers, examining AI outputs to ensure accuracy and identify potential errors.</li><li>Another implementation involves humans actively guiding AI behavior, providing feedback or making corrections in real-time. </li><li>In more complex setups, humans may collaborate with AI as partners, jointly solving problems or making decisions through interactive dialog or shared interfaces. </li></ul><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Human-Oversight"><a href="#Human-Oversight" class="headerlink" title="Human Oversight"></a>Human Oversight</h3><p>Human Oversight, which involves monitoring AI agent performance and output (e.g., via log reviews or real-time dashboards) to ensure adherence to guidelines and prevent undesirable outcomes. </p><p>Intervention and Correction occurs when an AI agent encounters errors or ambiguous scenarios and may request human intervention; human operators can rectify errors, supply missing data, or guide the agent, which also informs future agent improvements. </p><p>Human Feedback for Learning is collected and used to refine AI models, prominently in methodologies like reinforcement learning with human feedback, where human preferences directly influence the agent’s learning trajectory.</p><h3 id="Decision-Augmentation"><a href="#Decision-Augmentation" class="headerlink" title="Decision Augmentation"></a>Decision Augmentation</h3><p>Decision Augmentation is where an AI agent provides analyses and recommendations to a human, who then makes the final decision, enhancing human decision-making through AI-generated insights rather than full autonomy. </p><h3 id="Human-Agent-Collaboration"><a href="#Human-Agent-Collaboration" class="headerlink" title="Human-Agent Collaboration"></a>Human-Agent Collaboration</h3><p>Human-Agent Collaboration is a cooperative interaction where humans and AI agents contribute their respective strengths; routine data processing may be handled by the agent, while creative problem-solving or complex negotiations are managed by the human. </p><h3 id="Escalation-Policies"><a href="#Escalation-Policies" class="headerlink" title="Escalation Policies"></a>Escalation Policies</h3><p>Escalation Policies are established protocols that dictate when and how an agent should escalate tasks to human operators, preventing errors in situations beyond the agent’s capability.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Content-Moderation"><a href="#Content-Moderation" class="headerlink" title="Content Moderation"></a>Content Moderation</h3><p>AI agents can rapidly filter vast amounts of online content for violations (e.g., hate speech, spam). However, ambiguous cases or borderline content are escalated to human moderators for review and final decision, ensuring nuanced judgment and adherence to complex policies.</p><h3 id="Autonomous-Driving"><a href="#Autonomous-Driving" class="headerlink" title="Autonomous Driving"></a>Autonomous Driving</h3><p>While self-driving cars handle most driving tasks autonomously, they are designed to hand over control to a human driver in complex, unpredictable, or dangerous situations that the AI cannot confidently navigate (e.g., extreme weather, unusual road conditions).</p><h3 id="Financial-Fraud-Detection"><a href="#Financial-Fraud-Detection" class="headerlink" title="Financial Fraud Detection"></a>Financial Fraud Detection</h3><p>AI systems can flag suspicious transactions based on patterns. However, high-risk or ambiguous alerts are often sent to human analysts who investigate further, contact customers, and make the final determination on whether a transaction is fraudulent.</p><h3 id="Legal-Document-Review"><a href="#Legal-Document-Review" class="headerlink" title="Legal Document Review"></a>Legal Document Review</h3><p>AI can quickly scan and categorize thousands of legal documents to identify relevant clauses or evidence. Human legal professionals then review the AI’s findings for accuracy, context, and legal implications, especially for critical cases.</p><h3 id="Customer-Support-Complex-Queries"><a href="#Customer-Support-Complex-Queries" class="headerlink" title="Customer Support (Complex Queries)"></a>Customer Support (Complex Queries)</h3><p>A chatbot might handle routine customer inquiries. If the user’s problem is too complex, emotionally charged, or requires empathy that the AI cannot provide, the conversation is seamlessly handed over to a human support agent.</p><h3 id="Data-Labeling-and-Annotation"><a href="#Data-Labeling-and-Annotation" class="headerlink" title="Data Labeling and Annotation"></a>Data Labeling and Annotation</h3><p>AI models often require large datasets of labeled data for training. Humans are put in the loop to accurately label images, text, or audio, providing the ground truth that the AI learns from. This is a continuous process as models evolve.</p><h3 id="Generative-AI-Refinement"><a href="#Generative-AI-Refinement" class="headerlink" title="Generative AI Refinement"></a>Generative AI Refinement</h3><p>When an LLM generates creative content (e.g., marketing copy, design ideas), human editors or designers review and refine the output, ensuring it meets brand guidelines, resonates with the target audience, and maintains quality.</p><h3 id="Autonomous-Networks"><a href="#Autonomous-Networks" class="headerlink" title="Autonomous Networks"></a>Autonomous Networks</h3><p>AI systems are capable of analyzing alerts and forecasting network issues and traffic anomalies by leveraging key performance indicators (KPIs) and identified patterns. Nevertheless, crucial decisions—such as addressing high-risk alerts—are frequently escalated to human analysts. These analysts conduct further investigation and make the ultimate determination regarding the approval of network changes.</p><h3 id="Automated-financial-trading-system"><a href="#Automated-financial-trading-system" class="headerlink" title="Automated financial trading system"></a>Automated financial trading system</h3><p>In this scenario, a human financial expert sets the overarching investment strategy and rules. For instance, the human might define the policy as: “Maintain a portfolio of 70% tech stocks and 30% bonds, do not invest more than 5% in any single company, and automatically sell any stock that falls 10% below its purchase price.” The AI then monitors the stock market in real-time, executing trades instantly when these predefined conditions are met. The AI is handling the immediate, high-speed actions based on the slower, more strategic policy set by the human operator.</p><h3 id="Modern-call-center"><a href="#Modern-call-center" class="headerlink" title="Modern call center"></a>Modern call center</h3><p>In this setup, a human manager establishes high-level policies for customer interactions. For instance, the manager might set rules such as “any call mentioning ‘service outage’ should be immediately routed to a technical support specialist,” or “if a customer’s tone of voice indicates high frustration, the system should offer to connect them directly to a human agent.” The AI system then handles the initial customer interactions, listening to and interpreting their needs in real-time. It autonomously executes the manager’s policies by instantly routing the calls or offering escalations without needing human intervention for each individual case. This allows the AI to manage the high volume of immediate actions according to the slower, strategic guidance provided by the human operator.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Human-in-the-Loop&quot;&gt;&lt;a href=&quot;#Human-in-the-Loop&quot; class=&quot;headerlink&quot; title=&quot;Human in the Loop&quot;&gt;&lt;/a&gt;Human in the Loop&lt;/h1&gt;&lt;h2 id=&quot;Motiv</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>12_Exception_Handling_and_Recovery</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-12_Exception_Handling_and_Recovery/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-12_Exception_Handling_and_Recovery/</id>
    <published>2025-09-14T05:19:57.000Z</published>
    <updated>2025-09-18T06:26:05.379Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Exception-Handling-and-Recovery"><a href="#Exception-Handling-and-Recovery" class="headerlink" title="Exception Handling and Recovery"></a>Exception Handling and Recovery</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI agents operating in real-world environments inevitably encounter unforeseen situations, errors, and system malfunctions. These disruptions can range from tool failures and network issues to invalid data, threatening the agent’s ability to complete its tasks. Without a structured way to manage these problems, agents can be fragile, unreliable, and prone to complete failure when faced with unexpected hurdles. This unreliability makes it difficult to deploy them in critical or complex applications where consistent performance is essential.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>This pattern focuses on developing exceptionally durable and resilient agents that can maintain uninterrupted functionality and operational integrity despite various difficulties and anomalies. </p><p>The capacity to handle unexpected events ensures these AI systems are not only intelligent but also stable and reliable, which fosters greater confidence in their deployment and performance. Integrating comprehensive monitoring and diagnostic tools further strengthens an agent’s ability to quickly identify and address issues, preventing potential disruptions and ensuring smoother operation in evolving conditions.</p><p>This pattern may sometimes be used with reflection. For example, if an initial attempt fails and raises an exception, a reflective process can analyze the failure and reattempt the task with a refined approach, such as an improved prompt, to resolve the error.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The Exception Handling and Recovery pattern addresses the need for AI agents to manage operational failures. This pattern involves anticipating potential issues, such as tool errors or service unavailability, and developing strategies to mitigate them. </p><p>These strategies may include error logging, retries, fallbacks, graceful degradation, and notifications. </p><p>Additionally, the pattern emphasizes recovery mechanisms like state rollback, diagnosis, selation, to lf-correction, and escarestore agents to stable operation.</p><p><img src="" alt="img"></p><h3 id="Error-Detection"><a href="#Error-Detection" class="headerlink" title="Error Detection"></a>Error Detection</h3><p>This involves meticulously identifying operational issues as they arise. </p><p>This could manifest as invalid or malformed tool outputs, specific API errors such as 404 (Not Found) or 500 (Internal Server Error) codes, unusually long response times from services or APIs, or incoherent and nonsensical responses that deviate from expected formats. </p><p>Additionally, monitoring by other agents or specialized monitoring systems might be implemented for more proactive anomaly detection, enabling the system to catch potential issues before they escalate.</p><h3 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling"></a>Error Handling</h3><p>Once an error is detected, a carefully thought-out response plan is essential. </p><p>This includes:</p><ul><li>Recording error details meticulously in logs for later debugging and analysis (logging). </li><li>Retrying the action or request, sometimes with slightly adjusted parameters, may be a viable strategy, especially for transient errors (retries). </li><li>Utilizing alternative strategies or methods (fallbacks) can ensure that some functionality is maintained. </li></ul><p>Where complete recovery is not immediately possible, the agent can maintain partial functionality to provide at least some value (graceful degradation). </p><p>Finally, alerting human operators or other agents might be crucial for situations that require human intervention or collaboration (notification).</p><h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h3><p>This stage is about restoring the agent or system to a stable and operational state after an error. </p><p>It could involve reversing recent changes or transactions to undo the effects of the error (state rollback). </p><p>A thorough investigation into the cause of the error is vital for preventing recurrence. </p><ul><li>Adjusting the agent’s plan, logic, or parameters through a self-correction mechanism or replanning process may be needed to avoid the same error in the future. </li><li>In complex or severe cases, delegating the issue to a human operator or a higher-level system (escalation) might be the best course of action.</li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Customer-Service-Chatbots"><a href="#Customer-Service-Chatbots" class="headerlink" title="Customer Service Chatbots"></a>Customer Service Chatbots</h3><ul><li>Problem:<ul><li>If a chatbot tries to access a customer database and the database is temporarily down, it shouldn’t crash. </li></ul></li><li>Solution:<ul><li>Instead, it should detect the API error, inform the user about the temporary issue, perhaps suggest trying again later, or escalate the query to a human agent.</li></ul></li></ul><h3 id="Automated-Financial-Trading"><a href="#Automated-Financial-Trading" class="headerlink" title="Automated Financial Trading"></a>Automated Financial Trading</h3><ul><li>Problem: <ul><li>A trading bot attempting to execute a trade might encounter an “insufficient funds” error or a “market closed” error. </li></ul></li><li>Solution:<ul><li>It needs to handle these exceptions by logging the error, not repeatedly trying the same invalid trade, and potentially notifying the user or adjusting its strategy.</li></ul></li></ul><h3 id="Smart-Home-Automation"><a href="#Smart-Home-Automation" class="headerlink" title="Smart Home Automation"></a>Smart Home Automation</h3><ul><li>Problem: <ul><li>An agent controlling smart lights might fail to turn on a light due to a network issue or a device malfunction.</li></ul></li><li>Solution:<ul><li>It should detect this failure, perhaps retry, and if still unsuccessful, notify the user that the light could not be turned on and suggest manual intervention.</li></ul></li></ul><h3 id="Data-Processing-Agents"><a href="#Data-Processing-Agents" class="headerlink" title="Data Processing Agents"></a>Data Processing Agents</h3><ul><li>Problem:<ul><li>An agent tasked with processing a batch of documents might encounter a corrupted file. </li></ul></li><li>Solution:<ul><li>It should skip the corrupted file, log the error, continue processing other files, and report the skipped files at the end rather than halting the entire process.</li></ul></li></ul><h3 id="Web-Scraping-Agents"><a href="#Web-Scraping-Agents" class="headerlink" title="Web Scraping Agents"></a>Web Scraping Agents</h3><ul><li>Problem:<ul><li>A web scraping agent encounters a CAPTCHA, a changed website structure, or a server error (e.g., 404 Not Found, 503 Service Unavailable).</li></ul></li><li>Solution:<ul><li>It needs to handle these gracefully. This could involve pausing, using a proxy, or reporting the specific URL that failed.</li></ul></li></ul><h3 id="Robotics-and-Manufacturing"><a href="#Robotics-and-Manufacturing" class="headerlink" title="Robotics and Manufacturing"></a>Robotics and Manufacturing</h3><ul><li>Problem:<ul><li>A robotic arm performing an assembly task might fail to pick up a component due to misalignment. </li></ul></li><li>Solution:<ul><li>It needs to detect this failure (e.g., via sensor feedback), attempt to readjust, retry the pickup, and if persistent, alert a human operator or switch to a different component.</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Exception-Handling-and-Recovery&quot;&gt;&lt;a href=&quot;#Exception-Handling-and-Recovery&quot; class=&quot;headerlink&quot; title=&quot;Exception Handling and Recover</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>11_Goal_Setting_and_Monitoring</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-11_Goal_Setting_and_Monitoring/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-11_Goal_Setting_and_Monitoring/</id>
    <published>2025-09-14T05:19:30.000Z</published>
    <updated>2025-09-18T05:13:04.560Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Goal-Setting-and-Monitoring"><a href="#Goal-Setting-and-Monitoring" class="headerlink" title="Goal Setting and Monitoring"></a>Goal Setting and Monitoring</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI agents often lack a clear direction, preventing them from acting with purpose beyond simple, reactive tasks. Without defined objectives, they cannot independently tackle complex, multi-step problems or orchestrate sophisticated workflows. Furthermore, there is no inherent mechanism for them to determine if their actions are leading to a successful outcome. This limits their autonomy and prevents them from being truly effective in dynamic, real-world scenarios where mere task execution is insufficient.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>In the context of AI agents, planning typically involves an agent taking a high-level objective and autonomously, or semi-autonomously, generating a series of intermediate steps or sub-goals. These steps can then be executed sequentially or in a more complex flow, potentially involving other patterns like tool use, routing, or multi-agent collaboration. The planning mechanism might involve sophisticated search algorithms, logical reasoning, or increasingly, leveraging the capabilities of large language models (LLMs) to generate plausible and effective plans based on their training data and understanding of tasks.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>An autonomous AI agent engineered to generate and refine Python code. Its core function is to produce solutions for specified problems, ensuring adherence to user-defined quality benchmarks.</p><p>It employs a “goal-setting and monitoring” pattern where it doesn’t just generate code once, but enters into an iterative cycle of creation, self-evaluation, and improvement. The agent’s success is measured by its own AI-driven judgment on whether the generated code successfully meets the initial objectives. The ultimate output is a polished, commented, and ready-to-use Python file that represents the culmination of this refinement process.</p><p>The process begins when you hand the AI a detailed project brief, which is the specific coding problem it needs to solve. Along with this brief, you provide a strict quality checklist, which represents the objectives the final code must meet—criteria like “the solution must be simple,” “it must be functionally correct,” or “it needs to handle unexpected edge cases.”</p><p>With this assignment in hand, the AI programmer gets to work and produces its first draft of the code. However, instead of immediately submitting this initial version, it pauses to perform a crucial step: a rigorous self-review. It meticulously compares its own creation against every item on the quality checklist you provided, acting as its own quality assurance inspector. After this inspection, it renders a simple, unbiased verdict on its own progress: “True” if the work meets all standards, or “False” if it falls short.</p><p>If the verdict is “False,” the AI doesn’t give up. It enters a thoughtful revision phase, using the insights from its self-critique to pinpoint the weaknesses and intelligently rewrite the code. This cycle of drafting, self-reviewing, and refining continues, with each iteration aiming to get closer to the goals. This process repeats until the AI finally achieves a “True” status by satisfying every requirement, or until it reaches a predefined limit of attempts, much like a developer working against a deadline. Once the code passes this final inspection, the script packages the polished solution, adding helpful comments and saving it to a clean, new Python file, ready for use.</p><p>An LLM may not fully grasp the intended meaning of a goal and might incorrectly assess its performance as successful. Even if the goal is well understood, the model may hallucinate. When the same LLM is responsible for both writing the code and judging its quality, it may have a harder time discovering it is going in the wrong direction. </p><p>A more robust approach involves separating these concerns by giving specific roles to a crew of agents.</p><ul><li>The Peer Programmer: Helps write and brainstorm code.</li><li>The Code Reviewer: Catches errors and suggests improvements.</li><li>The Document Writer: Generates clear and concise documentation.</li><li>The Test Writer: Creates comprehensive unit tests.</li><li>The Prompt Refiner: Optimizes interactions with the AI.</li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Customer-Support-Automation"><a href="#Customer-Support-Automation" class="headerlink" title="Customer Support Automation"></a>Customer Support Automation</h3><p>An agent’s goal might be to “resolve customer’s billing inquiry.” It monitors the conversation, checks database entries, and uses tools to adjust billing. Success is monitored by confirming the billing change and receiving positive customer feedback. If the issue isn’t resolved, it escalates.</p><h3 id="Personalized-Learning-Systems"><a href="#Personalized-Learning-Systems" class="headerlink" title="Personalized Learning Systems"></a>Personalized Learning Systems</h3><p>A learning agent might have the goal to “improve students’ understanding of algebra.” It monitors the student’s progress on exercises, adapts teaching materials, and tracks performance metrics like accuracy and completion time, adjusting its approach if the student struggles.</p><h3 id="Project-Management-Assistants"><a href="#Project-Management-Assistants" class="headerlink" title="Project Management Assistants"></a>Project Management Assistants</h3><p>An agent could be tasked with “ensuring project milestone X is completed by Y date.” It monitors task statuses, team communications, and resource availability, flagging delays and suggesting corrective actions if the goal is at risk.</p><h3 id="Automated-Trading-Bots"><a href="#Automated-Trading-Bots" class="headerlink" title="Automated Trading Bots"></a>Automated Trading Bots</h3><p>A trading agent’s goal might be to “maximize portfolio gains while staying within risk tolerance.” It continuously monitors market data, its current portfolio value, and risk indicators, executing trades when conditions align with its goals and adjusting strategy if risk thresholds are breached.</p><h3 id="Robotics-and-Autonomous-Vehicles"><a href="#Robotics-and-Autonomous-Vehicles" class="headerlink" title="Robotics and Autonomous Vehicles"></a>Robotics and Autonomous Vehicles</h3><p>An autonomous vehicle’s primary goal is “safely transport passengers from A to B.” It constantly monitors its environment (other vehicles, pedestrians, traffic signals), its own state (speed, fuel), and its progress along the planned route, adapting its driving behavior to achieve the goal safely and efficiently.</p><h3 id="Content-Moderation"><a href="#Content-Moderation" class="headerlink" title="Content Moderation"></a>Content Moderation</h3><p>An agent’s goal could be to “identify and remove harmful content from platform X.” It monitors incoming content, applies classification models, and tracks metrics like false positives/negatives, adjusting its filtering criteria or escalating ambiguous cases to human reviewers.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Goal-Setting-and-Monitoring&quot;&gt;&lt;a href=&quot;#Goal-Setting-and-Monitoring&quot; class=&quot;headerlink&quot; title=&quot;Goal Setting and Monitoring&quot;&gt;&lt;/a&gt;Goal </summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>10_Model_Context_Protocol</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-10_Model_Context_Protocol/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-10_Model_Context_Protocol/</id>
    <published>2025-09-14T05:19:08.000Z</published>
    <updated>2025-09-18T04:48:31.716Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Model-Context-Protocol-MCP"><a href="#Model-Context-Protocol-MCP" class="headerlink" title="Model Context Protocol (MCP)"></a>Model Context Protocol (MCP)</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Without a standardized communication method, each integration between an LLM and an external tool or data source becomes a custom, complex, and non-reusable effort. This ad-hoc approach hinders scalability and makes building complex, interconnected AI systems difficult and inefficient.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>The Model Context Protocol (MCP) offers a standardized solution by acting as a universal interface between LLMs and external systems. It establishes an open, standardized protocol that defines how external capabilities are discovered and used.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>MCP operates on a client-server architecture. </p><ul><li>LLM: <ul><li>The core intelligence. It processes user requests, formulates plans, and decides when it needs to access external information or perform an action.</li></ul></li><li>Server: <ul><li>MCP server exposes different elements which are from Third-Party (3P) Service, and then are consumed by an authorized MCP client: <ul><li>Resources (data): Static data. </li><li>Tools (actionable functions): An executable function that performs an action.</li><li>Prompts (interactive templates): A template that guides the LLM in how to interact with a resource or tool, ensuring the interaction is structured and effective.</li></ul></li><li>Each server is typically responsible for a specific domain, such as a connection to a company’s internal database, an email service, or a public API.</li></ul></li><li>Client: <ul><li>MCP client could be a LLM host application or an AI Agent. </li><li>It acts as the intermediary, translating the LLM’s intent into a formal request that conforms to the MCP standard. </li><li>It is responsible for discovering, connecting to, and communicating with MCP Servers.</li></ul></li></ul><h3 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h3><p>MCP defines the underlying transport layers for communication. </p><ul><li>For local interactions, it uses JSON-RPC over STDIO (standard input/output) for efficient inter-process communication. </li><li>For remote connections, it leverages web-friendly protocols like Streamable HTTP and Server-Sent Events (SSE) to enable persistent and efficient client-server communication.</li></ul><p>The interaction flows as follows:</p><ul><li>Discovery: <ul><li>The MCP Client, on behalf of the LLM, queries an MCP Server to ask what capabilities it offers. The server responds with a manifest listing its available tools, resources, and prompts.</li></ul></li><li>Request Formulation:<ul><li>The LLM determines that it needs to use one of the discovered tools. It formulates a request, specifying the tool to use and the necessary parameters.</li></ul></li><li>Client Communication:<ul><li>The MCP Client takes the LLM’s formulated request and sends it as a standardized call to the appropriate MCP Server.</li></ul></li><li>Server Execution:<ul><li>The MCP Server receives the request. It authenticates the client, validates the request, and then executes the specified action by interfacing with the underlying software.</li></ul></li><li>Response and Context Update: <ul><li>After execution, the MCP Server sends a standardized response back to the MCP Client. This response indicates whether the action was successful and includes any relevant output. The client then passes this result back to the LLM, updating its context and enabling it to proceed with the next step of its task.</li></ul></li></ul><h2 id="Applicable-scenarios"><a href="#Applicable-scenarios" class="headerlink" title="Applicable scenarios"></a>Applicable scenarios</h2><p>The Model Context Protocol (MCP) operates as a standardized interface for LLMs to discover, communicate with, and utilize external capabilities. </p><p>It functions as an open protocol that facilitates interaction with a wide range of tools and systems, aiming to establish an ecosystem where any compliant tool can be accessed by any compliant LLM. </p><p>This fosters interoperability, composability and reusability across different systems and implementations.</p><h3 id="Database-Integration"><a href="#Database-Integration" class="headerlink" title="Database Integration"></a>Database Integration</h3><p>MCP allows LLMs and agents to seamlessly access and interact with structured data in databases through natural language commands.</p><h3 id="Generative-Media-Orchestration"><a href="#Generative-Media-Orchestration" class="headerlink" title="Generative Media Orchestration"></a>Generative Media Orchestration</h3><p>MCP enables agents to integrate with advanced generative media services.</p><h3 id="External-API-Interaction"><a href="#External-API-Interaction" class="headerlink" title="External API Interaction"></a>External API Interaction</h3><p>MCP provides a standardized way for LLMs to call and receive responses from any external API.</p><h3 id="Reasoning-Based-Information-Extraction"><a href="#Reasoning-Based-Information-Extraction" class="headerlink" title="Reasoning-Based Information Extraction"></a>Reasoning-Based Information Extraction</h3><p>Leveraging an LLM’s strong reasoning skills, MCP facilitates effective, query-dependent information extraction that surpasses conventional search and retrieval systems. Instead of a traditional search tool returning an entire document, an agent can analyze the text and extract the precise clause, figure, or statement that directly answers a user’s complex question.</p><h3 id="Custom-Tool-Development"><a href="#Custom-Tool-Development" class="headerlink" title="Custom Tool Development"></a>Custom Tool Development</h3><p>Developers can build custom tools and expose them via an MCP server. This allows specialized internal functions or proprietary systems to be made available to LLMs and other agents in a standardized, easily consumable format, without needing to modify the LLM directly.</p><h3 id="Standardized-LLM-to-Application-Communication"><a href="#Standardized-LLM-to-Application-Communication" class="headerlink" title="Standardized LLM-to-Application Communication"></a>Standardized LLM-to-Application Communication</h3><p>MCP ensures a consistent communication layer between LLMs and the applications they interact with. This reduces integration overhead, promotes interoperability between different LLM providers and host applications, and simplifies the development of complex agentic systems.</p><h3 id="Complex-Workflow-Orchestration"><a href="#Complex-Workflow-Orchestration" class="headerlink" title="Complex Workflow Orchestration"></a>Complex Workflow Orchestration</h3><p>By combining various MCP-exposed tools and data sources, agents can orchestrate highly complex, multi-step workflows. An agent could, for example, retrieve customer data from a database, generate a personalized marketing image, draft a tailored email, and then send it, all by interacting with different MCP services.</p><h3 id="IoT-Device-Control"><a href="#IoT-Device-Control" class="headerlink" title="IoT Device Control"></a>IoT Device Control</h3><p>MCP can facilitate LLM interaction with Internet of Things (IoT) devices. An agent could use MCP to send commands to smart home appliances, industrial sensors, or robotics, enabling natural language control and automation of physical systems.</p><h3 id="Financial-Services-Automation"><a href="#Financial-Services-Automation" class="headerlink" title="Financial Services Automation"></a>Financial Services Automation</h3><p>In financial services, MCP could enable LLMs to interact with various financial data sources, trading platforms, or compliance systems. An agent might analyze market data, execute trades, generate personalized financial advice, or automate regulatory reporting, all while maintaining secure and standardized communication.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The Agent Development Kit (ADK) supports both utilizing existing MCP servers and exposing ADK tools via an MCP server.</p><p>FastMCP simplifies the development and management of MCP servers, particularly for exposing tools implemented in Python.</p><p>MCP Tools for Genmedia Services allows agents to integrate with Google Cloud’s generative media capabilities (Imagen, Veo, Chirp 3 HD, Lyria).</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Model-Context-Protocol-MCP&quot;&gt;&lt;a href=&quot;#Model-Context-Protocol-MCP&quot; class=&quot;headerlink&quot; title=&quot;Model Context Protocol (MCP)&quot;&gt;&lt;/a&gt;Model </summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>9_Learning_and_Adaptation</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-9_Learning_and_Adaptation/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-9_Learning_and_Adaptation/</id>
    <published>2025-09-14T05:18:40.000Z</published>
    <updated>2025-09-17T05:46:40.737Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-and-Adaptation"><a href="#Learning-and-Adaptation" class="headerlink" title="Learning and Adaptation"></a>Learning and Adaptation</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>AI agents often operate in dynamic and unpredictable environments where pre-programmed logic is insufficient. Their performance can degrade when faced with novel situations not anticipated during their initial design. Without the ability to learn from experience, agents cannot optimize their strategies or personalize their interactions over time. This rigidity limits their effectiveness and prevents them from achieving true autonomy in complex, real-world scenarios.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Learning and adaptation are pivotal for enhancing the capabilities of artificial intelligence agents. These processes enable agents to evolve beyond predefined parameters, allowing them to improve autonomously through experience and environmental interaction. By learning and adapting, agents can effectively manage novel situations and optimize their performance without constant manual intervention. </p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>Agents adapt by changing strategy, understanding, or goals based on learning. This is vital for agents in unpredictable, changing, or new environments.</p><h3 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h3><p>Agents try actions and receive rewards for positive outcomes and penalties for negative ones, learning optimal behaviors in changing situations. </p><p>Useful for agents controlling robots or playing games.</p><h3 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h3><p>Agents learn from labeled examples, connecting inputs to desired outputs, enabling tasks like decision-making and pattern recognition. </p><p>Ideal for agents sorting emails or predicting trends.</p><h3 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h3><p>Agents discover hidden connections and patterns in unlabeled data, aiding in sights, organization, and creating a mental map of their environment.</p><p>Useful for agents exploring data without specific guidance.</p><h3 id="Few-Shot-Zero-Shot-Learning-with-LLM-Based-Agents"><a href="#Few-Shot-Zero-Shot-Learning-with-LLM-Based-Agents" class="headerlink" title="Few-Shot/Zero-Shot Learning with LLM-Based Agents"></a>Few-Shot/Zero-Shot Learning with LLM-Based Agents</h3><p>Agents leveraging LLMs can quickly adapt to new tasks with minimal examples or clear instructions, enabling rapid responses to new commands or situations.</p><h3 id="Online-Learning"><a href="#Online-Learning" class="headerlink" title="Online Learning"></a>Online Learning</h3><p>Agents continuously update knowledge with new data, essential for real-time reactions and ongoing adaptation in dynamic environments. </p><p>Critical for agents processing continuous data streams.</p><h3 id="Memory-Based-Learning"><a href="#Memory-Based-Learning" class="headerlink" title="Memory-Based Learning"></a>Memory-Based Learning</h3><p>Agents recall past experiences to adjust current actions in similar situations, enhancing context awareness and decision-making.</p><p>Effective for agents with memory recall capabilities.</p><h3 id="Proximal-Policy-Optimization-PPO"><a href="#Proximal-Policy-Optimization-PPO" class="headerlink" title="Proximal Policy Optimization (PPO)"></a>Proximal Policy Optimization (PPO)</h3><p>This is a reinforcement learning algorithm used to train agents in environments with a continuous range of actions, like controlling a robot’s joints or a character in a game. Its main goal is to reliably and stably improve an agent’s decision-making strategy, known as its policy.</p><p>The core idea behind PPO is to make small, careful updates to the agent’s policy. It avoids drastic changes that could cause performance to collapse. Here’s how it works:</p><ul><li>Train a Reward Model, and Collect Data:<ul><li>The agent interacts with its environment (e.g., plays a game) using its current policy and collects a batch of experiences (state, action, reward).</li></ul></li><li>Fine-Tune with PPO: <ul><li>The LLM’s goal is to generate responses that get the highest possible score from the reward model. The reward model acts as the “judge” in the training game. (However, LLM might find a loophole and learn the “hack” the reward model to get high scores for bad responses)</li></ul></li><li>Evaluate a “Surrogate” Goal:<ul><li>PPO calculates how a potential policy update would change the expected reward. However, instead of just maximizing this reward, it uses a special “clipped” objective function.</li></ul></li><li>The “Clipping” Mechanism: <ul><li>This is the key to PPO’s stability. It creates a “trust region” or a safe zone around the current policy. </li><li>The algorithm is prevented from making an update that is too different from the current strategy. </li><li>This clipping acts like a safety brake, ensuring the agent doesn’t take a huge, risky step that undoes its learning.</li></ul></li></ul><p>PPO balances improving performance with staying close to a known, working strategy, which prevents catastrophic failures during training and leads to more stable learning.</p><h3 id="Direct-Preference-Optimization-DPO"><a href="#Direct-Preference-Optimization-DPO" class="headerlink" title="Direct Preference Optimization (DPO)"></a>Direct Preference Optimization (DPO)</h3><p>This is a more recent method designed specifically for aligning LLMs with human preferences. It offers a simpler, more direct alternative to using PPO for this task.</p><p>DPO skips the reward model entirely. Instead of translating human preferences into a reward score and then optimizing for that score, DPO uses the preference data directly to update the LLM’s policy.</p><p>It works by using a mathematical relationship that directly links preference data to the optimal policy. </p><p>It essentially teaches the model:</p><ul><li>Increase the probability of generating responses like the preferred one.</li><li>Decrease the probability of generating responses like the disfavored one.</li></ul><p>DPO simplifies alignment by directly optimizing the language model on human preference data. This avoids the complexity and potential instability of training and using a separate reward model, making the alignment process more efficient and robust.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><h3 id="Personalized-assistant-agents"><a href="#Personalized-assistant-agents" class="headerlink" title="Personalized assistant agents"></a>Personalized assistant agents</h3><p>It refines interaction protocols through longitudinal analysis of individual user behaviors, ensuring highly optimized response generation.</p><h3 id="Trading-bot-agents"><a href="#Trading-bot-agents" class="headerlink" title="Trading bot agents"></a>Trading bot agents</h3><p>It optimizes decision-making algorithms by dynamically adjusting model parameters based on high-resolution, real-time market data, thereby maximizing financial returns and mitigating risk factors.</p><h3 id="Application-agents"><a href="#Application-agents" class="headerlink" title="Application agents"></a>Application agents</h3><p>It optimizes user interface and functionality through dynamic modification based on observed user behavior, resulting in increased user engagement and system intuitiveness.</p><h3 id="Robotic-and-autonomous-vehicles-agents"><a href="#Robotic-and-autonomous-vehicles-agents" class="headerlink" title="Robotic and autonomous vehicles agents"></a>Robotic and autonomous vehicles agents</h3><p>It enhances navigation and response capabilities by integrating sensor data and historical action analysis, enabling safe and efficient operation across diverse environmental conditions.</p><h3 id="Fraud-detection-agents"><a href="#Fraud-detection-agents" class="headerlink" title="Fraud detection agents"></a>Fraud detection agents</h3><p>It improves anomaly detection by refining predictive models with newly identified fraudulent patterns, enhancing system security and minimizing financial losses.</p><h3 id="Recommendation-agents"><a href="#Recommendation-agents" class="headerlink" title="Recommendation agents"></a>Recommendation agents</h3><p>It improves content selection precision by employing user preference learning algorithms, providing highly individualized and contextually relevant recommendations.</p><h3 id="Game-AI-Agents"><a href="#Game-AI-Agents" class="headerlink" title="Game AI Agents"></a>Game AI Agents</h3><p>It enhances player engagement by dynamically adapting strategic algorithms, thereby increasing game complexity and challenge.</p><h3 id="Knowledge-Base-Learning-Agents"><a href="#Knowledge-Base-Learning-Agents" class="headerlink" title="Knowledge Base Learning Agents"></a>Knowledge Base Learning Agents</h3><p>It can leverage Retrieval Augmented Generation (RAG) to maintain a dynamic knowledge base of problem descriptions and proven solutions. By storing successful strategies and challenges encountered, the agent can reference this data during decision-making, enabling it to adapt to new situations more effectively by applying previously successful patterns or avoiding known pitfalls.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><h3 id="The-Self-Improving-Coding-Agent-SICA"><a href="#The-Self-Improving-Coding-Agent-SICA" class="headerlink" title="The Self-Improving Coding Agent (SICA)"></a>The Self-Improving Coding Agent (SICA)</h3><p>It represents an advancement in agent-based learning, demonstrating the capacity for an agent to modify its own source code, without requiring traditional training paradigms. It acts as both the modifier and the modified entity, iteratively refining its code base to improve performance across various coding challenges.</p><ul><li>SICA reviews an archive of its past versions and their performance on benchmark tests.</li><li>SICA selects the version with the highest performance score, calculated based on a weighted formula considering success, time and computational cost.</li><li>This selected version then undertakes the next round of self-modification. </li><li>It analyzes the archive to identify potential improvements and then directly alters its codebase. </li><li>The modified agent is subsequently tested against benchmarks, with the results recorded in the archive.</li><li>This process repeats, facilitating learning directly from past performance. </li></ul><p>SICA uses Abstract Syntax Trees (AST) parsing for efficiency. Additionally, a “SmartEditor Input Normalizer” was added. In terms of navigation, SICA independently created an “AST Symbol Locator”, using the code’s structural map to identify definitions within the codebase. Later, a “Hybrid Symbol Locator” was developed, combining a quick search with AST checking. This was further optimized via “Optimized AST Parsing in Hybrid Symbol Locator” to focus on relevant code sections, improving search speed.</p><p>A critical component is the asynchronous overseer, an LLM that runs concurrently with the main agent. This overseer periodically assesses the agent’s behavior for pathological deviations or stagnation and can intervene by sending notifications or even cancelling the agent’s execution if necessary. It receives a detailed textual representation of the system’s state, including a callgraph and an event stream of LLM messages, tool calls, and responses, which allows it to detect inefficient patterns or repeated work.</p><p><a href="https://github.com/MaximeRobeyns/self_improving_coding_agent/">SICA Github Repository</a></p><h3 id="AlphaEvolve"><a href="#AlphaEvolve" class="headerlink" title="AlphaEvolve"></a>AlphaEvolve</h3><p>AlphaEvolve is an AI agent developed by Google designed to discover and optimize algorithms. </p><p>It utilizes a combination of LLMs, specifically Gemini models (Flash and Pro), automated evaluation systems, and an evolutionary algorithm framework. </p><ul><li>Flash is used for generating a wide range of initial algorithm proposals.</li><li>Pro provides more in-depth analysis and refinement.</li></ul><p>This system aims to advance both theoretical mathematics and practical computing applications.</p><h3 id="OpenEvolve"><a href="#OpenEvolve" class="headerlink" title="OpenEvolve"></a>OpenEvolve</h3><p>OpenEvolve is an evolutionary coding agent that leverages LLMs to iteratively optimize code. </p><p>It orchestrates a pipeline of LLM-driven code generation, evaluation, and selection to continuously enhance programs for a wide range of tasks.</p><p>A key aspect of OpenEvolve is its capability to evolve entire code files rather than being limited to single functions. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Learning-and-Adaptation&quot;&gt;&lt;a href=&quot;#Learning-and-Adaptation&quot; class=&quot;headerlink&quot; title=&quot;Learning and Adaptation&quot;&gt;&lt;/a&gt;Learning and Adap</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>8. Memory Management</title>
    <link href="http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-8_Memory_Management/"/>
    <id>http://zjn-astonishe.github.io/2025/09/14/Agent/2025-09-14-8_Memory_Management/</id>
    <published>2025-09-14T05:17:58.000Z</published>
    <updated>2025-09-16T06:52:26.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Agentic systems need to remember information from past interactions to perform complex tasks and provide coherent experiences. </p><p>Without a memory mechanism, agents are stateless, unable to maintain conversational context, learn from experience, or personalize responses for users. </p><p>This fundamentally limits them to simple, one-shot interactions, failing to handle multi-step processes or evolving user needs. </p><p>The core problem is how to effectively manage both the immediate, temporary information of a single conversation and the vast, persistent knowledge gathered over time.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>In agent systems, memory refers to an agent’s ability to retain and utilize information from past interactions, observations, and learning experiences. This capability allows agents to make informed decisions, maintain conversational context, and improve over time.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>Agent memory is generally categorized into two main types:</p><ul><li>Short-Term Memory (Contextual Memory):<ul><li>This memory holds information currently being processed or recently accessed.</li><li>This memory primarily exists within the context window which contains recent messages, agent replies, tool usage results, and agent reflections from the current interaction. All inform the LLM’s subsequent responses and actions. </li><li>The context window has a limited capacity, restricting the amount of recent information an agent can directly access. <ul><li>Efficient short-term memory management involves keeping the most relevant information within this limited space, summarizing older conversation segments or emphasizing key details.</li><li>Long Context windows simply expands the size of this short-term memory, allowing more information to be held within a single interaction.</li></ul></li><li>However, it is still ephemeral and is lost once the session concludes, and it can be costly and inefficient to process every time. </li></ul></li><li>Long-Term Memory (Persistent Memory):<ul><li>This memory acts as a repository for information agents need to retain across various interactions, tasks or extended periods, akin to long-term knowledge bases.<ul><li>Data is typically stored outside the agent’s immediate processing environment, often in databases, knowledge graphs, or vector databases.</li><li>In vector databases, information is converted into numerical vectors and stored, enabling agents to retrieve data based on semantic similarity rather than exact keyword matches, a process known as semantic search.</li></ul></li><li>When an agent needs information from long-term memory, it queries the external storage, retrieves relevant data, and integrates it into the short-term context for immediate use, thus combining prior knowledge with the current interaction.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when an agent needs to do more than answer a single question. It is essential for agents that must maintain context throughout a conversation, track progress in multi-step tasks, or personalize interactions by recalling user preferences and history. Implement memory management whenever the agent is expected to learn or adapt based on past successes, failures, or newly acquired information.</p><ul><li>Chatbots and Conversational AI<ul><li>Maintaining conversation flow relies on Short-term memory, so that they can remember prior user inputs to provide coherent responses.  </li><li>Long-term memory enables chatbots to recall user preferences, past issues, or prior discussions, offering personalized and continuous interactions.</li></ul></li><li>Task-Oriented Agent<ul><li>Managing mult-step tasks need short-term memory to track previous steps, current progress, and overall goals, which might reside in the task’s context or temporary storage.</li><li>Long-term memory is crucial for accessing specific user-related data not in the immediate context.</li></ul></li><li>Personalized Experiences<ul><li>Agent utilize long-term memory to store and retrieve user preferences, past behaviors, and personal information. This allows agents to adapt their responses and suggestions.</li></ul></li><li>Learning and Improvement<ul><li>Agents can refine their performance by learning from past interactions. Successful strategies, mistakes, and new information are stored in long-term memory, facilitating future adaptation. Reinforcement learning agents store learned strategies or knowledge in this way. </li></ul></li><li>Information Retrieval (RAG)<ul><li>Agents designed for answering questions access a knowledge base, their long-term memory, often implemented within Retrieval Augmented Generation (RAG). The agent retrieves relevant documents or data to inform its responses.</li></ul></li><li>Autonomous Systems<ul><li>Robots or self-driving cars require memory for maps, routes, object locations, and learned behaviors. This involves short-term memory for immediate surroundings and long-term memory for general environmental knowledge.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><h3 id="Google-ADK"><a href="#Google-ADK" class="headerlink" title="Google ADK"></a>Google ADK</h3><p>Agentic frameworks like the Google ADK provide specific components to manage this, such as Session for the conversation thread and State for its temporary data. A dedicated MemoryService is used to interface with the long-term knowledge base, allowing the agent to retrieve and incorporate relevant past information into its current context.</p><p>The Google Agent Developer Kit (ADK) offers a structured method for managing context and memory, including components for practical application. A solid grasp of ADK’s Session, State and Memory is vital for building agents that need to retain information. </p><p>Every interaction with an agent can be considered a unique conversation thread. </p><h4 id="Session-Keeping-Track-of-Each-Chat"><a href="#Session-Keeping-Track-of-Each-Chat" class="headerlink" title="Session: Keeping Track of Each Chat"></a>Session: Keeping Track of Each Chat</h4><p>An individual chat thread that logs messages and actions (Events) for that specific interaction, also storing temporary data (State) relevant to that conversation.</p><p>The SessionService manages chat threads (Session objects) by handling their initiation, recording, and termination.</p><p>A Session object in ADK is designed to track and manage individual chat threads. </p><ul><li>Developers typically interact with Session objects indirectly through the SessionService. Upon initiation of a conversation with an agent, the SessionService generates a Session object, represented as “google.adk.sessions.Session”. This object encapsulates all data relevant to a specific conversation thread, including: <ul><li>Unique identifiers “(id, app_name, user_id)”, </li><li>A chronological record of events as “Event objects”, </li><li>A storage area for session-specific temporary data known as “State”</li><li>A timestamp indicating the last update “last_update_time”</li></ul></li></ul><p>The SessionService is responsible for managing the lifecycle of conversation sessions, which includes: </p><ul><li>Initiating new sessions, </li><li>Resuming previous sessions, </li><li>Recording session activity (including state updates), </li><li>Identifying active sessions, </li><li>Managing the removal of session data. </li></ul><p>The ADK provides several SessionService implementations with varying storage mechanisms for session history and temporary data, which determines how the agent’s interaction history and temporary data are stored and their persistence, such as:</p><ul><li>The “InMemorySessionService”, which is suitable for testing but does not provide data persistence across application restarts.</li><li>There is “DatabaseSessionService” if you want reliable saving to a database you manage. </li><li>There is also “VertexAiSessionService” which uses Vertex AI infrastructure for scalable production on Google Cloud.</li></ul><p>Each message exchange involves a cyclical process: </p><ul><li>A message is received, the Runner retrieves or establishes a Session using the SessionService, </li><li>The agent processes the message using the Session’s context (state and historical interactions), </li><li>The agent generates a response and may update the state.</li><li>The Runner encapsulates the response as an Event, and the “session_service.append_event” method records the new event and updates the state in storage. </li><li>The Session then awaits the next message. </li><li>Ideally, the “delete_session” method is employed to terminate the session when the interaction concludes. </li></ul><h4 id="State-The-Session’s-Scratchpad"><a href="#State-The-Session’s-Scratchpad" class="headerlink" title="State: The Session’s Scratchpad"></a>State: The Session’s Scratchpad</h4><p>Data stored within a Session, containing information relevant only to the current, active chat thread. </p><p>Each Session, representing a chat thread, includes a State component akin to an agent’s temporary working memory for the duration of that specific conversation. </p><ul><li>“session.events” logs the entire chat history, </li><li>“session.state” stores and updates dynamic data points relevant to the active chat. It operates as a dictionary, storing data as key-value pairs. Its core function is to enable the agent to retain and manage details essential for coherent dialogue, such as: <ul><li>user preferences,</li><li>task progress,</li><li>incremental data collection,</li><li>conditional flags influencing subsequent agent actions.</li></ul></li></ul><p>The state’s structure comprises string keys paired with values of serializable Python types, including strings, numbers, booleans, lists, and dictionaries containing these basic types. </p><p>State is dynamic, evolving throughout the conversation. The permanence of these changes depends on the configured SessionService.</p><p>State organization can be achieved using key prefixes to define data scope and persistence. Keys without prefixes are session-specific. </p><ul><li>The “user”: prefix associates data with a user ID across all sessions.</li><li>The “app”: prefix designates data shared among all users of the application.</li><li>The “temp”: prefix indicates data valid only for the current processing turn and is not persistently stored.</li></ul><p>The agent accesses all state data through a single “session.state” dictionary. </p><p>The SessionService handles data retrieval, merging, and persistence. State should be updated upon adding an Event to the session history via “session_service.append(event)”. </p><ul><li>The simple way:<ul><li>Using “ouput_key” for Agent Text Replies. This is the easiest method if you just want to save your agent’s final text response directly into the state. </li><li>When you set up your “LlmAgent”, just tell it the “output_key” you want to use. </li><li>The Runner sees this and automatically creates the necessary actions with a “state_delta” to save the response to the state when it “append_event”. </li></ul></li><li>The Standard way: <ul><li>Using “EventActions.state_delta” for More Complicated Updates. For times when you need to do more complex things (updating several keys at once, saving things that aren’t just text, targeting specific scopes (user, app), or making updates that aren’t tied to the agent’s final text reply). </li><li>You should manually build a dictionary of your state changes (the state_delta) and include it within the “EventActions” of the Event you’re appending.</li></ul></li></ul><p>Note that direct modification of the “session.state” dictionary after retrieving a session is strongly discouraged as it bypasses the standard event processing mechanism. Such direct changes will not be recorded in the session’s event history, may not be persisted by the selected “SessionService”, could lead to concurrency issues, and will not update essential metadata such as timestamps. </p><p>The recommended methods for updating the session state are </p><ul><li>Using the “output_key” parameter on an “LlmAgent” (specifically for the agent’s final text responses) or </li><li>Including state changes within “EventActions.state_delta” when appending an event via “session_service.append_event()”. </li><li>The “session.state” should primarily be used for reading existing data. When designing your state, keep it simple, use basic data types, give your keys clear names and use prefixes correctly, avoid deep nesting, and always update state using the append_event process.</li></ul><h4 id="Memory-Long-Term-Knowledge-with-MemoryService"><a href="#Memory-Long-Term-Knowledge-with-MemoryService" class="headerlink" title="Memory: Long-Term Knowledge with MemoryService"></a>Memory: Long-Term Knowledge with MemoryService</h4><p>A searchable repository of information sourced from various past chats or external sources, serving as a resource for data retrieval beyond the immediate conversation.</p><p>The “MemoryService” oversees the storage and retrieval of long-term knowledge. </p><p>Session and State can be conceptualized as short-term memory for a single chat session, whereas the Long-Term Knowledge managed by the “MemoryService” functions as a persistent and searchable repository, which may contain information from multiple past interactions or external sources. </p><p>The “MemoryService”, as defined by the “BaseMemoryService” interface, establishes a standard for managing this searchable, long-term knowledge. Its primary functions include </p><ul><li>Adding information, which involves extracting content from a session and storing it using the “add_session_to_memory” method, </li><li>Retrieving information, which allows an agent to query the store and receive relevant data using the “search_memory” method.</li></ul><p>The ADK offers several implementations for creating this long-term knowledge store. </p><ul><li>The “InMemoryMemoryService” provides a temporary storage solution suitable for testing purposes, but data is not preserved across application restarts. </li><li>For production environments, the “VertexAiRagMemoryService” is typically utilized. This service leverages Google Cloud’s Retrieval Augmented Generation (RAG) service, enabling scalable, persistent, and semantic search capabilities. </li></ul><h3 id="LangChain-and-LangGraph"><a href="#LangChain-and-LangGraph" class="headerlink" title="LangChain and LangGraph"></a>LangChain and LangGraph</h3><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><ul><li>ChatMessageHistory: Manual Memory Management<ul><li>For direct and simple control over a conversation’s history outside of a formal chain, this method allows for the manual tracking of dialogue exchanges.</li></ul></li><li>ConversationBufferMemory(perhaps abandoned): Automated Memory for Chains<ul><li>For integrating memory directly into chains, this method is a common choice. It holds a buffer of the conversation and makes it available to your prompt. Its behavior can be customized with two key parameters:<ul><li>“memory_key”: A string that specifies the variable name in your prompt that will hold the chat history. It defaults to “history”</li><li>“return_messages”: A boolean that dictates the format of the history. <ul><li>If False (the default), it returns a single formatted string, which is ideal for standard LLMs.</li><li>If True, it returns a list of message objects, which is the recommended format for Chat Models.</li></ul></li></ul></li></ul></li></ul><h4 id="Short-Term-Memory"><a href="#Short-Term-Memory" class="headerlink" title="Short-Term Memory"></a>Short-Term Memory</h4><p>This is thread-scoped, meaning it tracks the ongoing conversation within a single session or thread. It provides immediate context, but a full history can challenge an LLM’s context window, potentially leading to errors or poor performance. </p><p>LangGraph manages short-term memory as part of the agent’s state, which is persisted via a checkpointer, allowing a thread to be resumed at any time.</p><h4 id="Long-Term-Memory"><a href="#Long-Term-Memory" class="headerlink" title="Long-Term Memory"></a>Long-Term Memory</h4><p>This stores user-specific or application-level data across sessions and is shared between conversational threads. It is saved in custom “namespaces” and can be recalled at any time in any thread. </p><p>LangGraph provides stores to save and recall long-term memories, enabling agents to retain knowledge indefinitely. It stores long-term memories as JSON documents in a store. Each memory is organized under a custom namespace (like a folder) and a distinct key (like a file name). This hierarchical structure allows for easy organization and retrieval of information. </p><ul><li>Semantic Memory: Remembering Facts<ul><li>This involves retaining specific facts and concepts, such as user preferences or domain knowledge. </li><li>It is used to ground an agent’s responses, leading to more personalized and relevant interactions. </li><li>This information can be managed as a continuously updated user “profile” (a JSON document) or as a “collection” of individual factual documents.</li></ul></li><li>Episodic Memory: Remembering Experiences<ul><li>This involves recalling past events or actions. </li><li>For AI agents, episodic memory is often used to remember how to accomplish a task. </li><li>In practice, it is frequently implemented through few-shot example prompting, where an agent learns from past successful interaction sequences to perform tasks correctly.</li></ul></li><li>Procedural Memory: Remembering Rules<ul><li>This is the memory of how to perform tasks —— the agent’s core instructions and behaviors, often contained in its system prompt. It is common for agents to modify their own prompts to adapt and improve. </li><li>An effective technique is “Reflection”, where an agent is prompted with its current instructions and recent interactions, then asked to refine its own instructions.</li></ul></li></ul><h3 id="Vertex-Memory-Bank"><a href="#Vertex-Memory-Bank" class="headerlink" title="Vertex Memory Bank"></a>Vertex Memory Bank</h3><p>Memory Bank, a managed service in the Vertex AI Agent Engine, provides agents with persistent, long-term memory. The service uses Gemini models to asynchronously analyze conversation histories to extract key facts and user preferences. </p><p>This information is stored persistently, organized by a defined scope like user ID, and intelligently updated to consolidate new data and resolve contradictions. </p><p>Upon starting a new session, the agent retrieves relevant memories through either a full data recall or a similarity search using embeddings. This process allows an agent to maintain continuity across sessions and personalize responses based on recalled information.</p><p>The agent’s runner interacts with the VertexAiMemoryBankService, which is initialized first. This service handles the automatic storage of memories generated during the agent’s conversations. Each memory is tagged with a unique “USER_ID” and “APP_NAME”, ensuring accurate retrieval in the future.</p><ul><li>Memory Bank offers seamless integration with the Google ADK, providing an immediate out-of-the-box experience. </li><li>For users of other agent frameworks, such as LangGraph and CrewAI, Memory Bank also offers support through direct API calls. </li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Memory-Management&quot;&gt;&lt;a href=&quot;#Memory-Management&quot; class=&quot;headerlink&quot; title=&quot;Memory Management&quot;&gt;&lt;/a&gt;Memory Management&lt;/h1&gt;&lt;h2 id=&quot;Motiv</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>7. Multi-Agent Collaboration</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-7_Multi_Agent_Collaboration/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-7_Multi_Agent_Collaboration/</id>
    <published>2025-09-08T09:26:13.000Z</published>
    <updated>2025-09-13T05:23:13.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Multi-Agent-Collaboration"><a href="#Multi-Agent-Collaboration" class="headerlink" title="Multi-Agent Collaboration"></a>Multi-Agent Collaboration</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problems often exceed the capabilities of a single, monolithic LLM-based agent. A solitary agent may lack the diverse, specialized skills or access to the specific tools needed to address all parts of a multifaceted task. This limitation creates a bottleneck, reducing the system’s overall effectiveness and scalability. As a result, tackling sophisticated, multi-domain objectives becomes inefficient and can lead to incomplete or suboptimal outcomes.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Multi-Agent Collaboration pattern offers a standardized solution by creating a system of multiple, cooperating agents. </p><p>A complex problem is broken down into smaller, more manageable sub-problems. Each sub-problem is then assigned to a specialized agent with the precise tools and capabilities required to solve it. </p><p>The efficacy of such a system is not merely due to the division of labor but is critically dependent on the mechanisms for inter-agent communication. These agents work together through defined communication protocols and shared ontology, allowing agents to exchange data, delegate sub-tasks, and coordinate their actions to ensure the final output is coherent.</p><p>This agentic, distributed approach creates a synergistic effect, allowing the group to achieve outcomes that would be impossible for any single agent.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p><img src="" alt="img"></p><p>A multi-agent system fundamentally comprises the delineation of agent roles and responsibilities, the establishment of communication channels through which agents exchange information, and the formulation of a task flow or interaction protocol that directs their collaborative endeavors.</p><ul><li>A complex research query might be decomposed and assigned to a Research Agent for information retrieval, </li><li>A Data Analysis Agent for statistical processing, </li><li>A Synthesis Agent for generating the final report.</li></ul><h3 id="Collaboration-Pattern"><a href="#Collaboration-Pattern" class="headerlink" title="Collaboration Pattern"></a>Collaboration Pattern</h3><p>Collaboration can take various forms: </p><ul><li>Sequential Handoffs: One agent completes a task and passes its output to another agent for the next step in a pipeline (similar to the <a href="">Planning</a>, but explicitly involving different agents).</li><li>Parallel Processing: Multiple agents work on different parts of a problem simultaneously, and their results are later combined.</li><li>Debate and Consensus: Multi-Agent Collaboration where Agents with varied perspectives and information sources engage in discussions to evaluate options, ultimately reaching a consensus or a more informed decision.</li><li>Hierarchical Structures: A manager agent might delegate tasks to worker agents dynamically based on their tool access or plugin capabilities and synthesize their results. Each agent can also handle relevant groups of tools, rather than a single agent handling all the tools.</li><li>Expert Teams: Agents with specialized knowledge in different domains (e.g., a researcher, a writer, an editor) collaborate to produce a complex output.</li><li>Critic-Reviewer: Agents create initial outputs such as plans, drafts, or answers. A second group of agents then critically assesses this output for adherence to policies, security, compliance, correctness, quality, and alignment with organizational objectives. The original creator or a final agent revises the output based on the feedback. <ul><li>This pattern is particularly effective for code generation, research writing, logic checking, and ensuring ethical alignment. </li><li>The advantages of this approach include increased robustness, improved quality, and a reduced likelihood of hallucinations or errors.</li></ul></li></ul><h3 id="Collaboration-Architecture"><a href="#Collaboration-Architecture" class="headerlink" title="Collaboration Architecture"></a>Collaboration Architecture</h3><ul><li>Single Agent: <ul><li>At the most basic level, a “Single Agent” operates autonomously without direct interaction or communication with other entities.</li><li>It is suitable for tasks that are decomposable into independent sub-problems, each solvable by a single, self-sufficient agent.</li><li>While this method is straightforward to implement and manage, its capabilities are inherently limited by the individual agent’s scope and resources.</li></ul></li><li>Network:<ul><li>The “Network” represents a significant step towards collaboration, where multiple agents interact directly with each other in a decentralized fashion.</li><li>Communication typically occurs peer-to-peer, allowing for the sharing of information, resources, and even tasks.</li><li>This method fosters resilience, as the failure of one agent does not necessarily cripple the entire system.</li><li>However, managing communication overhead and ensuring coherent decision-making in a large, unstructured network can be challenging.</li></ul></li><li>Supervisor (Agent version):<ul><li>A dedicated agent as “supervisor”, oversees and coordinates the activities of a group of subordinate agents.</li><li>The supervisor acts as a central hub for communication, task allocation, and conflict resolution.</li><li>This hierarchical structure offers clear lines of authority and can simplify management and control.</li><li>However, it introduces a single point of failure (the supervisor) and can become a bottleneck if the supervisor is overwhelmed by a large number of subordinates or complex tasks.</li></ul></li><li>Supervisor (Tool version): <ul><li>The supervisor’s role is less about direct command and control and more about providing resources, guidance, or analytical support to other agents, aiming to leverage the supervisor’s capabilities without imposing rigid top-down control.</li></ul></li><li>Hierarchical:<ul><li>This method expands upon the supervisor concept to create a multi-layered organizational structure. </li><li>This involves multiple levels of supervisors, with higher-level supervisors overseeing lower-level ones, and ultimately, a collection of operational agents at the lowest tier.</li><li>This structure is well-suited for complex problems that can be decomposed into sub-problems, each managed by a specific layer of the hierarchy. </li></ul></li><li>Custom:<ul><li>This method represents the ultimate flexibility in multi-agent system design. </li><li>It allows for the creation of unique interrelationship and communication structures tailored precisely to the specific requirements of a given problem or application. It requires careful consideration of communication protocols, coordination mechanisms, and emergent behaviors.</li><li>This can involve hybrid approaches that combine elements from the previously mentioned models, or entirely novel designs that emerge from the unique constraints and opportunities of the environment.</li><li>Custom models often arise from the need to optimize for specific performance metrics, handle highly dynamic environments, or incorporate domain-specific knowledge into the system’s architecture.</li></ul></li></ul><p><img src="" alt="img"></p><p>Each method offers distinct advantages and disadvantages, and the optimal choice depends on factors such as the complexity of the task, the number of agents, the desired level of autonomy, the need for robustness, and the acceptable communication overhead. </p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when a task is too complex for a single agent and can be decomposed into distinct sub-tasks requiring specialized skills or tools. </p><p>It is ideal for problems that benefit from diverse expertise, parallel processing, or a structured workflow with multiple stages, such as complex research and analysis, software development, or creative content generation.</p><h3 id="Complex-Research-and-Analysis"><a href="#Complex-Research-and-Analysis" class="headerlink" title="Complex Research and Analysis"></a>Complex Research and Analysis</h3><p>This mirrors how a human research team might operate:</p><ul><li>One agent might specialize in searching academic databases, </li><li>Another in summarizing findings, </li><li>A third in identifying trends, </li><li>A fourth in synthesizing the information into a report. </li></ul><h3 id="Software-Development"><a href="#Software-Development" class="headerlink" title="Software Development"></a>Software Development</h3><p>This mirrors how a human software team might operate:</p><ul><li>One agent could be a requirement analyst, </li><li>Another a code generator,</li><li>A third a tester,</li><li>A fourth a documentation writer</li></ul><h3 id="Creative-Content-Generation"><a href="#Creative-Content-Generation" class="headerlink" title="Creative Content Generation"></a>Creative Content Generation</h3><p>Creating a marketing campaign could involve:</p><ul><li>A market research agent, </li><li>A copywriter agent, </li><li>A graphic design agent which use image generation tools,</li><li>A social media scheduling agent </li></ul><h3 id="Financial-Analysis"><a href="#Financial-Analysis" class="headerlink" title="Financial Analysis"></a>Financial Analysis</h3><p>This might specialize in:</p><ul><li>Fetching stock data,</li><li>Analyzing news sentiment, </li><li>Performing technical analysis, </li><li>Generating investment recommendations</li></ul><h3 id="Customer-Support-Escalation"><a href="#Customer-Support-Escalation" class="headerlink" title="Customer Support Escalation"></a>Customer Support Escalation</h3><p>A front-line support agent can handle:</p><ul><li>Initial queries,</li><li>Escalating complex issues to a specialist agent (e.g., a technical expert or a billing specialist) when needed, demonstrating a sequential handoff based on problem complexity.</li></ul><h3 id="Supply-Chain-Optimization"><a href="#Supply-Chain-Optimization" class="headerlink" title="Supply Chain Optimization"></a>Supply Chain Optimization</h3><p>Agents could represent different nodes in a supply chain:</p><ul><li>Suppliers,</li><li>Manufacturers,</li><li>Distributors</li></ul><p>They Collaborate to optimize:</p><ul><li>Inventory levels,</li><li>Logistics,</li><li>Scheduling</li></ul><h3 id="Network-Analysis-amp-Remediation"><a href="#Network-Analysis-amp-Remediation" class="headerlink" title="Network Analysis &amp; Remediation"></a>Network Analysis &amp; Remediation</h3><p>Multiple agents can collaborate to triage and remediate issues, suggesting optimal actions.</p><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Frameworks such as Crew AI and Google ADK are engineered to facilitate this paradigm by providing structures for the specification of agents, tasks, and their interactive procedures. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Multi-Agent-Collaboration&quot;&gt;&lt;a href=&quot;#Multi-Agent-Collaboration&quot; class=&quot;headerlink&quot; title=&quot;Multi-Agent Collaboration&quot;&gt;&lt;/a&gt;Multi-Agent</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>6. Planning</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-6_Planning/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-6_Planning/</id>
    <published>2025-09-08T09:25:51.000Z</published>
    <updated>2025-09-12T03:10:18.390Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Planning"><a href="#Planning" class="headerlink" title="Planning"></a>Planning</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Complex problems often cannot be solved with a single action and require foresight to achieve a desired outcome. Without a structured approach, an agentic system struggles to handle multifaceted requests that involve multiple steps and dependencies. This makes it difficult to break down high-level objectives into a manageable series of smaller, executable tasks. Consequently, the system fails to strategize effectively, leading to incomplete or incorrect results when faced with intricate goals.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Planning pattern offers a standardized solution by having an agentic system first create a coherent plan to address a goal. It involves decomposing a high-level objective into a sequence of smaller, actionable steps or sub-goals. This allows the system to manage complex workflows, orchestrate various tools, and handle dependencies in a logical order. LLMs are particularly well-suited for this, as they can generate plausible and effective plans based on their vast training data. This structured approach transforms a simple reactive agent into a strategic executor that can proactively work towards a complex objective and even adapt its plan if necessary.</p><p>The efficiency of this approach stems from the automation of the iterative search-and-filter cycle, which is a core bottleneck in manual research. </p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>Use this pattern when a user’s request is too complex to be handled by a single action or tool. It is ideal for automating multi-step processes, such as generating a detailed research report, onboarding a new employee, or executing a competitive analysis. Apply the Planning pattern whenever a task requires a sequence of interdependent operations to reach a final, synthesized outcome.</p><ul><li>In domains such as procedural task automation, planning is used to orchestrate complex workflows.</li><li>Within robotics and autonomous navigation, planning is fundamental for state-space traversal. </li><li>Planning is also critical for structured information synthesis.</li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Google Deep Research is an agent analyzing on our behalf sources obtained using Google Search as a tool. It reflects, plans, and executes</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Planning&quot;&gt;&lt;a href=&quot;#Planning&quot; class=&quot;headerlink&quot; title=&quot;Planning&quot;&gt;&lt;/a&gt;Planning&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>5. Tool_Use</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-5_Tool_Use/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-5_Tool_Use/</id>
    <published>2025-09-08T09:25:34.000Z</published>
    <updated>2025-09-11T03:28:24.336Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tool-Use-Function-Calling"><a href="#Tool-Use-Function-Calling" class="headerlink" title="Tool Use (Function Calling)"></a>Tool Use (Function Calling)</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>LLMs are powerful text generators, but they are fundamentally disconnected from the outside world. Their knowledge is static, limited to the data they were trained on, and they lack the ability to perform actions or retrieve real-time information. This inherent limitation prevents them from completing tasks that require interaction with external APIs, databases, or services. Without a bridge to these external systems, their utility for solving real-world problems is severely constrained.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>The Tool Use pattern, often implemented through a mechanism called Function Calling, enables an agent to interact with external APIs, databases, services, or even execute code. It allows the LLM at the core of the agent to decide when and how to use a specific external function based on the user’s request or the current state of the task.</p><p>A “tool” can be a traditional function, but it can also be a complex API endpoint, a request to a database, or even an instruction directed at another specialized agent. </p><p>Tool Use is a cornerstone pattern for building powerful, interactive, and externally aware agents.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The process typically involves the following steps:</p><ul><li>Tool Definition: <ul><li>External functions or capabilities are defined and described to the LLM. This description includes the function’s purpose, its name, and the parameters it accepts, along with their types and descriptions.</li></ul></li><li>LLM Decision:<ul><li>The LLM receives the user’s request and the available tool definitions. Based on its understanding of the request and the tools, the LLM decides if calling one or more tools is necessary to fulfill the request.</li></ul></li><li>Function Call Generation:<ul><li>If the LLM decides to use a tool, it generates a structured output (often a JSON object) that specifies the name of the tool to call and the arguments (parameters) to pass to it, extracted from the user’s request.</li></ul></li><li>Tool Execution:<ul><li>The agentic framework or orchestration layer intercepts this structured output. It identifies the requested tool and executes the actual external function with the provided arguments.</li></ul></li><li>Observation/Result:<ul><li>The output or result from the tool execution is returned to the agent.</li></ul></li><li>LLM Processing:<ul><li>The LLM receives the tool’s output as context and uses it to formulate a final response to the user or decide on the next step in the workflow (which might involve calling another tool, reflecting, or providing a final answer).</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>The Tool Use pattern is applicable in virtually any scenario where an agent needs to go beyond generating text to perform an action or retrieve specific, dynamic information. This is essential for tasks requiring real-time data (e.g., checking weather, stock prices), accessing private or proprietary information (e.g., querying a company’s database), performing precise calculations, executing code, or triggering actions in other systems (e.g., sending an email, controlling smart devices).</p><h3 id="Information-Retrieval-from-External-Sources"><a href="#Information-Retrieval-from-External-Sources" class="headerlink" title="Information Retrieval from External Sources"></a>Information Retrieval from External Sources</h3><p>Accessing real-time data or information that is not present in the LLM’s training data. </p><ul><li>Weather Agent:<ul><li>Tool: A weather API that takes a location and returns the current weather conditions.</li><li>Workflow: User asks, “What’s the weather in London?”, LLM identifies the need for the weather tool, calls the tool with “London”, tool returns data, LLM formats the data into a user-friendly response.</li></ul></li></ul><h3 id="Interacting-with-Databases-and-APIs"><a href="#Interacting-with-Databases-and-APIs" class="headerlink" title="Interacting with Databases and APIs"></a>Interacting with Databases and APIs</h3><p>Performing queries, updates, or other operations on structured data.</p><ul><li>E-commerce Agent:<ul><li>Tool: API calls to check product inventory, get order status, or process payments.</li><li>Workflow: User asks “Is product X in stock?”, LLM calls the inventory API, tool returns stock count, LLM tells the user the stock status.</li></ul></li></ul><h3 id="Performing-Calculations-and-Data-Analysis"><a href="#Performing-Calculations-and-Data-Analysis" class="headerlink" title="Performing Calculations and Data Analysis"></a>Performing Calculations and Data Analysis</h3><p>Using external calculators, data analysis libraries, or statistical tools.</p><ul><li>Financial Agent:<ul><li>Tools: A calculator function, a stock market data API, a spreadsheet tool.</li><li>Workflow: User asks “What’s the current price of AAPL and calculate the potential profit if I bought 100 shares at $150?”, LLM calls stock API, gets current price, then calls calculator tool, gets result, formats response.</li></ul></li></ul><h3 id="Sending-Communications"><a href="#Sending-Communications" class="headerlink" title="Sending Communications"></a>Sending Communications</h3><p>Sending emails, messages, or making API calls to external communication services.</p><ul><li>Personal Assistant Agent: <ul><li>Tools: An email sending API.</li><li>Workflow: User says, “Send an e-mail to John about the meeting tomorrow.”, LLM calls an email tool with the recipient, subject, and body extracted from the request.</li></ul></li></ul><h3 id="Executing-Code"><a href="#Executing-Code" class="headerlink" title="Executing Code"></a>Executing Code</h3><p>Running code snippets in a safe environment to perform specific tasks.</p><ul><li>Coding Assistant Agent: <ul><li>Tools: A coding interpreter.</li><li>Workflow: User provides a Python snippet and asks, “What does this code do?”, LLM uses the interpreter tool to run the code and analyze its output.</li></ul></li></ul><h3 id="Controlling-Other-Systems-or-Devices"><a href="#Controlling-Other-Systems-or-Devices" class="headerlink" title="Controlling Other Systems or Devices"></a>Controlling Other Systems or Devices</h3><p>Interacting with smart home devices, IoT platforms, or other connected systems.</p><ul><li>Smart Home Assistant Agent:<ul><li>Tools: An API to control smart lights.</li><li>Workflow: User says, “Turn off the living room lights”, LLM calls the smart home tool with the command and target device.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The implementation of tool use within the LangChain framework is a two-stage process.</p><ul><li>Initially, one or more tools are defined, typically by encapsulating existing Python functions or other runnable components. </li><li>Subsequently, these tools are bound to a language model, thereby granting the model the capability to generate a structured tool-use request when it determines that an external function call is required to fulfill a user’s query.</li></ul><p>LangChain simplifies tool definition using the @tool decorator and provides create_tool_calling_agent and AgentExecutor for building tool-using agents.</p><p>Google ADK has a number of very useful pre-built tools such as Google Search, Code Execution and Vertex AI Search Tool.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Tool-Use-Function-Calling&quot;&gt;&lt;a href=&quot;#Tool-Use-Function-Calling&quot; class=&quot;headerlink&quot; title=&quot;Tool Use (Function Calling)&quot;&gt;&lt;/a&gt;Tool Use </summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>4. Reflection</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-4_Reflection/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-4_Reflection/</id>
    <published>2025-09-08T09:25:16.000Z</published>
    <updated>2025-09-10T03:30:28.817Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Reflection"><a href="#Reflection" class="headerlink" title="Reflection"></a>Reflection</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>An agent’s initial output is often suboptimal, suffering from inaccuracies, incompleteness, or a failure to meet complex requirements. Basic agentic workflows lack a built-in process for the agent to recognize and fix its own errors. This is solved by having the agent evaluate its own work or, more robustly, by introducing a separate logical agent to act as a critic, preventing the initial response from being the final one regardless of quality.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>The Reflection pattern involves an agent evaluating its own work, output, or internal state and using that evaluation to improve its performance or refine its response. It’s a form of self-correction or self-improvement, allowing the agent to iteratively refine its output or adjust its approach based on feedback, internal critique, or comparison against desired criteria. Reflection can occasionally be facilitated by a separate agent whose specific role is to analyze the output of an initial agent.</p><p><img src="" alt="img"></p><p>The intersection of reflection with goal setting and monitoring (See <a href="#">Chapter 11</a>) is worth noticing. A goal provides the ultimate benchmark for the agent’s self-evaluation, while monitoring tracks its progress. This synergy transforms the agent from a passive executor into a purposeful system that adaptively works to achieve its objectives.</p><p>Furthermore, the effectiveness of the Reflection pattern is significantly enhanced when the LLM keeps a memory of the conversation (see <a href="#">Chapter 8</a>). This conversational history provides crucial context for the evaluation phase, allowing the agent to assess its output not just in isolation, but against the backdrop of previous interactions, user feedback, and evolving goals. It enables the agent to learn from past critiques and avoid repeating errors. Without memory, each reflection is a self-contained event; with memory, reflection becomes a cumulative process where each cycle builds upon the last, leading to more intelligent and context-aware refinement.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The Reflection pattern introduces a feedback loop. The agent doesn’t just produce an output; it then examines that output (or the process that generated it), identifies potential issues or areas for improvement, and uses those insights to generate a better version or modify its future actions.</p><p>The workflow is as follows:</p><ul><li>Execution: <ul><li>The agent performs a task or generates an initial output.</li></ul></li><li>Evaluation/Critique: <ul><li>The agent (often using another LLM call or a set or rules) analyzes the result from the previous step. This evaluation might check for factual accuracy, coherence, style, completeness, adherence to instructions, or other relevant criteria.</li></ul></li><li>Reflection/Refinement: <ul><li>Based on the critique, the agent determines how to improve. This might involve generating a refined output, adjusting parameters for a subsequent step, or even modifying the overall plan.</li></ul></li><li>Iteration (Optional but common): <ul><li>The refined output or adjusted approach can then be executed, and the reflection process can repeat until a satisfactory result is achieved, or a stopping condition is met.</li></ul></li></ul><p>A key and highly effective implementation of the Reflection pattern separates the process into two distinct logical roles: a Producer and a Critic. This is often called the “Generator-Critic” or “Producer-Reviewer” model. While a single agent can perform self-reflection, using two specialized agents (or two separate LLM calls with distinct system prompts) often yields more robust and unbiased results.</p><ul><li>The Producer Agent:<ul><li>This agent’s primary responsibility is to perform the initial execution of the task. It focuses entirely on generating the content, whether it’s writing code, drafting a blog post, or creating a plan. It takes the initial prompt and produces the first version of the output.</li></ul></li><li>The Critic Agent:<ul><li>This agent’s sole purpose is to evaluate the output generated by the Producer. It is given a different set of instructions, often a distinct persona (e.g., “You are a senior software engineer,” “You are a meticulous fact-checker”). The Critic’s instructions guide it to analyze the Producer’s work against specific criteria, such as factual accuracy, code quality, stylistic requirements, or completeness. It is designed to find flaws, suggest improvements, and provide structured feedback.</li></ul></li></ul><p>This separation of concerns is powerful because it prevents the “cognitive bias” of an agent reviewing its own work. The Critic agent approaches the output with a fresh perspective, dedicated entirely to finding errors and areas for improvement. The feedback from the Critic is then passed back to the Producer agent, which uses it as a guide to generate a new, refined version of the output. </p><p>Reflection adds a layer of meta-cognition to agentic systems, enabling them to learn from their own outputs and processes, leading to more intelligent, reliable, and high-quality results.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>The Reflection pattern is valuable in scenarios where output quality, accuracy, or adherence to complex constraints is critical. </p><h3 id="Creative-Writing-and-Content-Creation"><a href="#Creative-Writing-and-Content-Creation" class="headerlink" title="Creative Writing and Content Creation"></a>Creative Writing and Content Creation</h3><p>Refining generated text, stories, poems, or marketing copy.</p><ul><li>Reflection Tasks: Generate a draft, critique it for flow, tone, and clarity, then rewrite based on the critique. Repeat until the post meets quality standards.</li></ul><h3 id="Code-Generation-and-Debugging"><a href="#Code-Generation-and-Debugging" class="headerlink" title="Code Generation and Debugging"></a>Code Generation and Debugging</h3><p>Writing code, identifying errors, and fixing them.</p><ul><li>Reflection Tasks: Write initial code, run tests or static analysis, identify errors or inefficiencies, then modify the code based on the findings.</li></ul><h3 id="Complex-Problem-Solving"><a href="#Complex-Problem-Solving" class="headerlink" title="Complex Problem Solving"></a>Complex Problem Solving</h3><p>Evaluating intermediate steps or proposed solutions in multi-step reasoning tasks.</p><ul><li>Reflection Tasks: Propose a step, evaluate if it leads closer to the solution or introduces contradictions, backtrack or choose a different step if needed.</li></ul><h3 id="Summarization-and-Information-Synthesis"><a href="#Summarization-and-Information-Synthesis" class="headerlink" title="Summarization and Information Synthesis"></a>Summarization and Information Synthesis</h3><p>Refining summaries for accuracy, completeness, and conciseness. </p><ul><li>Reflection Tasks: Generate an initial summary, compare it against key points in the original document, refine the summary to include missing information or improve accuracy. </li></ul><h3 id="Planning-and-Strategy"><a href="#Planning-and-Strategy" class="headerlink" title="Planning and Strategy"></a>Planning and Strategy</h3><p>Evaluating a proposed plan and identifying potential flaws or improvements.</p><ul><li>Reflection Tasks: Generate a plan, simulate its execution or evaluate its feasibility against constraints, revise the plan based on the evaluation.</li></ul><h3 id="Conversational-Agents"><a href="#Conversational-Agents" class="headerlink" title="Conversational Agents"></a>Conversational Agents</h3><p>Reviewing previous turns in a conversation to maintain context, correct misunderstandings, or improve response quality.</p><ul><li>Reflection Tasks: After a user response, review the conversation history and the last generated message to ensure coherence and address the user’s latest input accurately.</li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The provided LangChain and ADK code examples both implement this two-agent model: the LangChain example uses a specific “reflector_prompt” to create a critic persona, while the ADK example explicitly defines a producer and a reviewer agent. While a single step of evaluation and refinement can be implemented within either a LangChain/LangGraph, or ADK, or Crew.AI chain, true iterative reflection typically involves more complex orchestration.</p><h2 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages"></a>Disadvantages</h2><p>The iterative process, though powerful, can lead to higher costs and latency, since every refinement loop may require a new LLM call, making it suboptimal for time-sensitive applications. Furthermore, the pattern is memory-intensive; with each iteration, the conversational history expands, including the initial output, critique, and subsequent refinements.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Reflection&quot;&gt;&lt;a href=&quot;#Reflection&quot; class=&quot;headerlink&quot; title=&quot;Reflection&quot;&gt;&lt;/a&gt;Reflection&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>3. Parallelization</title>
    <link href="http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-3_Parallelization/"/>
    <id>http://zjn-astonishe.github.io/2025/09/08/Agent/2025-09-08-3_Parallelization/</id>
    <published>2025-09-08T08:04:45.000Z</published>
    <updated>2025-09-10T03:22:26.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parallelization"><a href="#Parallelization" class="headerlink" title="Parallelization"></a>Parallelization</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Many complex agentic tasks involve multiple sub-tasks that can be executed simultaneously rather than one after another. A purely sequential execution, where each task waits for the previous one to finish, is often inefficient and slow. This latency becomes a significant bottleneck when tasks depend on external I/O operations, such as calling different APIs or querying multiple databases. Without a mechanism for concurrent execution, the total processing time is the sum of all individual task durations, hindering the system’s overall performance and responsiveness.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>Parallelization involves executing multiple components, such as LLM calls, tool usages, or even entire sub-agents, concurrently. Instead of waiting for one step to complete before starting the next, parallel execution allows independent tasks to run at the same time, significantly reducing the overall execution time for tasks that can be broken down into independent parts.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The core idea is to identify parts of the workflow that do not depend on the output of other parts and execute them in parallel. </p><p>Implementing parallelization often requires frameworks that support asynchronous execution or multi-threading/multi-processing. Modern agentic frameworks are designed with asynchronous operations in mind, allowing you to easily define steps that can run in parallel.</p><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>This is particularly effective when dealing with external services (like APIs or databases) that have latency, as you can issue multiple requests concurrently.</p><h3 id="Information-Gathering-and-Research"><a href="#Information-Gathering-and-Research" class="headerlink" title="Information Gathering and Research"></a>Information Gathering and Research</h3><p>Collecting information from multiple sources simultaneously is a classic use case. </p><ul><li>Parallel Tasks: execute below all at the same time.<ul><li>Search news articles</li><li>Pull stock data</li><li>Check social media mentions</li><li>Query a company database</li></ul></li></ul><h3 id="Data-Processing-and-Analysis"><a href="#Data-Processing-and-Analysis" class="headerlink" title="Data Processing and Analysis"></a>Data Processing and Analysis</h3><p>Applying different analysis techniques or processing different data segments concurrently. </p><ul><li>Parallel Tasks: execute across a batch of feedback entries simultaneously.<ul><li>Run sentiment analysis</li><li>Extract keywords</li><li>Categorize feedback</li><li>Identify urgent issues</li></ul></li></ul><h3 id="Multi-API-or-Tool-Interaction"><a href="#Multi-API-or-Tool-Interaction" class="headerlink" title="Multi-API or Tool Interaction"></a>Multi-API or Tool Interaction</h3><p>Calling multiple independent APIs or tools to gather different types of information or perform different actions, such as travel planning agent.</p><ul><li>Parallel Tasks: execute below concurrently.<ul><li>Check flight prices</li><li>Search for hotel availability</li><li>Look up local events</li><li>Find restaurant recommendations</li></ul></li></ul><h3 id="Content-Generation-with-Multiple-Components"><a href="#Content-Generation-with-Multiple-Components" class="headerlink" title="Content Generation with Multiple Components"></a>Content Generation with Multiple Components</h3><p>Generating different parts of a complex piece of content in parallel.</p><ul><li>Parallel Tasks:<ul><li>Generate a subject line</li><li>Draft the email body</li><li>Find a relevant image</li><li>Create a call-to-action button text</li></ul></li></ul><h3 id="Validation-and-Verification"><a href="#Validation-and-Verification" class="headerlink" title="Validation and Verification"></a>Validation and Verification</h3><p>Performing multiple independent checks or validations concurrently.</p><ul><li>Parallel Tasks:<ul><li>Check email format</li><li>Validate phone number</li><li>Verify address against a database</li><li>Check for profanity</li></ul></li></ul><h3 id="Multi-Modal-Processing"><a href="#Multi-Modal-Processing" class="headerlink" title="Multi-Modal Processing"></a>Multi-Modal Processing</h3><p>Processing different modalities (text, image, audio) of the same input concurrently.</p><ul><li>Parallel Tasks:<ul><li>Analyze the text for sentiment and keywords</li><li>Analyze the image for objects and scene description</li></ul></li></ul><h3 id="A-B-Testing-or-Multiple-Options-Generation"><a href="#A-B-Testing-or-Multiple-Options-Generation" class="headerlink" title="A/B Testing or Multiple Options Generation"></a>A/B Testing or Multiple Options Generation</h3><p>Generating multiple variations of a response or output in parallel to select the best one.</p><ul><li>Parallel tasks:<ul><li>Generate three different headlines for an article simultaneously using slightly different prompts or models.</li></ul></li></ul><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Frameworks provide distinct mechanisms for implementing this pattern. In LangChain, constructs like RunnableParallel are used to explicitly define and execute multiple processing chains simultaneously. In contrast, frameworks like the Google Agent Developer Kit (ADK) can achieve parallelization through multi-agent delegation, where a primary coordinator model assigns different sub-tasks to specialized agents that can operate concurrently.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Parallelization&quot;&gt;&lt;a href=&quot;#Parallelization&quot; class=&quot;headerlink&quot; title=&quot;Parallelization&quot;&gt;&lt;/a&gt;Parallelization&lt;/h1&gt;&lt;h2 id=&quot;Motivation&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
  <entry>
    <title>2. Routing</title>
    <link href="http://zjn-astonishe.github.io/2025/09/07/Agent/2025-09-07-2_Routing/"/>
    <id>http://zjn-astonishe.github.io/2025/09/07/Agent/2025-09-07-2_Routing/</id>
    <published>2025-09-07T09:17:43.000Z</published>
    <updated>2025-09-10T03:22:03.418Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><img src="" alt="img"></p><p>Real-world agentic systems must often arbitrate between multiple potential actions based on contingent factors, such as the state of the environment, user input, or the outcome of a preceding operation. </p><p>This capacity for dynamic decision-making, which governs the flow of control to different specialized functions, tools, or sub-processes, is achieved through a mechanism known as routing.</p><p>Routing introduces conditional logic into an agent’s operational framework, enabling a shift from a fixed execution path to a model where the agent dynamically evaluates specific criteria to select from a set of possible subsequent actions. This allows for more flexible and context-aware system behavior.</p><p>The implementation of routing enables a system to move beyond deterministic sequential processing. It facilitates the development of more adaptive execution flows that can respond dynamically and appropriately to a wider range of inputs and state changes.</p><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p>The core component of the Routing pattern is a mechanism that performs the evaluation and directs the flow. This mechanism can be implemented in several ways: </p><ul><li>LLM-based Routing: <ul><li>The language model itself can be prompted to analyze the input and output a specific identifier or instruction that indicates the next step or destination. </li></ul></li><li>Embedding-based Routing: <ul><li>The input query can be converted into a vector embedding. This embedding is then compared to embeddings representing different routes or capabilities. The query is routed to the route whose embedding is most similar. </li><li>This is useful for semantic routing, where the decision is based on the meaning of the input rather than just keywords. </li></ul></li><li>Rule-based Routing: <ul><li>This involves using predefined rules or logic (e.g., if-else statements, switch cases) based on keywords, patterns, or structured data extracted from the input. This can be faster and more deterministic than LLM-based routing, but is less flexible for handling nuanced or novel inputs. </li></ul></li><li>Machine Learning Model-Based Routing: <ul><li>It employs a discriminative model, such as a classifier, that has been specifically trained on a small corpus of labeled data to perform a routing task. </li><li>While it shares conceptual similarities with embedding-based methods, its key characteristic is the supervised fine-tuning process, which adjusts the model’s parameters to create a specialized routing function.</li><li>This technique is also distinct from LLM-based routing because the decision-making component is not a generative model executing a prompt at inference time. Instead, the routing logic is encoded within the fine-tuned model’s learned weights. </li><li>While LLMs may be used in a pre-processing step to generate synthetic data for augmenting the training set, they are not involved in the real-time routing decision itself.</li></ul></li></ul><h2 id="Applicable-Scenarios"><a href="#Applicable-Scenarios" class="headerlink" title="Applicable Scenarios"></a>Applicable Scenarios</h2><p>An agent designed for customer inquiries, when equipped with a routing function, can first classify an incoming query to determine the user’s intent. Based on this classification, it can then direct the query to a specialized agent for direct question-answering:</p><ul><li>Analyze the user’s query.</li><li>Route the query based on its intent:<ul><li>If the intent is “Check order status”, route to a sub-agent or tool chain that interacts with the order database. </li><li>If the intent is “product information”, route to a sub-agent or chain that searches the product catalog.</li><li>If the intent is “technical support”, route to a different chain that accesses troubleshooting guides or escalates to a human.</li><li>If the intent is unclear, route to a clarification sub-agent or prompt chain.</li></ul></li></ul><p>Routing mechanisms can be implemented at multiple junctures within an agent’s operational cycle. </p><ul><li>They can be applied at the outset to classify a primary task, </li><li>at intermediate points within a processing chain to determine a subsequent action, </li><li>or during a subroutine to select the most appropriate tool from a given set.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Routing&quot;&gt;&lt;a href=&quot;#Routing&quot; class=&quot;headerlink&quot; title=&quot;Routing&quot;&gt;&lt;/a&gt;Routing&lt;/h1&gt;&lt;h2 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/categories/Agent/"/>
    
    
    <category term="Agent" scheme="http://zjn-astonishe.github.io/tags/Agent/"/>
    
  </entry>
  
</feed>
